scripts/gmstereo_scale2_regrefine3_train.sh: 27: --img_height: not found
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth--no_resume_optimizer', strict_resume=False, no_resume_optimizer=False, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth--no_resume_optimizer
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 210, in main
    checkpoint = torch.load(args.resume, map_location=loc)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/serialization.py", line 771, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/serialization.py", line 270, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/serialization.py", line 251, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth--no_resume_optimizer'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 19430) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_12:05:43
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 19430)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 0 training samples found in the training set
2023-02-28 12:06:22.173145: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 12:06:22.282467: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 12:06:22.653156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 12:06:22.653193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 12:06:22.653196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 0 training samples found in the training set
2023-02-28 12:56:54.708017: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 12:56:54.792403: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 12:56:55.175491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 12:56:55.175524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 12:56:55.175528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 0 training samples found in the training set
2023-02-28 13:00:18.062491: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:00:18.145900: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:00:18.525777: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64::/usr/local/lib/:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:00:18.525824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64::/usr/local/lib/:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:00:18.525828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 0 training samples found in the training set
2023-02-28 13:01:00.167333: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:01:00.249674: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:01:00.628571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:01:00.628606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:01:00.628610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 0 training samples found in the training set
2023-02-28 13:06:55.195260: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:06:55.278847: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:06:55.663372: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:06:55.663408: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:06:55.663411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 352, in main
    train_data = build_dataset(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 693, in build_dataset
    return Hybrid(transform=train_transform)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 650, in __init__
    assert len(left_files) == len(right_files) == len(disp_files)
AssertionError
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 440524) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:10:35
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 440524)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 0
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 352, in main
    train_data = build_dataset(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 694, in build_dataset
    return Hybrid(transform=train_transform)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 651, in __init__
    assert len(left_files) == len(right_files) == len(disp_files)
AssertionError
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 440633) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:11:33
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 440633)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:12:56.614718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:12:56.707785: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:12:57.269553: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:12:57.269588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:12:57.269591: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 82, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 310, in __call__
    h, w = sample['disp'].shape
ValueError: too many values to unpack (expected 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 443471) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:13:09
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 443471)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:14:02.766317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:14:02.858395: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:14:03.263602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:14:03.263638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:14:03.263641: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 82, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 90, in __call__
    sample['disp'] = np.lib.pad(sample['disp'],
  File "<__array_function__ internals>", line 180, in pad
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 743, in pad
    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 518, in _as_pairs
    return np.broadcast_to(x, (ndim, 2)).tolist()
  File "<__array_function__ internals>", line 180, in broadcast_to
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 412, in broadcast_to
    return _broadcast_to(array, shape, subok=subok, readonly=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 348, in _broadcast_to
    it = np.nditer(
ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 448331) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:14:15
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 448331)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:15:57.855788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:15:57.939060: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:15:58.324416: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:15:58.324452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:15:58.324455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 82, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 310, in __call__
    h, w = sample['disp'].shape
ValueError: too many values to unpack (expected 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 452790) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:16:11
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 452790)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:26:39.985729: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:26:40.068875: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:26:40.451140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:26:40.451177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:26:40.451180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 93, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 310, in __call__
    h, w = sample['disp'].shape
ValueError: too many values to unpack (expected 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 454149) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:26:53
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 454149)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:32:49.022238: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:32:49.106272: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:32:49.492028: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:32:49.492066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:32:49.492069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 310, in __call__
    h, w = sample['disp'].shape
ValueError: too many values to unpack (expected 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 454830) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:33:02
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 454830)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:33:55.221504: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:33:55.305615: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:33:55.692201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:33:55.692236: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:33:55.692240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 310, in __call__
    h, w = sample['disp'].shape
ValueError: too many values to unpack (expected 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 455341) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:34:08
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 455341)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:39:25.159409: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:39:25.243501: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:39:25.632274: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:39:25.632311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:39:25.632314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 311, in __call__
    h, w = sample['disp'].shape
ValueError: too many values to unpack (expected 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 456188) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:39:38
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 456188)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:40:42.593379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:40:42.675881: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:40:43.058876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:40:43.058911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:40:43.058915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 311, in __call__
    h, w = sample['disp'].shape
ValueError: too many values to unpack (expected 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 456691) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:40:55
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 456691)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:41:59.306956: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:41:59.392302: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:41:59.777856: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:41:59.777894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:41:59.777897: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
[[[0.0859375  0.04296875 0.22265625]
  [0.0859375  0.04296875 0.22265625]
  [0.0859375  0.04296875 0.22265625]
  ...
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]]

 [[0.0859375  0.04296875 0.22265625]
  [0.0859375  0.04296875 0.22265625]
  [0.0859375  0.04296875 0.22265625]
  ...
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]]

 [[0.0859375  0.04296875 0.22265625]
  [0.0859375  0.04296875 0.22265625]
  [0.0859375  0.04296875 0.22265625]
  ...
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]]

 ...

 [[0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]]

 [[0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  ...
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]]

 [[0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  ...
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]]]
[[[0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  ...
  [0.62109375 0.1640625  0.38671875]
  [0.59375    0.15234375 0.3984375 ]
  [0.55859375 0.140625   0.41015625]]

 [[0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  ...
  [0.60546875 0.16015625 0.390625  ]
  [0.58203125 0.1484375  0.40234375]
  [0.5390625  0.1328125  0.4140625 ]]

 [[0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  ...
  [0.60546875 0.16015625 0.390625  ]
  [0.5703125  0.14453125 0.40625   ]
  [0.5390625  0.1328125  0.4140625 ]]

 ...

 [[0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]]

 [[0.96875    0.98046875 0.6015625 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]]

 [[0.96875    0.98046875 0.6015625 ]
  [0.96875    0.98046875 0.6015625 ]
  [0.96875    0.98046875 0.6015625 ]
  ...
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]]]
[[[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.00390625 0.         0.01953125]
  [0.00390625 0.         0.01953125]
  [0.00390625 0.         0.01953125]]

 [[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.00390625 0.         0.01953125]
  [0.00390625 0.         0.01953125]
  [0.00390625 0.         0.01953125]]

 [[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.00390625 0.         0.01953125]
  [0.00390625 0.         0.01953125]
  [0.00390625 0.         0.01953125]]

 ...

 [[0.953125   0.96875    0.5546875 ]
  [0.953125   0.96875    0.5546875 ]
  [0.953125   0.96875    0.5546875 ]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.7734375  0.17578125]]

 [[0.953125   0.96875    0.5546875 ]
  [0.953125   0.96875    0.5546875 ]
  [0.953125   0.96875    0.5546875 ]
  ...
  [0.97265625 0.77734375 0.18359375]
  [0.97265625 0.77734375 0.18359375]
  [0.9765625  0.7734375  0.17578125]]

 [[0.953125   0.96875    0.5546875 ]
  [0.953125   0.96875    0.5546875 ]
  [0.953125   0.96875    0.5546875 ]
  ...
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]
  [0.9765625  0.7734375  0.17578125]]]
[[[0.15625    0.04296875 0.32421875]
  [0.15625    0.04296875 0.32421875]
  [0.15625    0.04296875 0.32421875]
  ...
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]]

 [[0.1484375  0.046875   0.31640625]
  [0.15625    0.04296875 0.32421875]
  [0.15625    0.04296875 0.32421875]
  ...
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]]

 [[0.109375   0.046875   0.26171875]
  [0.12109375 0.046875   0.28125   ]
  [0.12890625 0.046875   0.2890625 ]
  ...
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]]

 ...

 [[0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.7734375  0.17578125]]

 [[0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.97265625 0.77734375 0.18359375]
  [0.9765625  0.7734375  0.17578125]]

 [[0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.97265625 0.77734375 0.18359375]
  [0.97265625 0.77734375 0.18359375]
  [0.9765625  0.7734375  0.17578125]]]
[[[0.05078125 0.03125    0.16015625]
  [0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  ...
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]]

 [[0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  [0.05078125 0.03125    0.16015625]
  ...
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]]

 [[0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  ...
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]]

 ...

 [[0.94140625 0.94140625 0.47265625]
  [0.94140625 0.94140625 0.47265625]
  [0.94140625 0.94140625 0.47265625]
  ...
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.81640625 0.23828125]]

 [[0.94140625 0.94140625 0.47265625]
  [0.94140625 0.94140625 0.47265625]
  [0.94140625 0.94140625 0.47265625]
  ...
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]]

 [[0.94140625 0.94140625 0.47265625]
  [0.94140625 0.94140625 0.47265625]
  [0.94140625 0.94140625 0.47265625]
  ...
  [0.9609375  0.83203125 0.26171875]
  [0.9609375  0.83203125 0.26171875]
  [0.96484375 0.82421875 0.25      ]]]
[[[0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  ...
  [0.         0.         0.015625  ]
  [0.         0.         0.015625  ]
  [0.         0.         0.015625  ]]

 [[0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  ...
  [0.         0.         0.015625  ]
  [0.         0.         0.015625  ]
  [0.         0.         0.015625  ]]

 [[0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  [0.05078125 0.03125    0.16015625]
  ...
  [0.         0.         0.015625  ]
  [0.         0.         0.015625  ]
  [0.         0.         0.015625  ]]

 ...

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.7734375  0.17578125]]

 [[0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.765625   0.1640625 ]]

 [[0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.9609375  0.5390625 ]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.765625   0.1640625 ]]]
[[[0.12890625 0.046875   0.2890625 ]
  [0.12890625 0.046875   0.2890625 ]
  [0.12890625 0.046875   0.2890625 ]
  ...
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 [[0.12890625 0.046875   0.2890625 ]
  [0.12890625 0.046875   0.2890625 ]
  [0.12890625 0.046875   0.2890625 ]
  ...
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 [[0.12890625 0.046875   0.2890625 ]
  [0.12890625 0.046875   0.2890625 ]
  [0.12890625 0.046875   0.2890625 ]
  ...
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 ...

 [[0.9453125  0.9453125  0.48828125]
  [0.9453125  0.9453125  0.48828125]
  [0.9453125  0.9453125  0.48828125]
  ...
  [0.97265625 0.77734375 0.18359375]
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]]

 [[0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]]

 [[0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]]]
[[[0.16796875 0.04296875 0.33984375]
  [0.16796875 0.04296875 0.33984375]
  [0.16796875 0.04296875 0.33984375]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.15625    0.04296875 0.32421875]
  [0.16015625 0.04296875 0.33203125]
  [0.16796875 0.04296875 0.33984375]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.09765625 0.046875   0.2421875 ]
  [0.1171875  0.046875   0.26953125]
  [0.13671875 0.046875   0.296875  ]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 ...

 [[0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  ...
  [0.953125   0.86328125 0.30859375]
  [0.953125   0.86328125 0.30859375]
  [0.95703125 0.85546875 0.296875  ]]]
[[[0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  ...
  [0.00390625 0.00390625 0.03125   ]
  [0.00390625 0.00390625 0.03125   ]
  [0.00390625 0.00390625 0.03125   ]]

 [[0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  [0.1484375  0.046875   0.31640625]
  ...
  [0.00390625 0.00390625 0.03125   ]
  [0.00390625 0.00390625 0.03125   ]
  [0.00390625 0.00390625 0.03125   ]]

 [[0.13671875 0.046875   0.296875  ]
  [0.13671875 0.046875   0.296875  ]
  [0.13671875 0.046875   0.296875  ]
  ...
  [0.00390625 0.00390625 0.03125   ]
  [0.00390625 0.00390625 0.03125   ]
  [0.00390625 0.00390625 0.03125   ]]

 ...

 [[0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]]

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]]

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87109375 0.32421875]]]
[[[0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.19140625 0.0390625  0.359375  ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.203125   0.0390625  0.37109375]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.12109375 0.046875   0.28125   ]
  [0.140625   0.046875   0.30859375]
  [0.16015625 0.04296875 0.33203125]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 ...

 [[0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  ...
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]]

 [[0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  ...
  [0.94921875 0.89453125 0.36328125]
  [0.94921875 0.89453125 0.36328125]
  [0.94921875 0.88671875 0.3515625 ]]

 [[0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  ...
  [0.9453125  0.8984375  0.37890625]
  [0.94921875 0.89453125 0.36328125]
  [0.94921875 0.88671875 0.3515625 ]]]
[[[0.09375    0.046875   0.234375  ]
  [0.09375    0.046875   0.234375  ]
  [0.09375    0.046875   0.234375  ]
  ...
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]]

 [[0.09375    0.046875   0.234375  ]
  [0.09375    0.046875   0.234375  ]
  [0.09375    0.046875   0.234375  ]
  ...
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]]

 [[0.08203125 0.04296875 0.21484375]
  [0.0859375  0.04296875 0.22265625]
  [0.0859375  0.04296875 0.22265625]
  ...
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]]

 ...

 [[0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  ...
  [0.9765625  0.7578125  0.15625   ]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.7578125  0.15625   ]]

 [[0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  ...
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.7578125  0.15625   ]]

 [[0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.7578125  0.15625   ]]]
[[[0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  ...
  [0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]]

 [[0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  ...
  [0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]]

 [[0.16796875 0.04296875 0.33984375]
  [0.17578125 0.04296875 0.34765625]
  [0.17578125 0.04296875 0.34765625]
  ...
  [0.33203125 0.05859375 0.42578125]
  [0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]]

 ...

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.953125   0.86328125 0.30859375]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.86328125 0.30859375]]

 [[0.94140625 0.93359375 0.45703125]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.86328125 0.30859375]]

 [[0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  ...
  [0.94921875 0.88671875 0.3515625 ]
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.86328125 0.30859375]]]
[[[0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  ...
  [0.0078125  0.0078125  0.046875  ]
  [0.0078125  0.0078125  0.046875  ]
  [0.0078125  0.0078125  0.046875  ]]

 [[0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  ...
  [0.0078125  0.0078125  0.046875  ]
  [0.0078125  0.0078125  0.046875  ]
  [0.0078125  0.0078125  0.046875  ]]

 [[0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  ...
  [0.0078125  0.0078125  0.046875  ]
  [0.0078125  0.0078125  0.046875  ]
  [0.0078125  0.0078125  0.046875  ]]

 ...

 [[0.45703125 0.10546875 0.4296875 ]
  [0.45703125 0.10546875 0.4296875 ]
  [0.45703125 0.10546875 0.4296875 ]
  ...
  [0.421875   0.09375    0.4296875 ]
  [0.421875   0.09375    0.4296875 ]
  [0.421875   0.09375    0.4296875 ]]

 [[0.45703125 0.10546875 0.4296875 ]
  [0.45703125 0.10546875 0.4296875 ]
  [0.45703125 0.10546875 0.4296875 ]
  ...
  [0.421875   0.09375    0.4296875 ]
  [0.421875   0.09375    0.4296875 ]
  [0.421875   0.09375    0.4296875 ]]

 [[0.46484375 0.109375   0.42578125]
  [0.45703125 0.10546875 0.4296875 ]
  [0.45703125 0.10546875 0.4296875 ]
  ...
  [0.42578125 0.09375    0.4296875 ]
  [0.42578125 0.09375    0.4296875 ]
  [0.421875   0.09375    0.4296875 ]]]
[[[0.3828125  0.078125   0.4296875 ]
  [0.37890625 0.07421875 0.4296875 ]
  [0.37890625 0.07421875 0.4296875 ]
  ...
  [0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]]

 [[0.390625   0.08203125 0.4296875 ]
  [0.390625   0.08203125 0.4296875 ]
  [0.3828125  0.078125   0.4296875 ]
  ...
  [0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]]

 [[0.40234375 0.0859375  0.4296875 ]
  [0.40234375 0.0859375  0.4296875 ]
  [0.39453125 0.08203125 0.4296875 ]
  ...
  [0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]
  [0.203125   0.0390625  0.37109375]]

 ...

 [[0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  ...
  [0.95703125 0.84765625 0.28515625]
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.84765625 0.28515625]]

 [[0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.953125   0.86328125 0.30859375]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  ...
  [0.953125   0.86328125 0.30859375]
  [0.953125   0.86328125 0.30859375]
  [0.953125   0.86328125 0.30859375]]]
[[[0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 ...

 [[0.9453125  0.9140625  0.41015625]
  [0.9453125  0.9140625  0.41015625]
  [0.9453125  0.9140625  0.41015625]
  ...
  [0.97265625 0.79296875 0.20703125]
  [0.97265625 0.79296875 0.20703125]
  [0.96875    0.80078125 0.21484375]]

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.97265625 0.79296875 0.20703125]
  [0.96875    0.80078125 0.21484375]
  [0.96875    0.80078125 0.21484375]]

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.97265625 0.79296875 0.20703125]
  [0.96875    0.80078125 0.21484375]
  [0.97265625 0.79296875 0.20703125]]]
[[[0.140625   0.046875   0.30859375]
  [0.140625   0.046875   0.30859375]
  [0.140625   0.046875   0.30859375]
  ...
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]]

 [[0.140625   0.046875   0.30859375]
  [0.140625   0.046875   0.30859375]
  [0.140625   0.046875   0.30859375]
  ...
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]
  [0.02734375 0.01953125 0.10546875]]

 [[0.109375   0.046875   0.26171875]
  [0.1171875  0.046875   0.26953125]
  [0.1171875  0.046875   0.26953125]
  ...
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]
  [0.0234375  0.015625   0.09765625]]

 ...

 [[0.9453125  0.9140625  0.41015625]
  [0.9453125  0.9140625  0.41015625]
  [0.9453125  0.9140625  0.41015625]
  ...
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]]

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.97265625 0.79296875 0.20703125]
  [0.97265625 0.79296875 0.20703125]
  [0.97265625 0.78515625 0.1953125 ]]

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.96875    0.80078125 0.21484375]
  [0.96875    0.80078125 0.21484375]
  [0.97265625 0.78515625 0.1953125 ]]]
[[[0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]
  ...
  [0.015625   0.01171875 0.078125  ]
  [0.015625   0.01171875 0.078125  ]
  [0.015625   0.01171875 0.078125  ]]

 [[0.33203125 0.05859375 0.42578125]
  [0.33984375 0.0625     0.4296875 ]
  [0.33984375 0.0625     0.4296875 ]
  ...
  [0.015625   0.01171875 0.078125  ]
  [0.015625   0.01171875 0.078125  ]
  [0.015625   0.01171875 0.078125  ]]

 [[0.2578125  0.0390625  0.40625   ]
  [0.27734375 0.04296875 0.4140625 ]
  [0.27734375 0.04296875 0.4140625 ]
  ...
  [0.015625   0.01171875 0.078125  ]
  [0.015625   0.01171875 0.078125  ]
  [0.015625   0.01171875 0.078125  ]]

 ...

 [[0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  ...
  [0.9609375  0.83203125 0.26171875]
  [0.9609375  0.83203125 0.26171875]
  [0.9609375  0.83203125 0.26171875]]

 [[0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  ...
  [0.9609375  0.83984375 0.2734375 ]
  [0.9609375  0.83984375 0.2734375 ]
  [0.9609375  0.83203125 0.26171875]]

 [[0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87890625 0.3359375 ]
  [0.953125   0.87109375 0.32421875]
  ...
  [0.95703125 0.84765625 0.28515625]
  [0.95703125 0.84765625 0.28515625]
  [0.9609375  0.83984375 0.2734375 ]]]
[[[0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 [[0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 [[0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 ...

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]]

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]]

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]]]
[[[0.734375   0.21484375 0.328125  ]
  [0.734375   0.21484375 0.328125  ]
  [0.734375   0.21484375 0.328125  ]
  ...
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]]

 [[0.734375   0.21484375 0.328125  ]
  [0.734375   0.21484375 0.328125  ]
  [0.734375   0.21484375 0.328125  ]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 [[0.59375    0.15234375 0.3984375 ]
  [0.6015625  0.15625    0.39453125]
  [0.6015625  0.15625    0.39453125]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 ...

 [[0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.96875    0.80078125 0.21484375]
  [0.96875    0.80859375 0.2265625 ]
  [0.96875    0.80859375 0.2265625 ]]

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.96875    0.80859375 0.2265625 ]
  [0.96875    0.80859375 0.2265625 ]
  [0.96875    0.80859375 0.2265625 ]]

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]
  [0.96875    0.80859375 0.2265625 ]]]
[[[0.23046875 0.03515625 0.390625  ]
  [0.23046875 0.03515625 0.390625  ]
  [0.23046875 0.03515625 0.390625  ]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.22265625 0.03515625 0.38671875]
  [0.22265625 0.03515625 0.38671875]
  [0.23046875 0.03515625 0.390625  ]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 [[0.18359375 0.0390625  0.35546875]
  [0.1953125  0.0390625  0.3671875 ]
  [0.2109375  0.03515625 0.37890625]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]]

 ...

 [[0.95703125 0.97265625 0.5703125 ]
  [0.95703125 0.97265625 0.5703125 ]
  [0.95703125 0.97265625 0.5703125 ]
  ...
  [0.96875    0.80859375 0.2265625 ]
  [0.96484375 0.81640625 0.23828125]
  [0.96875    0.80859375 0.2265625 ]]

 [[0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.96875    0.80859375 0.2265625 ]
  [0.96484375 0.81640625 0.23828125]
  [0.96875    0.80859375 0.2265625 ]]

 [[0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]
  [0.96875    0.80859375 0.2265625 ]]]
[[[0.28515625 0.04296875 0.4140625 ]
  [0.28515625 0.04296875 0.4140625 ]
  [0.28515625 0.04296875 0.4140625 ]
  ...
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 [[0.28515625 0.04296875 0.4140625 ]
  [0.28515625 0.04296875 0.4140625 ]
  [0.28515625 0.04296875 0.4140625 ]
  ...
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 [[0.2421875  0.03515625 0.3984375 ]
  [0.2421875  0.03515625 0.3984375 ]
  [0.2421875  0.03515625 0.3984375 ]
  ...
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 ...

 [[0.96875    0.98046875 0.6015625 ]
  [0.96875    0.98046875 0.6015625 ]
  [0.96875    0.98046875 0.6015625 ]
  ...
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]
  [0.94921875 0.88671875 0.3515625 ]]

 [[0.96875    0.98046875 0.6015625 ]
  [0.96875    0.98046875 0.6015625 ]
  [0.96875    0.98046875 0.6015625 ]
  ...
  [0.94921875 0.89453125 0.36328125]
  [0.94921875 0.89453125 0.36328125]
  [0.94921875 0.88671875 0.3515625 ]]

 [[0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  [0.97265625 0.984375   0.61328125]
  ...
  [0.94921875 0.89453125 0.36328125]
  [0.94921875 0.89453125 0.36328125]
  [0.94921875 0.88671875 0.3515625 ]]]
[[[0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  ...
  [0.0703125  0.0390625  0.1953125 ]
  [0.0625     0.03515625 0.17578125]
  [0.0546875  0.03515625 0.16796875]]

 [[0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  [0.06640625 0.0390625  0.1875    ]
  ...
  [0.06640625 0.0390625  0.1875    ]
  [0.0625     0.03515625 0.17578125]
  [0.0625     0.03515625 0.17578125]]

 [[0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  ...
  [0.06640625 0.0390625  0.1875    ]
  [0.0625     0.03515625 0.17578125]
  [0.0625     0.03515625 0.17578125]]

 ...

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.96875    0.80859375 0.2265625 ]
  [0.96484375 0.81640625 0.23828125]
  [0.96875    0.80859375 0.2265625 ]]

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]
  [0.96875    0.80859375 0.2265625 ]]

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.81640625 0.23828125]
  [0.96875    0.80859375 0.2265625 ]]]
[[[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 [[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 [[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 ...

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]]

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]
  [0.97265625 0.78515625 0.1953125 ]]

 [[0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  [0.94140625 0.93359375 0.45703125]
  ...
  [0.97265625 0.79296875 0.20703125]
  [0.97265625 0.79296875 0.20703125]
  [0.97265625 0.78515625 0.1953125 ]]]
[[[0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  ...
  [0.09765625 0.046875   0.2421875 ]
  [0.09765625 0.046875   0.2421875 ]
  [0.09765625 0.046875   0.2421875 ]]

 [[0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  ...
  [0.09765625 0.046875   0.2421875 ]
  [0.09765625 0.046875   0.2421875 ]
  [0.09765625 0.046875   0.2421875 ]]

 [[0.17578125 0.04296875 0.34765625]
  [0.17578125 0.04296875 0.34765625]
  [0.17578125 0.04296875 0.34765625]
  ...
  [0.09765625 0.046875   0.2421875 ]
  [0.09765625 0.046875   0.2421875 ]
  [0.09765625 0.046875   0.2421875 ]]

 ...

 [[0.9453125  0.8984375  0.37890625]
  [0.9453125  0.8984375  0.37890625]
  [0.9453125  0.8984375  0.37890625]
  ...
  [0.9765625  0.7578125  0.15625   ]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]]

 [[0.9453125  0.90625    0.39453125]
  [0.9453125  0.8984375  0.37890625]
  [0.9453125  0.8984375  0.37890625]
  ...
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.7578125  0.15625   ]]

 [[0.9453125  0.90625    0.39453125]
  [0.9453125  0.90625    0.39453125]
  [0.9453125  0.90625    0.39453125]
  ...
  [0.9765625  0.7734375  0.17578125]
  [0.9765625  0.765625   0.1640625 ]
  [0.9765625  0.7578125  0.15625   ]]]
[[[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.00390625 0.00390625 0.0234375 ]
  [0.00390625 0.00390625 0.0234375 ]
  [0.00390625 0.00390625 0.0234375 ]]

 [[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.00390625 0.00390625 0.0234375 ]
  [0.00390625 0.00390625 0.0234375 ]
  [0.00390625 0.00390625 0.0234375 ]]

 [[0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  ...
  [0.00390625 0.00390625 0.0234375 ]
  [0.00390625 0.00390625 0.0234375 ]
  [0.00390625 0.00390625 0.0234375 ]]

 ...

 [[0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.94921875 0.95703125 0.5234375 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.953125   0.86328125 0.30859375]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.953125   0.86328125 0.30859375]
  [0.953125   0.86328125 0.30859375]
  [0.95703125 0.85546875 0.296875  ]]]
[[[0.12109375 0.046875   0.28125   ]
  [0.12109375 0.046875   0.28125   ]
  [0.12109375 0.046875   0.28125   ]
  ...
  [0.0390625  0.02734375 0.1328125 ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 [[0.12109375 0.046875   0.28125   ]
  [0.12109375 0.046875   0.28125   ]
  [0.12109375 0.046875   0.28125   ]
  ...
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]
  [0.03125    0.01953125 0.11328125]]

 [[0.10546875 0.046875   0.25390625]
  [0.109375   0.046875   0.26171875]
  [0.109375   0.046875   0.26171875]
  ...
  [0.01953125 0.015625   0.08984375]
  [0.01953125 0.015625   0.08984375]
  [0.0234375  0.015625   0.09765625]]

 ...

 [[0.9453125  0.9453125  0.48828125]
  [0.9453125  0.9453125  0.48828125]
  [0.9453125  0.9453125  0.48828125]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.953125   0.86328125 0.30859375]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.9453125  0.9453125  0.48828125]
  [0.9453125  0.9453125  0.48828125]
  [0.9453125  0.9453125  0.48828125]
  ...
  [0.953125   0.86328125 0.30859375]
  [0.953125   0.86328125 0.30859375]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  ...
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.87109375 0.32421875]
  [0.953125   0.86328125 0.30859375]]]
[[[0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  ...
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]]

 [[0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  ...
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]]

 [[0.0625     0.03515625 0.17578125]
  [0.0625     0.03515625 0.17578125]
  [0.0625     0.03515625 0.17578125]
  ...
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]
  [0.0078125  0.0078125  0.0546875 ]]

 ...

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.95703125 0.84765625 0.28515625]
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.84765625 0.28515625]]

 [[0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.9609375  0.5390625 ]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]]

 [[0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.9609375  0.5390625 ]
  ...
  [0.953125   0.86328125 0.30859375]
  [0.953125   0.86328125 0.30859375]
  [0.95703125 0.85546875 0.296875  ]]]
[[[0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  ...
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]]

 [[0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  ...
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]
  [0.046875   0.03125    0.1484375 ]]

 [[0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  [0.0546875  0.03515625 0.16796875]
  ...
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]
  [0.04296875 0.02734375 0.140625  ]]

 ...

 [[0.95703125 0.97265625 0.5703125 ]
  [0.95703125 0.97265625 0.5703125 ]
  [0.95703125 0.97265625 0.5703125 ]
  ...
  [0.9609375  0.83984375 0.2734375 ]
  [0.95703125 0.84765625 0.28515625]
  [0.95703125 0.84765625 0.28515625]]

 [[0.9609375  0.9765625  0.5859375 ]
  [0.95703125 0.97265625 0.5703125 ]
  [0.95703125 0.97265625 0.5703125 ]
  ...
  [0.95703125 0.84765625 0.28515625]
  [0.95703125 0.84765625 0.28515625]
  [0.95703125 0.84765625 0.28515625]]

 [[0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  [0.9609375  0.9765625  0.5859375 ]
  ...
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.85546875 0.296875  ]
  [0.95703125 0.84765625 0.28515625]]]
[[[0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  ...
  [0.2890625  0.046875   0.41796875]
  [0.296875   0.046875   0.41796875]
  [0.296875   0.046875   0.41796875]]

 [[0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  ...
  [0.2890625  0.046875   0.41796875]
  [0.296875   0.046875   0.41796875]
  [0.296875   0.046875   0.41796875]]

 [[0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  [0.1953125  0.0390625  0.3671875 ]
  ...
  [0.2890625  0.046875   0.41796875]
  [0.296875   0.046875   0.41796875]
  [0.296875   0.046875   0.41796875]]

 ...

 [[0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  [0.94140625 0.921875   0.42578125]
  ...
  [0.96875    0.80859375 0.2265625 ]
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]]

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]
  [0.96484375 0.81640625 0.23828125]]

 [[0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  [0.94140625 0.92578125 0.44140625]
  ...
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.82421875 0.25      ]
  [0.96484375 0.81640625 0.23828125]]]
[[[0.23046875 0.03515625 0.390625  ]
  [0.23046875 0.03515625 0.390625  ]
  [0.23046875 0.03515625 0.390625  ]
  ...
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]]

 [[0.23046875 0.03515625 0.390625  ]
  [0.23046875 0.03515625 0.390625  ]
  [0.23046875 0.03515625 0.390625  ]
  ...
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]]

 [[0.23046875 0.03515625 0.390625  ]
  [0.23046875 0.03515625 0.390625  ]
  [0.23828125 0.03515625 0.39453125]
  ...
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]
  [0.03515625 0.0234375  0.12109375]]

 ...

 [[0.9453125  0.953125   0.5078125 ]
  [0.9453125  0.953125   0.5078125 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.9765625  0.75       0.1484375 ]
  [0.9765625  0.7578125  0.15625   ]
  [0.9765625  0.75       0.1484375 ]]

 [[0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.9765625  0.75       0.1484375 ]
  [0.9765625  0.7578125  0.15625   ]
  [0.9765625  0.75       0.1484375 ]]

 [[0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.9609375  0.5390625 ]
  [0.94921875 0.95703125 0.5234375 ]
  ...
  [0.9765625  0.7578125  0.15625   ]
  [0.9765625  0.7578125  0.15625   ]
  [0.9765625  0.75       0.1484375 ]]]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 278, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 137, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 457194) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:42:12
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 457194)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:42:43.925961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:42:44.008734: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:42:44.392475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:42:44.392513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:42:44.392517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 278, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 137, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 457835) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:42:57
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 457835)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:52:33.573656: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:52:33.656738: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:52:34.043179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:52:34.043217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:52:34.043221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 458965) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:52:46
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 458965)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:56:06.002109: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:56:06.106800: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:56:06.528991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:56:06.529026: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:56:06.529030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 459853) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:56:18
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 459853)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 13:57:57.886983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 13:57:57.996472: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 13:57:58.384426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:57:58.384460: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 13:57:58.384465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 460556) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_13:58:10
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 460556)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 15:05:13.153447: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:05:13.237039: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:05:13.623322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:05:13.623356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:05:13.623360: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 464371) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:05:26
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 464371)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 15:12:10.289639: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:12:10.372954: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:12:10.756966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:12:10.757004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:12:10.757007: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 290, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 166, in __call__
    sample['left'] = F.adjust_contrast(sample['left'], contrast_factor)
  File "/home/godeta/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py", line 888, in adjust_contrast
    return F_pil.adjust_contrast(img, contrast_factor)
  File "/home/godeta/.local/lib/python3.9/site-packages/torchvision/transforms/functional_pil.py", line 82, in adjust_contrast
    raise TypeError(f"img should be PIL Image. Got {type(img)}")
TypeError: img should be PIL Image. Got <class 'numpy.ndarray'>

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 465396) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:12:23
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 465396)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 15:16:39.153043: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:16:39.253321: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:16:39.663906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:16:39.663960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:16:39.663964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 466161) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:16:52
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 466161)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 15:24:33.174305: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:24:33.257010: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:24:33.642361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:24:33.642400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:/usr/local/lib/python3.9/dist-packages/tensorrt/
2023-02-28 15:24:33.642403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 467510) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:24:46
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 467510)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 15:29:08.431090: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:29:08.513117: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:29:08.893496: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:29:08.893529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:29:08.893533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 468245) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:29:21
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 468245)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
3600 3600 3600
=> 3600 training samples found in the training set
2023-02-28 15:30:23.346324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:30:23.428880: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:30:23.811075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:30:23.811113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:30:23.811116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 468890) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:30:36
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 468890)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-02-28 15:37:49.482981: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:37:49.564125: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:37:49.946629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:37:49.946665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:37:49.946669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 93, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 469618) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:38:02
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 469618)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-02-28 15:41:06.252564: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-02-28 15:41:06.341988: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-02-28 15:41:06.725485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:41:06.725521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-02-28 15:41:06.725524: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 93, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3569) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-28_15:41:18
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3569)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 09:55:26.865216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 09:55:26.953278: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 09:55:27.331230: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 09:55:27.331264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 09:55:27.331267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 93, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 8005) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_09:55:39
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 8005)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 10:05:32.594396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 10:05:32.676366: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 10:05:33.037498: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:05:33.037533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:05:33.037536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 96, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 279, in __call__
    sample = ToPILImage()(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 138, in __call__
    sample['right'] = Image.fromarray(sample['right'].astype('uint8'))
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2949, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2876, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 2822, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/godeta/.local/lib/python3.9/site-packages/PIL/Image.py", line 827, in frombytes
    d.setimage(self.im)
ValueError: tile cannot extend outside image

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 9408) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_10:05:45
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 9408)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 12, in <module>
    from dataloader.stereo.datasets import build_dataset
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 98
    return sample
    ^
IndentationError: expected an indented block
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 10624) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_10:16:53
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 10624)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 10:17:37.587115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 10:17:37.669681: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 10:17:38.048307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:17:38.048345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:17:38.048349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
terminate called without an active exception
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
terminate called without an active exception
terminate called without an active exception
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
terminate called without an active exception
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
terminate called without an active exception
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
We get a new item
I'm in READ IMAGE (940, 1151, 3)
I'm in READ IMAGE (477, 579, 3)
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f6ab85d8c10>
Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1466, in __del__
    self._shutdown_workers()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1430, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.9/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/usr/lib/python3.9/multiprocessing/connection.py", line 936, in wait
    ready = selector.select(timeout)
  File "/usr/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 10976) is killed by signal: Aborted. 
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 407, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 127, in forward
    feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 65, in extract_feature
    concat = torch.cat((img0, img1), dim=0)  # [2B, C, H, W]
RuntimeError: Sizes of tensors must match except in dimension 0. Expected size 940 but got size 477 for tensor number 1 in the list.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 10841) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_10:17:50
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 10841)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 10:48:31.500947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 10:48:31.582280: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 10:48:31.941305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:48:31.941338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:48:31.941341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 407, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 127, in forward
    feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 65, in extract_feature
    concat = torch.cat((img0, img1), dim=0)  # [2B, C, H, W]
RuntimeError: Sizes of tensors must match except in dimension 0. Expected size 475 but got size 950 for tensor number 1 in the list.
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 17311) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_10:48:49
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 17311)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 10:51:12.661470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 10:51:12.743418: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 10:51:13.105541: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:51:13.105578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:51:13.105582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 96, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 90, in __call__
    sample['disp'] = np.lib.pad(sample['disp'],
  File "<__array_function__ internals>", line 180, in pad
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 743, in pad
    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 518, in _as_pairs
    return np.broadcast_to(x, (ndim, 2)).tolist()
  File "<__array_function__ internals>", line 180, in broadcast_to
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 412, in broadcast_to
    return _broadcast_to(array, shape, subok=subok, readonly=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 348, in _broadcast_to
    it = np.nditer(
ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 17929) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_10:51:25
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 17929)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 10:55:10.208947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 10:55:10.292212: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 10:55:10.651491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:55:10.651525: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:55:10.651528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
cv2.error: Caught error in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 91, in __getitem__
    sample['left'] = cv2.resize(sample['left'], sample['right'].shape, interpolation=cv2.INTER_LINEAR)
cv2.error: OpenCV(4.7.0) :-1: error: (-5:Bad argument) in function 'resize'
> Overload resolution failed:
>  - Can't parse 'dsize'. Expected sequence length 2, got 3
>  - Can't parse 'dsize'. Expected sequence length 2, got 3


ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 18847) of binary: /usr/bin/python3.9
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 10:57:03.694631: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 10:57:03.777428: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 10:57:04.167523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:57:04.167559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 10:57:04.167563: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 61, in fetch
    return self.collate_fn(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py", line 128, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py", line 128, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py", line 120, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py", line 162, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
RuntimeError: Trying to resize storage that is not resizable

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 19568) of binary: /usr/bin/python3.9
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:9989 (errno: 98 - Address already in use).
[W socket.cpp:426] [c10d] The server socket has failed to bind to 0.0.0.0:9989 (errno: 98 - Address already in use).
[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_10:57:16
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 19568)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:9989 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:9989 (errno: 98 - Address already in use).
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 11:00:42.377797: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 11:00:42.460456: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 11:00:42.819664: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:00:42.819698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:00:42.819701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 94, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 90, in __call__
    sample['disp'] = np.lib.pad(sample['disp'],
  File "<__array_function__ internals>", line 180, in pad
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 743, in pad
    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 518, in _as_pairs
    return np.broadcast_to(x, (ndim, 2)).tolist()
  File "<__array_function__ internals>", line 180, in broadcast_to
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 412, in broadcast_to
    return _broadcast_to(array, shape, subok=subok, readonly=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 348, in _broadcast_to
    it = np.nditer(
ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 20369) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_11:00:55
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 20369)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 11:02:18.469815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 11:02:18.551884: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 11:02:18.915604: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:02:18.915639: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:02:18.915642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 95, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 90, in __call__
    sample['disp'] = np.lib.pad(sample['disp'],
  File "<__array_function__ internals>", line 180, in pad
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 743, in pad
    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 518, in _as_pairs
    return np.broadcast_to(x, (ndim, 2)).tolist()
  File "<__array_function__ internals>", line 180, in broadcast_to
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 412, in broadcast_to
    return _broadcast_to(array, shape, subok=subok, readonly=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 348, in _broadcast_to
    it = np.nditer(
ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 20977) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_11:02:31
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 20977)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 11:04:15.885559: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 11:04:15.978565: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 11:04:16.379397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:04:16.379432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:04:16.379436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 96, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 90, in __call__
    sample['disp'] = np.lib.pad(sample['disp'],
  File "<__array_function__ internals>", line 180, in pad
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 743, in pad
    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 518, in _as_pairs
    return np.broadcast_to(x, (ndim, 2)).tolist()
  File "<__array_function__ internals>", line 180, in broadcast_to
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 412, in broadcast_to
    return _broadcast_to(array, shape, subok=subok, readonly=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 348, in _broadcast_to
    it = np.nditer(
ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 21850) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_11:04:28
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 21850)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 11:05:35.518176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 11:05:35.601926: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 11:05:35.968275: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:05:35.968309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 11:05:35.968312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 96, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 90, in __call__
    sample['disp'] = np.lib.pad(sample['disp'],
  File "<__array_function__ internals>", line 180, in pad
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 743, in pad
    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/arraypad.py", line 518, in _as_pairs
    return np.broadcast_to(x, (ndim, 2)).tolist()
  File "<__array_function__ internals>", line 180, in broadcast_to
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 412, in broadcast_to
    return _broadcast_to(array, shape, subok=subok, readonly=True)
  File "/usr/local/lib/python3.9/dist-packages/numpy/lib/stride_tricks.py", line 348, in _broadcast_to
    it = np.nditer(
ValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 22457) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_11:05:48
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 22457)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 13:40:45.029661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 13:40:45.111404: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 13:40:45.490253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:40:45.490289: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:40:45.490293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
UnboundLocalError: Caught UnboundLocalError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 74, in __getitem__
    sample['disp'] = read_disp(sample_path['disp'],
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/utils/file_io.py", line 62, in read_disp
    return im  # [H, W]
UnboundLocalError: local variable 'im' referenced before assignment

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 35878) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_13:40:58
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 35878)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 13:42:48.865180: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 13:42:48.946439: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 13:42:49.307895: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:42:49.307929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:42:49.307932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 397, in main
    for i, sample in enumerate(train_loader):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 628, in __next__
    data = self._next_data()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1333, in _next_data
    return self._process_data(data)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _process_data
    data.reraise()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 302, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 58, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/datasets.py", line 99, in __getitem__
    sample = self.transform(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 16, in __call__
    sample = t(sample)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/dataloader/stereo/transforms.py", line 312, in __call__
    h, w, l = sample['disp'].shape
ValueError: not enough values to unpack (expected 3, got 2)

ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 36442) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_13:43:01
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 36442)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 13:43:40.353789: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 13:43:40.436626: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 13:43:40.813844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:43:40.813879: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:43:40.813882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(940, 1151)
(384, 768, 3) (384, 768, 3)
We get a new item
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm here in file_io (940, 1151, 3)
The shapes are :  (475, 605, 3) (950, 1210, 3) (940, 1151)
(384, 768, 3) (384, 768, 3)
terminate called without an active exception
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7d00ee8c10>
Traceback (most recent call last):
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1466, in __del__
    self._shutdown_workers()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1430, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.9/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/usr/lib/python3.9/multiprocessing/connection.py", line 936, in wait
    ready = selector.select(timeout)
  File "/usr/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 37020) is killed by signal: Aborted. 
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 407, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 331.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 36941) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_13:44:28
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 36941)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 13:47:33.540627: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 13:47:33.623737: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 13:47:33.984474: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:47:33.984507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 13:47:33.984510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 407, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 329.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 37692) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_13:47:51
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 37692)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 14:03:38.809528: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 14:03:38.891833: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 14:03:39.272634: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 14:03:39.272670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 14:03:39.272674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 407, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 78, in single_head_split_window_attention
    k = torch.roll(k, shifts=(-shift_size_h, -shift_size_w), dims=(1, 2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 15.75 GiB total capacity; 14.18 GiB already allocated; 37.12 MiB free; 14.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 39479) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_14:03:56
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 39479)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=32, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
        main(args)main(args)

  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
      File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
    main(args)
RuntimeError:   File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 43204 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 43205) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-03-01_15:00:59
  host      : laptop-493
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 43206)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-03-01_15:00:59
  host      : laptop-493
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 43207)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-03-01_15:00:59
  host      : laptop-493
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 43208)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-03-01_15:00:59
  host      : laptop-493
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 43209)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-03-01_15:00:59
  host      : laptop-493
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 43210)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-03-01_15:00:59
  host      : laptop-493
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 43211)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:00:59
  host      : laptop-493
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 43205)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 215, in launch_agent
    spec = WorkerSpec(
  File "<string>", line 15, in __init__
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 87, in __post_init__
    assert self.local_world_size > 0
AssertionError
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=32, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 43360 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 43361) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:01:50
  host      : laptop-493
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 43361)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=32, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 15:02:20.655641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 15:02:20.737783: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 15:02:21.115381: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:02:21.115418: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:02:21.115422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
We get a new item
(384, 768, 3) (384, 768, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 407, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 127, in forward
    feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 66, in extract_feature
    features = self.backbone(concat)  # list of [2B, C, H, W], resolution from high to low
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/backbone.py", line 107, in forward
    x = self.layer2(x)  # 1/4
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/backbone.py", line 30, in forward
    y = self.relu(self.norm1(self.conv1(y)))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 15.75 GiB total capacity; 14.05 GiB already allocated; 177.12 MiB free; 14.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 43457) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:02:43
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 43457)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=32, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=False, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
UniMatch(
  (backbone): CNNEncoder(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (relu1): ReLU(inplace=True)
    (layer1): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
      (1): ResidualBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer2): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))
          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (layer3): Sequential(
      (0): ResidualBlock(
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (downsample): Sequential(
          (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))
          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        )
      )
      (1): ResidualBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (relu): ReLU(inplace=True)
        (norm1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (norm2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
    (trident_conv): MultiScaleTridentConv()
  )
  (transformer): FeatureTransformer(
    (layers): ModuleList(
      (0): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (1): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (2): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (3): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (4): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (5): TransformerBlock(
        (self_attn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (cross_attn_ffn): TransformerLayer(
          (q_proj): Linear(in_features=128, out_features=128, bias=False)
          (k_proj): Linear(in_features=128, out_features=128, bias=False)
          (v_proj): Linear(in_features=128, out_features=128, bias=False)
          (merge): Linear(in_features=128, out_features=128, bias=False)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (0): Linear(in_features=256, out_features=1024, bias=False)
            (1): GELU(approximate='none')
            (2): Linear(in_features=1024, out_features=128, bias=False)
          )
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (feature_flow_attn): SelfAttnPropagation(
    (q_proj): Linear(in_features=128, out_features=128, bias=True)
    (k_proj): Linear(in_features=128, out_features=128, bias=True)
  )
  (refine_proj): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
  (refine): BasicUpdateBlock(
    (encoder): BasicMotionEncoder(
      (convc1): Conv2d(81, 256, kernel_size=(1, 1), stride=(1, 1))
      (convc2): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (convf1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
      (convf2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv): Conv2d(256, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
    (gru): SepConvGRU(
      (convz1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convr1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convq1): Conv2d(384, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))
      (convz2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convr2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
      (convq2): Conv2d(384, 128, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
    )
    (flow_head): FlowHead(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU(inplace=True)
    )
    (mask): Sequential(
      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU(inplace=True)
      (2): Conv2d(256, 144, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 371, in main
    lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 1656, in __init__
    super(OneCycleLR, self).__init__(optimizer, last_epoch, verbose)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py", line 42, in __init__
    raise KeyError("param 'initial_lr' is not specified "
KeyError: "param 'initial_lr' is not specified in param_groups[0] when resuming an optimizer"
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 46987) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:35:31
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 46987)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=1, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7319721
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 212, in main
    model_without_ddp.load_state_dict(checkpoint['model'], strict=args.strict_resume)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1671, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for UniMatch:
	size mismatch for refine.mask.2.weight: copying a param with shape torch.Size([144, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([9, 256, 1, 1]).
	size mismatch for refine.mask.2.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([9]).
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 48085) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:47:01
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 48085)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 15:48:09.008023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 15:48:09.090990: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 15:48:09.474408: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:48:09.474448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:48:09.474452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
(384, 768, 3) (384, 768, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 407, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 329.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 48177) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:48:27
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 48177)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=2, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7326660
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 212, in main
    model_without_ddp.load_state_dict(checkpoint['model'], strict=args.strict_resume)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1671, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for UniMatch:
	size mismatch for refine.mask.2.weight: copying a param with shape torch.Size([144, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([36, 256, 1, 1]).
	size mismatch for refine.mask.2.bias: copying a param with shape torch.Size([144]) from checkpoint, the shape in current model is torch.Size([36]).
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 48855) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:49:36
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 48855)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 15:51:20.448433: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 15:51:20.529701: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 15:51:20.906732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:51:20.906768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:51:20.906772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 329.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 49132) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:51:38
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 49132)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 15:54:09.819089: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 15:54:09.902025: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 15:54:10.284506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:54:10.284541: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:54:10.284545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 331.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 50268) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:54:27
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 50268)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 11, in <module>
    from numba import cuda
  File "/usr/local/lib/python3.9/dist-packages/numba/__init__.py", line 200, in <module>
    _ensure_critical_deps()
  File "/usr/local/lib/python3.9/dist-packages/numba/__init__.py", line 140, in _ensure_critical_deps
    raise ImportError("Numba needs NumPy 1.21 or less")
ImportError: Numba needs NumPy 1.21 or less
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 50981) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_15:55:46
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 50981)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=1000, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 15:59:45.749605: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 15:59:45.840972: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 15:59:46.226170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:59:46.226207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 15:59:46.226210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 331.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 51375) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_16:00:03
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 51375)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 16:22:24.936664: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 16:22:25.030386: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 16:22:25.434966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 16:22:25.435002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 16:22:25.435005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 329.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 53686) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_16:22:43
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 53686)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-01 16:29:25.554251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-01 16:29:25.635672: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-01 16:29:25.994244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 16:29:25.994278: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-01 16:29:25.994281: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 329.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 54605) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-01_16:29:43
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 54605)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 11:04:54.947052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 11:04:55.144238: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 11:04:55.802976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:04:55.803023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:04:55.803027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.77 GiB already allocated; 331.12 MiB free; 13.92 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 6502) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-02_11:05:17
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 6502)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 11:12:13.081983: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 11:12:13.184576: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 11:12:13.608625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:12:13.608658: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:12:13.608661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 78, in single_head_split_window_attention
    k = torch.roll(k, shifts=(-shift_size_h, -shift_size_w), dims=(1, 2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 15.75 GiB total capacity; 14.18 GiB already allocated; 37.12 MiB free; 14.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 7659) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-02_11:12:31
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 7659)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 11:13:22.743068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 11:13:22.827823: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 11:13:23.203252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:13:23.203289: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:13:23.203292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 78, in single_head_split_window_attention
    k = torch.roll(k, shifts=(-shift_size_h, -shift_size_w), dims=(1, 2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 15.75 GiB total capacity; 14.18 GiB already allocated; 37.12 MiB free; 14.21 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 8331) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-02_11:13:40
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 8331)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 11:14:25.513075: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 11:14:25.595368: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 11:14:25.976009: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:14:25.976044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:14:25.976048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(399)main()
-> torch.cuda.empty_cache()
(Pdb) {'disp': tensor([[[ 18.2223,  18.2223,  18.2223,  ...,  14.0809,  14.0809,  12.7004],
         [ 18.2223,  18.2223,  18.2223,  ...,  14.0809,  12.8324,  12.7004],
         [ 18.2223,  18.2223,  18.2223,  ...,  14.3318,  14.0809,  12.7004],
         ...,
         [116.2362, 116.2362, 116.6655,  ...,  67.9195,  67.9195,  67.9195],
         [116.2362, 116.2362, 116.6655,  ...,  67.9195,  67.9195,  67.9195],
         [116.2362, 116.2362, 116.6655,  ...,  67.9195,  67.9195,  67.9195]],

        [[  8.4503,   8.6030,  10.0151,  ...,  13.1448,  13.1448,  13.1448],
         [  8.4503,   8.4503,   8.4503,  ...,  13.1448,  13.1448,  13.1448],
         [  8.4503,   8.4503,   8.7048,  ...,  13.1448,  13.1448,  13.1448],
         ...,
         [ 57.5869,  57.5869,  57.5869,  ...,  84.8156,  84.8156,  84.8156],
         [ 58.8388,  58.7167,  57.5869,  ...,  84.9404,  84.8156,  84.8156],
         [ 58.8388,  58.8388,  58.8388,  ...,  85.4415,  85.4415,  84.8589]],

        [[ 98.4309,  98.4309,  98.4309,  ...,  81.8976,  81.8976,  81.8976],
         [ 98.4309,  98.4309,  98.4309,  ...,  81.8976,  81.8873,  80.5540],
         [ 98.4309,  98.4309,  98.4309,  ...,  80.3596,  80.3596,  80.3596],
         ...,
         [ 23.8387,  23.8387,  23.8387,  ...,   8.0744,   8.0667,   7.0667],
         [ 23.8387,  23.8387,  23.8387,  ...,   9.3974,   8.0744,   8.0744],
         [ 23.8387,  23.8387,  23.8387,  ...,  10.3814,  10.3762,   9.7096]],

        ...,

        [[ 49.3333,  49.3333,  49.3333,  ...,  14.0000,  14.0000,  14.0000],
         [ 49.3333,  48.3333,  48.3333,  ...,  15.3333,  14.0000,  14.0000],
         [ 48.3333,  48.3333,  48.3333,  ...,  15.3333,  14.0000,  14.0000],
         ...,
         [ 61.3333,  61.3333,  61.3333,  ...,  73.6667,  73.6667,  73.6667],
         [ 62.6667,  62.6667,  62.6667,  ...,  73.6667,  73.6667,  73.6667],
         [ 62.6667,  62.6667,  62.6667,  ...,  73.6667,  73.6667,  73.6667]],

        [[ 48.4910,  48.4910,  48.1178,  ...,  14.4622,  14.4622,  14.4622],
         [ 48.4910,  48.4910,  48.4910,  ...,  14.4622,  14.4622,  14.4622],
         [ 48.4910,  48.4910,  48.4910,  ...,  14.4622,  14.4622,  14.4622],
         ...,
         [ 83.6540,  83.6540,  83.6540,  ...,  58.9832,  58.9832,  58.9832],
         [ 83.6540,  83.6540,  83.6540,  ...,  58.9832,  58.9832,  58.9832],
         [ 83.6540,  83.6540,  83.6540,  ...,  58.9832,  58.9832,  58.9832]],

        [[ 56.4434,  56.4434,  56.4434,  ...,  42.3325,  42.3325,  42.3325],
         [ 56.4434,  56.4434,  56.4434,  ...,  42.3325,  42.3325,  42.3325],
         [ 56.4434,  56.4434,  56.4434,  ...,  42.3325,  42.3325,  42.3325],
         ...,
         [ 32.5832,  32.5832,  32.5832,  ...,  13.8543,  13.8543,  13.8543],
         [ 32.5832,  32.5832,  32.5832,  ...,  13.8543,  13.8543,  13.8543],
         [ 32.5832,  32.5832,  32.5832,  ...,  13.8543,  13.8543,  13.8543]]]),
 'left': tensor([[[[ 0.7933,  0.6734,  0.7077,  ...,  1.0502,  1.0502,  1.0502],
          [ 0.7933,  0.7419,  0.6734,  ...,  0.8618,  0.8618,  0.8618],
          [ 0.6392,  0.7419,  0.6392,  ...,  0.6734,  0.6734,  0.6734],
          ...,
          [ 1.7694,  1.7694,  1.6495,  ...,  2.2489,  2.2489,  2.2489],
          [ 1.8037,  1.7694,  1.5982,  ...,  2.2489,  2.2489,  2.2489],
          [ 1.5982,  1.7180,  1.7180,  ...,  2.2489,  2.2489,  2.2489]],

         [[ 0.9405,  0.8179,  0.8529,  ...,  1.2031,  1.2031,  1.2031],
          [ 0.9405,  0.8880,  0.8179,  ...,  1.0105,  1.0105,  1.0105],
          [ 0.7829,  0.8880,  0.7829,  ...,  0.8179,  0.8179,  0.8179],
          ...,
          [ 1.9384,  1.9384,  1.8158,  ...,  2.4286,  2.4286,  2.4286],
          [ 1.9734,  1.9384,  1.7633,  ...,  2.4286,  2.4286,  2.4286],
          [ 1.7633,  1.8859,  1.8859,  ...,  2.4286,  2.4286,  2.4286]],

         [[ 1.1585,  1.0365,  1.0714,  ...,  1.4200,  1.4200,  1.4200],
          [ 1.1585,  1.1062,  1.0365,  ...,  1.2282,  1.2282,  1.2282],
          [ 1.0017,  1.1062,  1.0017,  ...,  1.0365,  1.0365,  1.0365],
          ...,
          [ 2.1520,  2.1520,  2.0300,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.1868,  2.1520,  1.9777,  ...,  2.6400,  2.6400,  2.6400],
          [ 1.9777,  2.0997,  2.0997,  ...,  2.6400,  2.6400,  2.6400]]],


        [[[-1.7412, -1.7412, -1.7069,  ..., -1.9638, -1.9638, -1.9638],
          [-1.6727, -1.6727, -1.6727,  ..., -1.9467, -1.9467, -1.9467],
          [-1.6384, -1.6384, -1.6384,  ..., -1.9638, -1.9638, -1.9638],
          ...,
          [-1.5699, -1.5699, -1.5699,  ..., -1.3302, -1.3302, -1.3302],
          [-1.5528, -1.5528, -1.5699,  ..., -1.3130, -1.3130, -1.3130],
          [-1.5528, -1.5870, -1.5870,  ..., -1.3473, -1.3473, -1.3473]],

         [[-1.6506, -1.6506, -1.6155,  ..., -1.8782, -1.8782, -1.8782],
          [-1.5805, -1.5805, -1.5805,  ..., -1.8606, -1.8606, -1.8606],
          [-1.5455, -1.5455, -1.5455,  ..., -1.8782, -1.8782, -1.8782],
          ...,
          [-1.4755, -1.4755, -1.4755,  ..., -1.2304, -1.2304, -1.2304],
          [-1.4580, -1.4580, -1.4755,  ..., -1.2129, -1.2129, -1.2129],
          [-1.4580, -1.4930, -1.4930,  ..., -1.2479, -1.2479, -1.2479]],

         [[-1.4210, -1.4210, -1.3861,  ..., -1.6476, -1.6476, -1.6476],
          [-1.3513, -1.3513, -1.3513,  ..., -1.6302, -1.6302, -1.6302],
          [-1.3164, -1.3164, -1.3164,  ..., -1.6476, -1.6476, -1.6476],
          ...,
          [-1.2467, -1.2467, -1.2467,  ..., -1.0027, -1.0027, -1.0027],
          [-1.2293, -1.2293, -1.2467,  ..., -0.9853, -0.9853, -0.9853],
          [-1.2293, -1.2641, -1.2641,  ..., -1.0201, -1.0201, -1.0201]]],


        [[[ 0.1254, -0.0801, -0.0801,  ...,  0.0569,  0.0569,  0.0569],
          [-0.0972,  0.0398,  0.0912,  ...,  0.1426,  0.1426,  0.1426],
          [ 0.0227, -0.1143, -0.1486,  ...,  0.0569,  0.0569,  0.0569],
          ...,
          [-0.7308, -0.8164, -0.9020,  ..., -0.5767, -0.5767, -0.5767],
          [-0.7479, -0.7479, -0.8335,  ..., -0.6281, -0.6281, -0.6281],
          [-0.8335, -0.8335, -0.7993,  ..., -0.6965, -0.6965, -0.6965]],

         [[ 0.2577,  0.0476,  0.0476,  ...,  0.1877,  0.1877,  0.1877],
          [ 0.0301,  0.1702,  0.2227,  ...,  0.2752,  0.2752,  0.2752],
          [ 0.1527,  0.0126, -0.0224,  ...,  0.1877,  0.1877,  0.1877],
          ...,
          [-0.6176, -0.7052, -0.7927,  ..., -0.4601, -0.4601, -0.4601],
          [-0.6352, -0.6352, -0.7227,  ..., -0.5126, -0.5126, -0.5126],
          [-0.7227, -0.7227, -0.6877,  ..., -0.5826, -0.5826, -0.5826]],

         [[ 0.4788,  0.2696,  0.2696,  ...,  0.4091,  0.4091,  0.4091],
          [ 0.2522,  0.3916,  0.4439,  ...,  0.4962,  0.4962,  0.4962],
          [ 0.3742,  0.2348,  0.1999,  ...,  0.4091,  0.4091,  0.4091],
          ...,
          [-0.3927, -0.4798, -0.5670,  ..., -0.2358, -0.2358, -0.2358],
          [-0.4101, -0.4101, -0.4973,  ..., -0.2881, -0.2881, -0.2881],
          [-0.4973, -0.4973, -0.4624,  ..., -0.3578, -0.3578, -0.3578]]],


        ...,


        [[[-1.2959, -1.4158, -1.4672,  ..., -0.2171, -0.2171, -0.2171],
          [-1.2788, -1.4158, -1.4500,  ..., -0.1143, -0.1143, -0.1143],
          [-1.3302, -1.4158, -1.3987,  ..., -0.0116, -0.0116, -0.0116],
          ...,
          [ 0.1254,  0.2282,  0.0569,  ...,  0.2796,  0.2796,  0.2796],
          [ 0.2282,  0.1426,  0.1083,  ...,  0.2967,  0.2967,  0.2967],
          [ 0.2624,  0.2282,  0.2624,  ...,  0.2624,  0.2624,  0.2624]],

         [[-1.1954, -1.3179, -1.3704,  ..., -0.0924, -0.0924, -0.0924],
          [-1.1779, -1.3179, -1.3529,  ...,  0.0126,  0.0126,  0.0126],
          [-1.2304, -1.3179, -1.3004,  ...,  0.1176,  0.1176,  0.1176],
          ...,
          [ 0.2577,  0.3627,  0.1877,  ...,  0.4153,  0.4153,  0.4153],
          [ 0.3627,  0.2752,  0.2402,  ...,  0.4328,  0.4328,  0.4328],
          [ 0.3978,  0.3627,  0.3978,  ...,  0.3978,  0.3978,  0.3978]],

         [[-0.9678, -1.0898, -1.1421,  ...,  0.1302,  0.1302,  0.1302],
          [-0.9504, -1.0898, -1.1247,  ...,  0.2348,  0.2348,  0.2348],
          [-1.0027, -1.0898, -1.0724,  ...,  0.3393,  0.3393,  0.3393],
          ...,
          [ 0.4788,  0.5834,  0.4091,  ...,  0.6356,  0.6356,  0.6356],
          [ 0.5834,  0.4962,  0.4614,  ...,  0.6531,  0.6531,  0.6531],
          [ 0.6182,  0.5834,  0.6182,  ...,  0.6182,  0.6182,  0.6182]]],


        [[[ 0.3994,  0.2796,  0.2624,  ...,  0.0569,  0.0569,  0.0569],
          [ 0.2624,  0.2796,  0.3309,  ...,  0.0741,  0.0741,  0.0741],
          [ 0.1939,  0.3481,  0.3138,  ...,  0.0569,  0.0569,  0.0569],
          ...,
          [ 1.1872,  1.0502,  1.0502,  ...,  0.3994,  0.3994,  0.3994],
          [ 1.1187,  1.1187,  1.1015,  ...,  0.3309,  0.3309,  0.3309],
          [ 1.1358,  1.2385,  1.2214,  ...,  0.3652,  0.3652,  0.3652]],

         [[ 0.5378,  0.4153,  0.3978,  ...,  0.1877,  0.1877,  0.1877],
          [ 0.3978,  0.4153,  0.4678,  ...,  0.2052,  0.2052,  0.2052],
          [ 0.3277,  0.4853,  0.4503,  ...,  0.1877,  0.1877,  0.1877],
          ...,
          [ 1.3431,  1.2031,  1.2031,  ...,  0.5378,  0.5378,  0.5378],
          [ 1.2731,  1.2731,  1.2556,  ...,  0.4678,  0.4678,  0.4678],
          [ 1.2906,  1.3957,  1.3782,  ...,  0.5028,  0.5028,  0.5028]],

         [[ 0.7576,  0.6356,  0.6182,  ...,  0.4091,  0.4091,  0.4091],
          [ 0.6182,  0.6356,  0.6879,  ...,  0.4265,  0.4265,  0.4265],
          [ 0.5485,  0.7054,  0.6705,  ...,  0.4091,  0.4091,  0.4091],
          ...,
          [ 1.5594,  1.4200,  1.4200,  ...,  0.7576,  0.7576,  0.7576],
          [ 1.4897,  1.4897,  1.4722,  ...,  0.6879,  0.6879,  0.6879],
          [ 1.5071,  1.6117,  1.5942,  ...,  0.7228,  0.7228,  0.7228]]],


        [[[ 0.6221,  0.6734,  0.6221,  ...,  0.7248,  0.7248,  0.7248],
          [ 0.6906,  0.7248,  0.6563,  ...,  0.7933,  0.7933,  0.7933],
          [ 0.6734,  0.7077,  0.7248,  ...,  0.7248,  0.7248,  0.7248],
          ...,
          [-0.9363, -1.0219, -1.0048,  ..., -0.2171, -0.2171, -0.2171],
          [-0.9534, -1.0048, -1.0219,  ..., -0.2171, -0.2171, -0.2171],
          [-0.9534, -0.9534, -0.9363,  ..., -0.2513, -0.2513, -0.2513]],

         [[ 0.7654,  0.8179,  0.7654,  ...,  0.8704,  0.8704,  0.8704],
          [ 0.8354,  0.8704,  0.8004,  ...,  0.9405,  0.9405,  0.9405],
          [ 0.8179,  0.8529,  0.8704,  ...,  0.8704,  0.8704,  0.8704],
          ...,
          [-0.8277, -0.9153, -0.8978,  ..., -0.0924, -0.0924, -0.0924],
          [-0.8452, -0.8978, -0.9153,  ..., -0.0924, -0.0924, -0.0924],
          [-0.8452, -0.8452, -0.8277,  ..., -0.1275, -0.1275, -0.1275]],

         [[ 0.9842,  1.0365,  0.9842,  ...,  1.0888,  1.0888,  1.0888],
          [ 1.0539,  1.0888,  1.0191,  ...,  1.1585,  1.1585,  1.1585],
          [ 1.0365,  1.0714,  1.0888,  ...,  1.0888,  1.0888,  1.0888],
          ...,
          [-0.6018, -0.6890, -0.6715,  ...,  0.1302,  0.1302,  0.1302],
          [-0.6193, -0.6715, -0.6890,  ...,  0.1302,  0.1302,  0.1302],
          [-0.6193, -0.6193, -0.6018,  ...,  0.0953,  0.0953,  0.0953]]]]),
 'right': tensor([[[[ 0.8618,  1.2557,  1.1872,  ...,  2.2489,  2.2489,  2.2489],
          [ 0.6221,  0.8618,  1.1015,  ...,  2.2489,  2.2489,  2.2489],
          [ 0.3652,  0.5536,  0.7762,  ...,  2.2489,  2.2489,  2.2489],
          ...,
          [ 2.2489,  2.2489,  2.2489,  ..., -1.9124, -1.8782, -1.8439],
          [ 2.2489,  2.2489,  2.2489,  ..., -1.9124, -1.9124, -1.9124],
          [ 2.2489,  2.2489,  2.2489,  ..., -1.9124, -1.9124, -1.9124]],

         [[ 0.6078,  1.2556,  1.6057,  ...,  2.4286,  2.4286,  2.4286],
          [ 0.5728,  1.1681,  1.4832,  ...,  2.4286,  2.4286,  2.4286],
          [ 0.4503,  1.0630,  1.4132,  ...,  2.4286,  2.4286,  2.4286],
          ...,
          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -1.9132],
          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0357],
          [ 2.4286,  2.4286,  2.4286,  ..., -2.0357, -2.0357, -2.0182]],

         [[ 0.2696,  0.5136,  1.0017,  ...,  2.6400,  2.6400,  2.6400],
          [ 0.1476,  0.3916,  1.1062,  ...,  2.6400,  2.6400,  2.6400],
          [ 0.0431,  0.2696,  0.9145,  ...,  2.6400,  2.6400,  2.6400],
          ...,
          [ 2.6400,  2.6400,  2.6400,  ..., -1.2293, -1.1944, -1.3861],
          [ 2.6400,  2.6400,  2.6400,  ..., -1.2293, -1.2293, -1.3164],
          [ 2.6400,  2.6400,  2.6400,  ..., -1.2293, -1.2293, -1.2467]]],


        [[[ 1.2557,  1.2557,  1.2728,  ...,  1.0159,  0.9988,  1.0159],
          [ 1.2557,  1.3070,  1.2899,  ...,  1.0331,  1.0159,  1.0673],
          [ 1.2899,  1.3242,  1.3070,  ...,  0.9988,  1.0159,  1.0159],
          ...,
          [ 1.2728,  1.2385,  1.1872,  ..., -1.3815, -1.3815, -1.2617],
          [ 1.3070,  1.2899,  1.2557,  ..., -1.3644, -1.2788, -1.2274],
          [ 1.3242,  1.3070,  1.3070,  ..., -1.1932, -1.1760, -1.1418]],

         [[ 1.6232,  1.6232,  1.6232,  ...,  1.1506,  1.1506,  1.1506],
          [ 1.6232,  1.6232,  1.6232,  ...,  1.1681,  1.1681,  1.1856],
          [ 1.6232,  1.6232,  1.6408,  ...,  1.1681,  1.2206,  1.1681],
          ...,
          [ 1.3606,  1.4132,  1.4132,  ..., -1.4405, -1.4230, -1.3529],
          [ 1.4482,  1.3957,  1.4482,  ..., -1.4055, -1.3529, -1.3179],
          [ 1.4482,  1.4132,  1.4132,  ..., -1.3004, -1.2829, -1.2654]],

         [[ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],
          ...,
          [ 1.2631,  1.2108,  1.1759,  ..., -0.6715, -0.6715, -0.6715],
          [ 1.2805,  1.2631,  1.2108,  ..., -0.6715, -0.6541, -0.6367],
          [ 1.2805,  1.2805,  1.2805,  ..., -0.5670, -0.5670, -0.5670]]],


        [[[-1.0904, -1.1418, -1.2103,  ..., -1.6042, -1.6042, -1.6042],
          [-1.2788, -1.3302, -1.3644,  ..., -1.7412, -1.7412, -1.7412],
          [-1.3987, -1.4329, -1.4843,  ..., -1.7925, -1.7925, -1.7925],
          ...,
          [-0.1828, -0.1999, -0.1999,  ...,  0.0056, -0.0116, -0.0116],
          [-0.1828, -0.2513, -0.2513,  ..., -0.0116, -0.0629, -0.0972],
          [-0.1657, -0.1999, -0.1999,  ...,  0.0056, -0.0629, -0.0972]],

         [[-0.9153, -0.9153, -0.9853,  ..., -1.7556, -1.7556, -1.6856],
          [-1.0203, -1.0378, -1.1078,  ..., -1.7906, -1.8081, -1.7906],
          [-1.1429, -1.1604, -1.2304,  ..., -1.8606, -1.8782, -1.8606],
          ...,
          [ 0.9930,  0.9755,  1.0105,  ...,  1.1506,  1.1681,  1.1331],
          [ 0.9930,  1.0630,  1.0280,  ...,  1.1506,  1.2206,  1.2031],
          [ 0.9580,  0.9580,  0.9580,  ...,  1.1506,  1.1681,  1.2206]],

         [[ 0.0953, -0.1487, -0.3055,  ..., -1.2816, -1.3164, -1.3164],
          [-0.1487, -0.3404, -0.4798,  ..., -1.3861, -1.3861, -1.3861],
          [-0.3753, -0.5321, -0.6715,  ..., -1.4036, -1.4210, -1.4210],
          ...,
          [ 2.0823,  2.0823,  2.0823,  ...,  2.3263,  2.4483,  2.4831],
          [ 2.0823,  2.0823,  2.1171,  ...,  2.3437,  2.4134,  2.4134],
          [ 2.1868,  2.2043,  2.2217,  ...,  2.4308,  2.4308,  2.4483]]],


        ...,


        [[[ 0.3994,  0.3994,  0.3994,  ...,  0.3309,  0.3138,  0.2967],
          [ 0.4337,  0.4337,  0.4508,  ...,  0.3138,  0.3138,  0.2967],
          [ 0.4508,  0.4679,  0.4851,  ...,  0.2967,  0.2967,  0.3138],
          ...,
          [ 0.8789,  0.8961,  0.8961,  ...,  1.4440,  2.0605,  2.1804],
          [ 0.8276,  0.8447,  0.8447,  ...,  1.6838,  2.2318,  2.2318],
          [ 0.7419,  0.7591,  0.7762,  ...,  1.7352,  2.2318,  2.2318]],

         [[ 1.1506,  1.1506,  1.1856,  ...,  1.0280,  0.9930,  0.9930],
          [ 1.2031,  1.2031,  1.1856,  ...,  1.0105,  1.0105,  1.0105],
          [ 1.2206,  1.2556,  1.2381,  ...,  1.0455,  1.0280,  1.0105],
          ...,
          [ 0.9230,  0.9580,  0.9055,  ...,  2.2710,  2.4111,  2.4111],
          [ 0.8880,  0.8880,  0.8354,  ...,  2.2535,  2.4111,  2.4286],
          [ 0.8004,  0.8004,  0.8179,  ...,  2.3936,  2.4286,  2.4286]],

         [[ 2.2391,  2.2740,  2.2391,  ...,  2.1520,  2.1171,  2.1346],
          [ 2.1868,  2.2043,  2.2217,  ...,  2.1694,  2.1520,  2.1520],
          [ 2.1694,  2.1520,  2.1868,  ...,  2.1868,  2.2391,  2.2740],
          ...,
          [ 0.7751,  0.7576,  0.8274,  ...,  2.1346,  2.4308,  2.6226],
          [ 0.7054,  0.6879,  0.7402,  ...,  2.5529,  2.5703,  2.6400],
          [ 0.7054,  0.6879,  0.6879,  ...,  2.5703,  2.6400,  2.6400]]],


        [[[-0.4911, -0.4568, -0.4739,  ..., -0.5082, -0.5253, -0.5424],
          [-0.4911, -0.4739, -0.4911,  ..., -0.5082, -0.5082, -0.5082],
          [-0.4911, -0.4911, -0.5082,  ..., -0.5253, -0.5082, -0.4911],
          ...,
          [-0.5767, -0.5424, -0.5424,  ..., -1.5357, -1.5357, -1.5357],
          [-0.5938, -0.5596, -0.5424,  ..., -1.5357, -1.5357, -1.5357],
          [-0.6452, -0.6281, -0.6109,  ..., -1.5357, -1.5357, -1.5357]],

         [[-0.3025, -0.3200, -0.3375,  ..., -0.2850, -0.2850, -0.2675],
          [-0.2850, -0.3025, -0.3200,  ..., -0.3200, -0.3025, -0.2850],
          [-0.3025, -0.3025, -0.3025,  ..., -0.3025, -0.2850, -0.2850],
          ...,
          [-0.1975, -0.1625, -0.1450,  ..., -1.3880, -1.4055, -1.4055],
          [-0.2150, -0.2150, -0.2150,  ..., -1.3704, -1.3880, -1.3880],
          [-0.2325, -0.2325, -0.1975,  ..., -1.3880, -1.3880, -1.4055]],

         [[ 0.0953,  0.1128,  0.0953,  ...,  0.1128,  0.0953,  0.1128],
          [ 0.0605,  0.0953,  0.0953,  ...,  0.1302,  0.1128,  0.1128],
          [ 0.0082,  0.0256,  0.0605,  ...,  0.1476,  0.1302,  0.0953],
          ...,
          [ 0.5659,  0.5485,  0.5311,  ..., -0.8110, -0.8284, -0.8284],
          [ 0.6182,  0.6008,  0.5834,  ..., -0.8284, -0.8633, -0.8633],
          [ 0.6182,  0.6008,  0.5659,  ..., -0.8458, -0.8633, -0.8458]]],


        [[[-1.5699, -1.6727, -1.7240,  ..., -1.6555, -1.5699, -1.5699],
          [-1.6555, -1.6898, -1.7240,  ..., -1.5528, -1.4500, -1.4329],
          [-1.7069, -1.7069, -1.7412,  ..., -1.4158, -1.3302, -1.3473],
          ...,
          [ 0.6392,  0.6221,  0.6221,  ...,  1.2043,  1.1700,  1.1358],
          [ 0.6392,  0.6392,  0.6392,  ...,  1.1700,  1.1529,  1.1187],
          [ 0.6563,  0.6563,  0.6734,  ...,  1.1700,  1.1529,  1.1187]],

         [[-1.4755, -1.6506, -1.6331,  ..., -1.5455, -1.5805, -1.5630],
          [-1.6506, -1.6506, -1.5805,  ..., -1.4230, -1.5630, -1.5805],
          [-1.6506, -1.6506, -1.5805,  ..., -1.4755, -1.6155, -1.6681],
          ...,
          [ 1.5882,  1.6232,  1.6583,  ...,  2.1835,  2.1485,  2.1660],
          [ 1.5882,  1.5532,  1.5882,  ...,  2.1485,  2.1310,  2.1485],
          [ 1.6057,  1.6057,  1.5707,  ...,  2.0784,  2.1310,  2.1485]],

         [[-1.0201, -1.1073, -1.1944,  ..., -1.0201, -1.0201, -1.0550],
          [-1.0027, -1.1596, -1.2119,  ..., -1.0550, -1.0898, -1.1247],
          [-1.0724, -1.1944, -1.2119,  ..., -1.0724, -1.0724, -1.1073],
          ...,
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]]])}
(Pdb) *** AttributeError: 'dict' object has no attribute 'shape'
(Pdb) tensor([[[[ 0.7933,  0.6734,  0.7077,  ...,  1.0502,  1.0502,  1.0502],
          [ 0.7933,  0.7419,  0.6734,  ...,  0.8618,  0.8618,  0.8618],
          [ 0.6392,  0.7419,  0.6392,  ...,  0.6734,  0.6734,  0.6734],
          ...,
          [ 1.7694,  1.7694,  1.6495,  ...,  2.2489,  2.2489,  2.2489],
          [ 1.8037,  1.7694,  1.5982,  ...,  2.2489,  2.2489,  2.2489],
          [ 1.5982,  1.7180,  1.7180,  ...,  2.2489,  2.2489,  2.2489]],

         [[ 0.9405,  0.8179,  0.8529,  ...,  1.2031,  1.2031,  1.2031],
          [ 0.9405,  0.8880,  0.8179,  ...,  1.0105,  1.0105,  1.0105],
          [ 0.7829,  0.8880,  0.7829,  ...,  0.8179,  0.8179,  0.8179],
          ...,
          [ 1.9384,  1.9384,  1.8158,  ...,  2.4286,  2.4286,  2.4286],
          [ 1.9734,  1.9384,  1.7633,  ...,  2.4286,  2.4286,  2.4286],
          [ 1.7633,  1.8859,  1.8859,  ...,  2.4286,  2.4286,  2.4286]],

         [[ 1.1585,  1.0365,  1.0714,  ...,  1.4200,  1.4200,  1.4200],
          [ 1.1585,  1.1062,  1.0365,  ...,  1.2282,  1.2282,  1.2282],
          [ 1.0017,  1.1062,  1.0017,  ...,  1.0365,  1.0365,  1.0365],
          ...,
          [ 2.1520,  2.1520,  2.0300,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.1868,  2.1520,  1.9777,  ...,  2.6400,  2.6400,  2.6400],
          [ 1.9777,  2.0997,  2.0997,  ...,  2.6400,  2.6400,  2.6400]]],


        [[[-1.7412, -1.7412, -1.7069,  ..., -1.9638, -1.9638, -1.9638],
          [-1.6727, -1.6727, -1.6727,  ..., -1.9467, -1.9467, -1.9467],
          [-1.6384, -1.6384, -1.6384,  ..., -1.9638, -1.9638, -1.9638],
          ...,
          [-1.5699, -1.5699, -1.5699,  ..., -1.3302, -1.3302, -1.3302],
          [-1.5528, -1.5528, -1.5699,  ..., -1.3130, -1.3130, -1.3130],
          [-1.5528, -1.5870, -1.5870,  ..., -1.3473, -1.3473, -1.3473]],

         [[-1.6506, -1.6506, -1.6155,  ..., -1.8782, -1.8782, -1.8782],
          [-1.5805, -1.5805, -1.5805,  ..., -1.8606, -1.8606, -1.8606],
          [-1.5455, -1.5455, -1.5455,  ..., -1.8782, -1.8782, -1.8782],
          ...,
          [-1.4755, -1.4755, -1.4755,  ..., -1.2304, -1.2304, -1.2304],
          [-1.4580, -1.4580, -1.4755,  ..., -1.2129, -1.2129, -1.2129],
          [-1.4580, -1.4930, -1.4930,  ..., -1.2479, -1.2479, -1.2479]],

         [[-1.4210, -1.4210, -1.3861,  ..., -1.6476, -1.6476, -1.6476],
          [-1.3513, -1.3513, -1.3513,  ..., -1.6302, -1.6302, -1.6302],
          [-1.3164, -1.3164, -1.3164,  ..., -1.6476, -1.6476, -1.6476],
          ...,
          [-1.2467, -1.2467, -1.2467,  ..., -1.0027, -1.0027, -1.0027],
          [-1.2293, -1.2293, -1.2467,  ..., -0.9853, -0.9853, -0.9853],
          [-1.2293, -1.2641, -1.2641,  ..., -1.0201, -1.0201, -1.0201]]],


        [[[ 0.1254, -0.0801, -0.0801,  ...,  0.0569,  0.0569,  0.0569],
          [-0.0972,  0.0398,  0.0912,  ...,  0.1426,  0.1426,  0.1426],
          [ 0.0227, -0.1143, -0.1486,  ...,  0.0569,  0.0569,  0.0569],
          ...,
          [-0.7308, -0.8164, -0.9020,  ..., -0.5767, -0.5767, -0.5767],
          [-0.7479, -0.7479, -0.8335,  ..., -0.6281, -0.6281, -0.6281],
          [-0.8335, -0.8335, -0.7993,  ..., -0.6965, -0.6965, -0.6965]],

         [[ 0.2577,  0.0476,  0.0476,  ...,  0.1877,  0.1877,  0.1877],
          [ 0.0301,  0.1702,  0.2227,  ...,  0.2752,  0.2752,  0.2752],
          [ 0.1527,  0.0126, -0.0224,  ...,  0.1877,  0.1877,  0.1877],
          ...,
          [-0.6176, -0.7052, -0.7927,  ..., -0.4601, -0.4601, -0.4601],
          [-0.6352, -0.6352, -0.7227,  ..., -0.5126, -0.5126, -0.5126],
          [-0.7227, -0.7227, -0.6877,  ..., -0.5826, -0.5826, -0.5826]],

         [[ 0.4788,  0.2696,  0.2696,  ...,  0.4091,  0.4091,  0.4091],
          [ 0.2522,  0.3916,  0.4439,  ...,  0.4962,  0.4962,  0.4962],
          [ 0.3742,  0.2348,  0.1999,  ...,  0.4091,  0.4091,  0.4091],
          ...,
          [-0.3927, -0.4798, -0.5670,  ..., -0.2358, -0.2358, -0.2358],
          [-0.4101, -0.4101, -0.4973,  ..., -0.2881, -0.2881, -0.2881],
          [-0.4973, -0.4973, -0.4624,  ..., -0.3578, -0.3578, -0.3578]]],


        ...,


        [[[-1.2959, -1.4158, -1.4672,  ..., -0.2171, -0.2171, -0.2171],
          [-1.2788, -1.4158, -1.4500,  ..., -0.1143, -0.1143, -0.1143],
          [-1.3302, -1.4158, -1.3987,  ..., -0.0116, -0.0116, -0.0116],
          ...,
          [ 0.1254,  0.2282,  0.0569,  ...,  0.2796,  0.2796,  0.2796],
          [ 0.2282,  0.1426,  0.1083,  ...,  0.2967,  0.2967,  0.2967],
          [ 0.2624,  0.2282,  0.2624,  ...,  0.2624,  0.2624,  0.2624]],

         [[-1.1954, -1.3179, -1.3704,  ..., -0.0924, -0.0924, -0.0924],
          [-1.1779, -1.3179, -1.3529,  ...,  0.0126,  0.0126,  0.0126],
          [-1.2304, -1.3179, -1.3004,  ...,  0.1176,  0.1176,  0.1176],
          ...,
          [ 0.2577,  0.3627,  0.1877,  ...,  0.4153,  0.4153,  0.4153],
          [ 0.3627,  0.2752,  0.2402,  ...,  0.4328,  0.4328,  0.4328],
          [ 0.3978,  0.3627,  0.3978,  ...,  0.3978,  0.3978,  0.3978]],

         [[-0.9678, -1.0898, -1.1421,  ...,  0.1302,  0.1302,  0.1302],
          [-0.9504, -1.0898, -1.1247,  ...,  0.2348,  0.2348,  0.2348],
          [-1.0027, -1.0898, -1.0724,  ...,  0.3393,  0.3393,  0.3393],
          ...,
          [ 0.4788,  0.5834,  0.4091,  ...,  0.6356,  0.6356,  0.6356],
          [ 0.5834,  0.4962,  0.4614,  ...,  0.6531,  0.6531,  0.6531],
          [ 0.6182,  0.5834,  0.6182,  ...,  0.6182,  0.6182,  0.6182]]],


        [[[ 0.3994,  0.2796,  0.2624,  ...,  0.0569,  0.0569,  0.0569],
          [ 0.2624,  0.2796,  0.3309,  ...,  0.0741,  0.0741,  0.0741],
          [ 0.1939,  0.3481,  0.3138,  ...,  0.0569,  0.0569,  0.0569],
          ...,
          [ 1.1872,  1.0502,  1.0502,  ...,  0.3994,  0.3994,  0.3994],
          [ 1.1187,  1.1187,  1.1015,  ...,  0.3309,  0.3309,  0.3309],
          [ 1.1358,  1.2385,  1.2214,  ...,  0.3652,  0.3652,  0.3652]],

         [[ 0.5378,  0.4153,  0.3978,  ...,  0.1877,  0.1877,  0.1877],
          [ 0.3978,  0.4153,  0.4678,  ...,  0.2052,  0.2052,  0.2052],
          [ 0.3277,  0.4853,  0.4503,  ...,  0.1877,  0.1877,  0.1877],
          ...,
          [ 1.3431,  1.2031,  1.2031,  ...,  0.5378,  0.5378,  0.5378],
          [ 1.2731,  1.2731,  1.2556,  ...,  0.4678,  0.4678,  0.4678],
          [ 1.2906,  1.3957,  1.3782,  ...,  0.5028,  0.5028,  0.5028]],

         [[ 0.7576,  0.6356,  0.6182,  ...,  0.4091,  0.4091,  0.4091],
          [ 0.6182,  0.6356,  0.6879,  ...,  0.4265,  0.4265,  0.4265],
          [ 0.5485,  0.7054,  0.6705,  ...,  0.4091,  0.4091,  0.4091],
          ...,
          [ 1.5594,  1.4200,  1.4200,  ...,  0.7576,  0.7576,  0.7576],
          [ 1.4897,  1.4897,  1.4722,  ...,  0.6879,  0.6879,  0.6879],
          [ 1.5071,  1.6117,  1.5942,  ...,  0.7228,  0.7228,  0.7228]]],


        [[[ 0.6221,  0.6734,  0.6221,  ...,  0.7248,  0.7248,  0.7248],
          [ 0.6906,  0.7248,  0.6563,  ...,  0.7933,  0.7933,  0.7933],
          [ 0.6734,  0.7077,  0.7248,  ...,  0.7248,  0.7248,  0.7248],
          ...,
          [-0.9363, -1.0219, -1.0048,  ..., -0.2171, -0.2171, -0.2171],
          [-0.9534, -1.0048, -1.0219,  ..., -0.2171, -0.2171, -0.2171],
          [-0.9534, -0.9534, -0.9363,  ..., -0.2513, -0.2513, -0.2513]],

         [[ 0.7654,  0.8179,  0.7654,  ...,  0.8704,  0.8704,  0.8704],
          [ 0.8354,  0.8704,  0.8004,  ...,  0.9405,  0.9405,  0.9405],
          [ 0.8179,  0.8529,  0.8704,  ...,  0.8704,  0.8704,  0.8704],
          ...,
          [-0.8277, -0.9153, -0.8978,  ..., -0.0924, -0.0924, -0.0924],
          [-0.8452, -0.8978, -0.9153,  ..., -0.0924, -0.0924, -0.0924],
          [-0.8452, -0.8452, -0.8277,  ..., -0.1275, -0.1275, -0.1275]],

         [[ 0.9842,  1.0365,  0.9842,  ...,  1.0888,  1.0888,  1.0888],
          [ 1.0539,  1.0888,  1.0191,  ...,  1.1585,  1.1585,  1.1585],
          [ 1.0365,  1.0714,  1.0888,  ...,  1.0888,  1.0888,  1.0888],
          ...,
          [-0.6018, -0.6890, -0.6715,  ...,  0.1302,  0.1302,  0.1302],
          [-0.6193, -0.6715, -0.6890,  ...,  0.1302,  0.1302,  0.1302],
          [-0.6193, -0.6193, -0.6018,  ...,  0.0953,  0.0953,  0.0953]]]])
(Pdb) torch.Size([8, 3, 384, 768])
(Pdb) dict_keys(['left', 'right', 'disp'])
(Pdb) torch.Size([8, 3, 384, 768])
(Pdb) tensor([[[ 18.2223,  18.2223,  18.2223,  ...,  14.0809,  14.0809,  12.7004],
         [ 18.2223,  18.2223,  18.2223,  ...,  14.0809,  12.8324,  12.7004],
         [ 18.2223,  18.2223,  18.2223,  ...,  14.3318,  14.0809,  12.7004],
         ...,
         [116.2362, 116.2362, 116.6655,  ...,  67.9195,  67.9195,  67.9195],
         [116.2362, 116.2362, 116.6655,  ...,  67.9195,  67.9195,  67.9195],
         [116.2362, 116.2362, 116.6655,  ...,  67.9195,  67.9195,  67.9195]],

        [[  8.4503,   8.6030,  10.0151,  ...,  13.1448,  13.1448,  13.1448],
         [  8.4503,   8.4503,   8.4503,  ...,  13.1448,  13.1448,  13.1448],
         [  8.4503,   8.4503,   8.7048,  ...,  13.1448,  13.1448,  13.1448],
         ...,
         [ 57.5869,  57.5869,  57.5869,  ...,  84.8156,  84.8156,  84.8156],
         [ 58.8388,  58.7167,  57.5869,  ...,  84.9404,  84.8156,  84.8156],
         [ 58.8388,  58.8388,  58.8388,  ...,  85.4415,  85.4415,  84.8589]],

        [[ 98.4309,  98.4309,  98.4309,  ...,  81.8976,  81.8976,  81.8976],
         [ 98.4309,  98.4309,  98.4309,  ...,  81.8976,  81.8873,  80.5540],
         [ 98.4309,  98.4309,  98.4309,  ...,  80.3596,  80.3596,  80.3596],
         ...,
         [ 23.8387,  23.8387,  23.8387,  ...,   8.0744,   8.0667,   7.0667],
         [ 23.8387,  23.8387,  23.8387,  ...,   9.3974,   8.0744,   8.0744],
         [ 23.8387,  23.8387,  23.8387,  ...,  10.3814,  10.3762,   9.7096]],

        ...,

        [[ 49.3333,  49.3333,  49.3333,  ...,  14.0000,  14.0000,  14.0000],
         [ 49.3333,  48.3333,  48.3333,  ...,  15.3333,  14.0000,  14.0000],
         [ 48.3333,  48.3333,  48.3333,  ...,  15.3333,  14.0000,  14.0000],
         ...,
         [ 61.3333,  61.3333,  61.3333,  ...,  73.6667,  73.6667,  73.6667],
         [ 62.6667,  62.6667,  62.6667,  ...,  73.6667,  73.6667,  73.6667],
         [ 62.6667,  62.6667,  62.6667,  ...,  73.6667,  73.6667,  73.6667]],

        [[ 48.4910,  48.4910,  48.1178,  ...,  14.4622,  14.4622,  14.4622],
         [ 48.4910,  48.4910,  48.4910,  ...,  14.4622,  14.4622,  14.4622],
         [ 48.4910,  48.4910,  48.4910,  ...,  14.4622,  14.4622,  14.4622],
         ...,
         [ 83.6540,  83.6540,  83.6540,  ...,  58.9832,  58.9832,  58.9832],
         [ 83.6540,  83.6540,  83.6540,  ...,  58.9832,  58.9832,  58.9832],
         [ 83.6540,  83.6540,  83.6540,  ...,  58.9832,  58.9832,  58.9832]],

        [[ 56.4434,  56.4434,  56.4434,  ...,  42.3325,  42.3325,  42.3325],
         [ 56.4434,  56.4434,  56.4434,  ...,  42.3325,  42.3325,  42.3325],
         [ 56.4434,  56.4434,  56.4434,  ...,  42.3325,  42.3325,  42.3325],
         ...,
         [ 32.5832,  32.5832,  32.5832,  ...,  13.8543,  13.8543,  13.8543],
         [ 32.5832,  32.5832,  32.5832,  ...,  13.8543,  13.8543,  13.8543],
         [ 32.5832,  32.5832,  32.5832,  ...,  13.8543,  13.8543,  13.8543]]])
(Pdb) torch.Size([8, 3, 384, 768])
(Pdb) I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 399, in main
    torch.cuda.empty_cache()
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 399, in main
    torch.cuda.empty_cache()
  File "/usr/lib/python3.9/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/lib/python3.9/bdb.py", line 112, in dispatch_line
    self.user_line(frame)
  File "/usr/lib/python3.9/pdb.py", line 262, in user_line
    self.interaction(frame, None)
  File "/usr/lib/python3.9/pdb.py", line 357, in interaction
    self._cmdloop()
  File "/usr/lib/python3.9/pdb.py", line 322, in _cmdloop
    self.cmdloop()
  File "/usr/lib/python3.9/cmd.py", line 126, in cmdloop
    line = input(self.prompt)
  File "/usr/lib/python3.9/codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 37: invalid continuation byte
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 8980) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-02_11:17:48
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 8980)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 156, in main
    init_dist(args.launcher, **dist_params)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/utils/dist_utils.py", line 16, in init_dist
    _init_dist_pytorch(backend, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/utils/dist_utils.py", line 27, in _init_dist_pytorch
    rank = int(os.environ['RANK'])
  File "/usr/lib/python3.9/os.py", line 679, in __getitem__
    raise KeyError(key) from None
KeyError: 'RANK'
2023-03-02 11:24:25.382091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 11:24:25.466716: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 11:24:25.826804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:24:25.826837: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:24:25.826841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(399)main()
-> torch.cuda.empty_cache()
(Pdb) I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 399, in main
    torch.cuda.empty_cache()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 180, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 107, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 15.75 GiB total capacity; 14.19 GiB already allocated; 67.12 MiB free; 14.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 11:26:01.356412: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 11:26:01.438650: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 11:26:01.795943: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:26:01.795984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:26:01.795989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(400)main()
-> torch.cuda.empty_cache()
(Pdb) 58839040
(Pdb) 71303168
(Pdb) 71303168
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(401)main()
-> left = sample['left'].to(device)  # [B, 3, H, W]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(402)main()
-> right = sample['right'].to(device)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(403)main()
-> gt_disp = sample['disp'].to(device)  # [B, H, W]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(405)main()
-> mask = (gt_disp > 0) & (gt_disp < args.max_disp)
(Pdb) 127932416
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(407)main()
-> if not mask.any():
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(410)main()
-> pred_disps = model(left, right,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(411)main()
-> attn_type=args.attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(412)main()
-> attn_splits_list=args.attn_splits_list,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(413)main()
-> corr_radius_list=args.corr_radius_list,
(Pdb) 408  	                continue
409  	
410  	            pred_disps = model(left, right,
411  	                               attn_type=args.attn_type,
412  	                               attn_splits_list=args.attn_splits_list,
413  ->	                               corr_radius_list=args.corr_radius_list,
414  	                               prop_radius_list=args.prop_radius_list,
415  	                               num_reg_refine=args.num_reg_refine,
416  	                               task='stereo',
417  	                               )['flow_preds']
418  	
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(414)main()
-> prop_radius_list=args.prop_radius_list,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(415)main()
-> num_reg_refine=args.num_reg_refine,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(416)main()
-> task='stereo',
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(410)main()
-> pred_disps = model(left, right,
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1188)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) 1183 	        finally:
1184 	            if recording_scopes:
1185 	                tracing_state.pop_scope()
1186 	        return result
1187 	
1188 ->	    def _call_impl(self, *input, **kwargs):
1189 	        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
1190 	        # If we don't have any hooks, we want to skip the rest of the logic in
1191 	        # this function, and just call forward.
1192 	        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
1193 	                or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1189)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1193)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) 1188 	    def _call_impl(self, *input, **kwargs):
1189 	        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
1190 	        # If we don't have any hooks, we want to skip the rest of the logic in
1191 	        # this function, and just call forward.
1192 	        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
1193 ->	                or _global_forward_hooks or _global_forward_pre_hooks):
1194 	            return forward_call(*input, **kwargs)
1195 	        # Do not call functions when jit is used
1196 	        full_backward_hooks, non_full_backward_hooks = [], []
1197 	        if self._backward_hooks or _global_backward_hooks:
1198 	            full_backward_hooks, non_full_backward_hooks = self._get_backward_hooks()
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) 1187 	
1188 	    def _call_impl(self, *input, **kwargs):
1189 	        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
1190 	        # If we don't have any hooks, we want to skip the rest of the logic in
1191 	        # this function, and just call forward.
1192 ->	        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
1193 	                or _global_forward_hooks or _global_forward_pre_hooks):
1194 	            return forward_call(*input, **kwargs)
1195 	        # Do not call functions when jit is used
1196 	        full_backward_hooks, non_full_backward_hooks = [], []
1197 	        if self._backward_hooks or _global_backward_hooks:
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1193)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) 1187 	
1188 	    def _call_impl(self, *input, **kwargs):
1189 	        forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
1190 	        # If we don't have any hooks, we want to skip the rest of the logic in
1191 	        # this function, and just call forward.
1192 ->	        if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
1193 	                or _global_forward_hooks or _global_forward_pre_hooks):
1194 	            return forward_call(*input, **kwargs)
1195 	        # Do not call functions when jit is used
1196 	        full_backward_hooks, non_full_backward_hooks = [], []
1197 	        if self._backward_hooks or _global_backward_hooks:
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(95)forward()
-> def forward(self, img0, img1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(113)forward()
-> if pred_bidir_flow:
(Pdb) 108  	                depth_from_argmax=False,
109  	                pred_bidir_depth=False,
110  	                **kwargs,
111  	                ):
112  	
113  ->	        if pred_bidir_flow:
114  	            assert task == 'flow'
115  	
116  	        if task == 'depth':
117  	            assert self.num_scales == 1  # multi-scale depth model is not supported yet
118  	
(Pdb) tensor([[[[ 0.8276,  0.6392,  0.6734,  ...,  1.3413,  1.3413,  1.3413],
          [ 0.7419,  0.7762,  0.7077,  ...,  1.4954,  1.4954,  1.4954],
          [ 0.7762,  0.7933,  0.8618,  ...,  1.6153,  1.6153,  1.6153],
          ...,
          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],
          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],
          [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],

         [[ 0.9755,  0.7829,  0.8179,  ...,  1.5007,  1.5007,  1.5007],
          [ 0.8880,  0.9230,  0.8529,  ...,  1.6583,  1.6583,  1.6583],
          [ 0.9230,  0.9405,  1.0105,  ...,  1.7808,  1.7808,  1.7808],
          ...,
          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],
          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],
          [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],

         [[ 1.1934,  1.0017,  1.0365,  ...,  1.7163,  1.7163,  1.7163],
          [ 1.1062,  1.1411,  1.0714,  ...,  1.8731,  1.8731,  1.8731],
          [ 1.1411,  1.1585,  1.2282,  ...,  1.9951,  1.9951,  1.9951],
          ...,
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],
          [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],


        [[[-1.9124, -1.9980, -1.9467,  ..., -0.1486, -0.1486, -0.1486],
          [-1.9467, -1.9638, -1.9980,  ..., -0.1486, -0.1486, -0.1486],
          [-1.9295, -1.9295, -1.9467,  ..., -0.1486, -0.1486, -0.1486],
          ...,
          [-0.1314, -0.1486, -0.1486,  ...,  0.0741,  0.0741,  0.0741],
          [-0.1486, -0.1143, -0.2856,  ...,  0.0912,  0.0912,  0.0912],
          [-0.2513, -0.1486, -0.1657,  ...,  0.0056,  0.0056,  0.0056]],

         [[-1.8256, -1.9132, -1.8606,  ..., -0.0224, -0.0224, -0.0224],
          [-1.8606, -1.8782, -1.9132,  ..., -0.0224, -0.0224, -0.0224],
          [-1.8431, -1.8431, -1.8606,  ..., -0.0224, -0.0224, -0.0224],
          ...,
          [-0.0049, -0.0224, -0.0224,  ...,  0.2052,  0.2052,  0.2052],
          [-0.0224,  0.0126, -0.1625,  ...,  0.2227,  0.2227,  0.2227],
          [-0.1275, -0.0224, -0.0399,  ...,  0.1352,  0.1352,  0.1352]],

         [[-1.5953, -1.6824, -1.6302,  ...,  0.1999,  0.1999,  0.1999],
          [-1.6302, -1.6476, -1.6824,  ...,  0.1999,  0.1999,  0.1999],
          [-1.6127, -1.6127, -1.6302,  ...,  0.1999,  0.1999,  0.1999],
          ...,
          [ 0.2173,  0.1999,  0.1999,  ...,  0.4265,  0.4265,  0.4265],
          [ 0.1999,  0.2348,  0.0605,  ...,  0.4439,  0.4439,  0.4439],
          [ 0.0953,  0.1999,  0.1825,  ...,  0.3568,  0.3568,  0.3568]]],


        [[[-0.0116, -0.0116, -0.0972,  ...,  0.3309,  0.3309,  0.3309],
          [-0.0287, -0.0116, -0.0287,  ...,  0.4508,  0.4508,  0.4508],
          [-0.1314, -0.0801, -0.0116,  ...,  0.3652,  0.3652,  0.3652],
          ...,
          [-1.4158, -1.4158, -1.4329,  ..., -0.4054, -0.4054, -0.4054],
          [-1.4672, -1.4672, -1.5014,  ..., -0.4568, -0.4568, -0.4568],
          [-1.3987, -1.5014, -1.5528,  ..., -0.4226, -0.4226, -0.4226]],

         [[ 0.1176,  0.1176,  0.0301,  ...,  0.4678,  0.4678,  0.4678],
          [ 0.1001,  0.1176,  0.1001,  ...,  0.5903,  0.5903,  0.5903],
          [-0.0049,  0.0476,  0.1176,  ...,  0.5028,  0.5028,  0.5028],
          ...,
          [-1.3179, -1.3179, -1.3354,  ..., -0.2850, -0.2850, -0.2850],
          [-1.3704, -1.3704, -1.4055,  ..., -0.3375, -0.3375, -0.3375],
          [-1.3004, -1.4055, -1.4580,  ..., -0.3025, -0.3025, -0.3025]],

         [[ 0.3393,  0.3393,  0.2522,  ...,  0.6879,  0.6879,  0.6879],
          [ 0.3219,  0.3393,  0.3219,  ...,  0.8099,  0.8099,  0.8099],
          [ 0.2173,  0.2696,  0.3393,  ...,  0.7228,  0.7228,  0.7228],
          ...,
          [-1.0898, -1.0898, -1.1073,  ..., -0.0615, -0.0615, -0.0615],
          [-1.1421, -1.1421, -1.1770,  ..., -0.1138, -0.1138, -0.1138],
          [-1.0724, -1.1770, -1.2293,  ..., -0.0790, -0.0790, -0.0790]]],


        ...,


        [[[-1.2445, -1.3473, -1.3987,  ..., -0.3712, -0.3712, -0.3712],
          [-1.2445, -1.3302, -1.3815,  ..., -0.4054, -0.4054, -0.4054],
          [-1.2788, -1.3130, -1.3130,  ..., -0.3883, -0.3883, -0.3883],
          ...,
          [ 0.7591,  0.9132,  0.7591,  ...,  0.8104,  0.8104,  0.8104],
          [ 0.7077,  0.7419,  0.7591,  ...,  0.8447,  0.8447,  0.8447],
          [ 0.8276,  0.7077,  0.6906,  ...,  0.7591,  0.7591,  0.7591]],

         [[-1.1429, -1.2479, -1.3004,  ..., -0.2500, -0.2500, -0.2500],
          [-1.1429, -1.2304, -1.2829,  ..., -0.2850, -0.2850, -0.2850],
          [-1.1779, -1.2129, -1.2129,  ..., -0.2675, -0.2675, -0.2675],
          ...,
          [ 0.9055,  1.0630,  0.9055,  ...,  0.9580,  0.9580,  0.9580],
          [ 0.8529,  0.8880,  0.9055,  ...,  0.9930,  0.9930,  0.9930],
          [ 0.9755,  0.8529,  0.8354,  ...,  0.9055,  0.9055,  0.9055]],

         [[-0.9156, -1.0201, -1.0724,  ..., -0.0267, -0.0267, -0.0267],
          [-0.9156, -1.0027, -1.0550,  ..., -0.0615, -0.0615, -0.0615],
          [-0.9504, -0.9853, -0.9853,  ..., -0.0441, -0.0441, -0.0441],
          ...,
          [ 1.1237,  1.2805,  1.1237,  ...,  1.1759,  1.1759,  1.1759],
          [ 1.0714,  1.1062,  1.1237,  ...,  1.2108,  1.2108,  1.2108],
          [ 1.1934,  1.0714,  1.0539,  ...,  1.1237,  1.1237,  1.1237]]],


        [[[ 0.0056, -0.1143, -0.0287,  ...,  0.4679,  0.4679,  0.4679],
          [-0.1143, -0.0972, -0.0287,  ...,  0.4337,  0.4337,  0.4337],
          [-0.1828, -0.0629, -0.0629,  ...,  0.3652,  0.3652,  0.3652],
          ...,
          [ 1.5468,  1.5468,  1.4954,  ...,  1.1872,  1.1872,  1.1872],
          [ 1.5810,  1.5297,  1.4612,  ...,  1.3584,  1.3584,  1.3584],
          [ 1.5468,  1.5468,  1.5297,  ...,  1.0673,  1.0673,  1.0673]],

         [[ 0.1352,  0.0126,  0.1001,  ...,  0.6078,  0.6078,  0.6078],
          [ 0.0126,  0.0301,  0.1001,  ...,  0.5728,  0.5728,  0.5728],
          [-0.0574,  0.0651,  0.0651,  ...,  0.5028,  0.5028,  0.5028],
          ...,
          [ 1.7108,  1.7108,  1.6583,  ...,  1.3431,  1.3431,  1.3431],
          [ 1.7458,  1.6933,  1.6232,  ...,  1.5182,  1.5182,  1.5182],
          [ 1.7108,  1.7108,  1.6933,  ...,  1.2206,  1.2206,  1.2206]],

         [[ 0.3568,  0.2348,  0.3219,  ...,  0.8274,  0.8274,  0.8274],
          [ 0.2348,  0.2522,  0.3219,  ...,  0.7925,  0.7925,  0.7925],
          [ 0.1651,  0.2871,  0.2871,  ...,  0.7228,  0.7228,  0.7228],
          ...,
          [ 1.9254,  1.9254,  1.8731,  ...,  1.5594,  1.5594,  1.5594],
          [ 1.9603,  1.9080,  1.8383,  ...,  1.7337,  1.7337,  1.7337],
          [ 1.9254,  1.9254,  1.9080,  ...,  1.4374,  1.4374,  1.4374]]],


        [[[ 0.7077,  0.6392,  0.7077,  ...,  0.8276,  0.8276,  0.8276],
          [ 0.6221,  0.6563,  0.6906,  ...,  0.7591,  0.7591,  0.7591],
          [ 0.7248,  0.7077,  0.6906,  ...,  0.8961,  0.8961,  0.8961],
          ...,
          [-0.0629, -0.0458, -0.0458,  ...,  0.2967,  0.2967,  0.2967],
          [-0.0629, -0.0629, -0.0801,  ...,  0.2453,  0.2453,  0.2453],
          [-0.0116, -0.0629, -0.0287,  ...,  0.2453,  0.2453,  0.2453]],

         [[ 0.8529,  0.7829,  0.8529,  ...,  0.9755,  0.9755,  0.9755],
          [ 0.7654,  0.8004,  0.8354,  ...,  0.9055,  0.9055,  0.9055],
          [ 0.8704,  0.8529,  0.8354,  ...,  1.0455,  1.0455,  1.0455],
          ...,
          [ 0.0651,  0.0826,  0.0826,  ...,  0.4328,  0.4328,  0.4328],
          [ 0.0651,  0.0651,  0.0476,  ...,  0.3803,  0.3803,  0.3803],
          [ 0.1176,  0.0651,  0.1001,  ...,  0.3803,  0.3803,  0.3803]],

         [[ 1.0714,  1.0017,  1.0714,  ...,  1.1934,  1.1934,  1.1934],
          [ 0.9842,  1.0191,  1.0539,  ...,  1.1237,  1.1237,  1.1237],
          [ 1.0888,  1.0714,  1.0539,  ...,  1.2631,  1.2631,  1.2631],
          ...,
          [ 0.2871,  0.3045,  0.3045,  ...,  0.6531,  0.6531,  0.6531],
          [ 0.2871,  0.2871,  0.2696,  ...,  0.6008,  0.6008,  0.6008],
          [ 0.3393,  0.2871,  0.3219,  ...,  0.6008,  0.6008,  0.6008]]]],
       device='cuda:0')
(Pdb) torch.Size([8, 3, 384, 768])
(Pdb) 119  	        results_dict = {}
120  	        flow_preds = []
121  	
122  	        if task == 'flow':
123  	            # stereo and depth tasks have normalized img in dataloader
124  	            img0, img1 = normalize_img(img0, img1)  # [B, 3, H, W]
125  	
126  	        # list of features, resolution low to high
127  	        feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
128  	
129  	        flow = None
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(116)forward()
-> if task == 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(119)forward()
-> results_dict = {}
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(120)forward()
-> flow_preds = []
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(122)forward()
-> if task == 'flow':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(127)forward()
-> feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(129)forward()
-> flow = None
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(131)forward()
-> if task != 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(132)forward()
-> assert len(attn_splits_list) == len(corr_radius_list) == len(prop_radius_list) == self.num_scales
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(136)forward()
-> for scale_idx in range(self.num_scales):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(137)forward()
-> feature0, feature1 = feature0_list[scale_idx], feature1_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(139)forward()
-> if pred_bidir_flow and scale_idx > 0:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(143)forward()
-> feature0_ori, feature1_ori = feature0, feature1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(145)forward()
-> upsample_factor = self.upsample_factor * (2 ** (self.num_scales - 1 - scale_idx))
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(147)forward()
-> if task == 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(152)forward()
-> if scale_idx > 0:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(156)forward()
-> if flow is not None:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(172)forward()
-> attn_splits = attn_splits_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(173)forward()
-> if task != 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(174)forward()
-> corr_radius = corr_radius_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(175)forward()
-> prop_radius = prop_radius_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(178)forward()
-> feature0, feature1 = feature_add_position(feature0, feature1, attn_splits, self.feature_channels)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(182)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(183)forward()
-> attn_num_splits=attn_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 15.75 GiB total capacity; 14.19 GiB already allocated; 67.12 MiB free; 14.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) 176  	
177  	            # add position to features
178  	            feature0, feature1 = feature_add_position(feature0, feature1, attn_splits, self.feature_channels)
179  	
180  	            # Transformer
181  ->	            feature0, feature1 = self.transformer(feature0, feature1,
182  	                                                  attn_type=attn_type,
183  	                                                  attn_num_splits=attn_splits,
184  	                                                  )
185  	
186  	            # correlation and softmax
(Pdb) 15236477440
(Pdb) I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 616, in <module>
    print(f"computed in {time.time()-a} sec")
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 410, in main
    attn_type=args.attn_type,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 181, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/usr/lib/python3.9/bdb.py", line 94, in trace_dispatch
    return self.dispatch_exception(frame, arg)
  File "/usr/lib/python3.9/bdb.py", line 174, in dispatch_exception
    if self.quitting: raise BdbQuit
bdb.BdbQuit
2023-03-02 11:34:35.523218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 11:34:35.606866: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 11:34:35.968686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:34:35.968719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 11:34:35.968722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(122)forward()
-> if task == 'flow':
(Pdb) 130291712
(Pdb) 130_291_712
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(127)forward()
-> feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
(Pdb) 130_291_712
(Pdb) 
Documented commands (type help <topic>):
========================================
EOF    c          d        h         list      q        rv       undisplay
a      cl         debug    help      ll        quit     s        unt      
alias  clear      disable  ignore    longlist  r        source   until    
args   commands   display  interact  n         restart  step     up       
b      condition  down     j         next      return   tbreak   w        
break  cont       enable   jump      p         retval   u        whatis   
bt     continue   exit     l         pp        run      unalias  where    

Miscellaneous help topics:
==========================
exec  pdb

(Pdb)   /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(615)<module>()
-> main(args)
  /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py(409)main()
-> pred_disps = model(left, right,
  /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()
-> return forward_call(*input, **kwargs)
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(127)forward()
-> feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
(Pdb) 122  	        if task == 'flow':
123  	            # stereo and depth tasks have normalized img in dataloader
124  	            img0, img1 = normalize_img(img0, img1)  # [B, 3, H, W]
125  	
126  	        # list of features, resolution low to high
127  ->	        feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
128  	
129  	        flow = None
130  	
131  	        if task != 'depth':
132  	            assert len(attn_splits_list) == len(corr_radius_list) == len(prop_radius_list) == self.num_scales
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(129)forward()
-> flow = None
(Pdb) 7_057_369_088
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(131)forward()
-> if task != 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(132)forward()
-> assert len(attn_splits_list) == len(corr_radius_list) == len(prop_radius_list) == self.num_scales
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(136)forward()
-> for scale_idx in range(self.num_scales):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(137)forward()
-> feature0, feature1 = feature0_list[scale_idx], feature1_list[scale_idx]
(Pdb) 7_057_369_088
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(139)forward()
-> if pred_bidir_flow and scale_idx > 0:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(143)forward()
-> feature0_ori, feature1_ori = feature0, feature1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(145)forward()
-> upsample_factor = self.upsample_factor * (2 ** (self.num_scales - 1 - scale_idx))
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(147)forward()
-> if task == 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(152)forward()
-> if scale_idx > 0:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(156)forward()
-> if flow is not None:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(172)forward()
-> attn_splits = attn_splits_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(173)forward()
-> if task != 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(174)forward()
-> corr_radius = corr_radius_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(175)forward()
-> prop_radius = prop_radius_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(178)forward()
-> feature0, feature1 = feature_add_position(feature0, feature1, attn_splits, self.feature_channels)
(Pdb) --Call--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(111)feature_add_position()
-> def feature_add_position(feature0, feature1, attn_splits, feature_channels):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(112)feature_add_position()
-> pos_enc = PositionEmbeddingSine(num_pos_feats=feature_channels // 2)
(Pdb) --Call--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(15)__init__()
-> def __init__(self, num_pos_feats=64, temperature=10000, normalize=True, scale=None):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(16)__init__()
-> super().__init__()
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(309)__init__()
-> def __init__(self) -> None:
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(313)__init__()
-> torch._C._log_api_usage_once("python.nn_module")
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(321)__init__()
-> super().__setattr__('training', True)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(322)__init__()
-> super().__setattr__('_parameters', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(323)__init__()
-> super().__setattr__('_buffers', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(324)__init__()
-> super().__setattr__('_non_persistent_buffers_set', set())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(325)__init__()
-> super().__setattr__('_backward_hooks', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(326)__init__()
-> super().__setattr__('_is_full_backward_hook', None)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(327)__init__()
-> super().__setattr__('_forward_hooks', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(328)__init__()
-> super().__setattr__('_forward_pre_hooks', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(329)__init__()
-> super().__setattr__('_state_dict_hooks', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(330)__init__()
-> super().__setattr__('_load_state_dict_pre_hooks', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(331)__init__()
-> super().__setattr__('_load_state_dict_post_hooks', OrderedDict())
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(332)__init__()
-> super().__setattr__('_modules', OrderedDict())
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(332)__init__()->None
-> super().__setattr__('_modules', OrderedDict())
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(17)__init__()
-> self.num_pos_feats = num_pos_feats
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(18)__init__()
-> self.temperature = temperature
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(19)__init__()
-> self.normalize = normalize
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(20)__init__()
-> if scale is not None and normalize is False:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(22)__init__()
-> if scale is None:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(23)__init__()
-> scale = 2 * math.pi
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(24)__init__()
-> self.scale = scale
(Pdb) --Return--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/position.py(24)__init__()->None
-> self.scale = scale
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(114)feature_add_position()
-> if attn_splits > 1:  # add position in splited window
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(115)feature_add_position()
-> feature0_splits = split_feature(feature0, num_splits=attn_splits)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(116)feature_add_position()
-> feature1_splits = split_feature(feature1, num_splits=attn_splits)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(118)feature_add_position()
-> position = pos_enc(feature0_splits)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(120)feature_add_position()
-> feature0_splits = feature0_splits + position
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(121)feature_add_position()
-> feature1_splits = feature1_splits + position
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(123)feature_add_position()
-> feature0 = merge_splits(feature0_splits, num_splits=attn_splits)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(124)feature_add_position()
-> feature1 = merge_splits(feature1_splits, num_splits=attn_splits)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(131)feature_add_position()
-> return feature0, feature1
(Pdb) --Return--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(131)feature_add_position()->(tensor([[[[ 0...iewBackward0>), tensor([[[[ 1...iewBackward0>))
-> return feature0, feature1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(182)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(183)forward()
-> attn_num_splits=attn_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 15.75 GiB total capacity; 14.19 GiB already allocated; 67.12 MiB free; 14.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) --Return--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()->None
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) 2023-03-02 13:05:11.252178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:05:11.336007: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:05:11.696073: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:05:11.696105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:05:11.696108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(181)forward()
-> print(f"{torch.cuda.memory_allocated(0):_d}")
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(315)memory_allocated()
-> def memory_allocated(device: Union[Device, int] = None) -> int:
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(330)memory_allocated()
-> return memory_stats(device=device).get("allocated_bytes.all.current", 0)
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(128)memory_stats()
-> def memory_stats(device: Union[Device, int] = None) -> Dict[str, Any]:
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(198)memory_stats()
-> result = []
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(200)memory_stats()
-> def _recurse_add_to_result(prefix, obj):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(209)memory_stats()
-> stats = memory_stats_as_nested_dict(device=device)
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(216)memory_stats_as_nested_dict()
-> def memory_stats_as_nested_dict(device: Union[Device, int] = None) -> Dict[str, Any]:
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(218)memory_stats_as_nested_dict()
-> if not is_initialized():
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/__init__.py(158)is_initialized()
-> def is_initialized():
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/__init__.py(160)is_initialized()
-> return _initialized and not _is_in_bad_fork()
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/__init__.py(160)is_initialized()->True
-> return _initialized and not _is_in_bad_fork()
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(220)memory_stats_as_nested_dict()
-> device = _get_device_index(device, optional=True)
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/_utils.py(7)_get_device_index()
-> def _get_device_index(device: Any, optional: bool = False,
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/_utils.py(23)_get_device_index()
-> if isinstance(device, str):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/_utils.py(25)_get_device_index()
-> if isinstance(device, torch.device):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/_utils.py(31)_get_device_index()
-> if not torch.jit.is_scripting():
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/_jit_internal.py(1082)is_scripting()
-> def is_scripting() -> bool:
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/_jit_internal.py(1101)is_scripting()
-> return False
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/_jit_internal.py(1101)is_scripting()->False
-> return False
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/_utils.py(32)_get_device_index()
-> if isinstance(device, torch.cuda.device):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/_utils.py(34)_get_device_index()
-> return _torch_get_device_index(device, optional, allow_cpu)
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/_utils.py(34)_get_device_index()->0
-> return _torch_get_device_index(device, optional, allow_cpu)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(221)memory_stats_as_nested_dict()
-> return torch._C._cuda_memoryStats(device)
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(221)memory_stats_as_nested_dict()->{'active': {'all': {'allocated': 440, 'current': 378, 'freed': 62, 'peak': 387}, 'large_pool': {'allocated': 90, 'current': 52, 'freed': 38, 'peak': 57}, 'small_pool': {'allocated': 350, 'current': 326, 'freed': 24, 'peak': 333}}, 'active_bytes': {'all': {'allocated': 23256762880, 'current': 7095117824, 'freed': 16161645056, 'peak': 9832101888}, 'large_pool': {'allocated': 23203702272, 'current': 7046692864, 'freed': 16157009408, 'peak': 9783808000}, 'small_pool': {'allocated': 53060608, 'current': 48424960, 'freed': 4635648, 'peak': 49253888}}, 'allocated_bytes': {'all': {'allocated': 23256762880, 'current': 7095117824, 'freed': 16161645056, 'peak': 9832101888}, 'large_pool': {'allocated': 23203702272, 'current': 7046692864, 'freed': 16157009408, 'peak': 9783808000}, 'small_pool': {'allocated': 53060608, 'current': 48424960, 'freed': 4635648, 'peak': 49253888}}, 'allocation': {'all': {'allocated': 440, 'current': 378, 'freed': 62, 'peak': 387}, 'large_pool': {'allocated': 90, 'current': 52, 'freed': 38, 'peak': 57}, 'small_pool': {'allocated': 350, 'current': 326, 'freed': 24, 'peak': 333}}, ...}
-> return torch._C._cuda_memoryStats(device)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(210)memory_stats()
-> _recurse_add_to_result("", stats)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(211)memory_stats()
-> result.sort()
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(213)memory_stats()
-> return collections.OrderedDict(result)
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(213)memory_stats()->OrderedDict([...l.peak', 24)])
-> return collections.OrderedDict(result)
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/cuda/memory.py(330)memory_allocated()->7095117824
-> return memory_stats(device=device).get("allocated_bytes.all.current", 0)
(Pdb) 7_095_117_824
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(183)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(184)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(185)forward()
-> attn_num_splits=attn_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(183)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1188)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1189)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1193)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) 7_095_117_824
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1193)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Call--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(226)forward()
-> def forward(self, feature0, feature1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(232)forward()
-> b, c, h, w = feature0.shape
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(233)forward()
-> assert self.d_model == c
(Pdb) 128
(Pdb) torch.Size([8, 128, 48, 96])
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(235)forward()
-> feature0 = feature0.flatten(-2).permute(0, 2, 1)  # [B, H*W, C]
(Pdb) torch.Size([8, 128, 48, 96])
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(236)forward()
-> feature1 = feature1.flatten(-2).permute(0, 2, 1)  # [B, H*W, C]
(Pdb) torch.Size([8, 4608, 128])
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(239)forward()
-> if 'swin' in attn_type and attn_num_splits > 1:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(241)forward()
-> window_size_h = h // attn_num_splits
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(242)forward()
-> window_size_w = w // attn_num_splits
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(245)forward()
-> shifted_window_attn_mask = generate_shift_window_attn_mask(
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(246)forward()
-> input_resolution=(h, w),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(247)forward()
-> window_size_h=window_size_h,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(248)forward()
-> window_size_w=window_size_w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(249)forward()
-> shift_size_h=window_size_h // 2,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(250)forward()
-> shift_size_w=window_size_w // 2,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(251)forward()
-> device=feature0.device,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(245)forward()
-> shifted_window_attn_mask = generate_shift_window_attn_mask(
(Pdb) 7_095_117_824
(Pdb) --Call--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(84)generate_shift_window_attn_mask()
-> def generate_shift_window_attn_mask(input_resolution, window_size_h, window_size_w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(88)generate_shift_window_attn_mask()
-> h, w = input_resolution
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(89)generate_shift_window_attn_mask()
-> img_mask = torch.zeros((1, h, w, 1)).to(device)  # 1 H W 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(90)generate_shift_window_attn_mask()
-> h_slices = (slice(0, -window_size_h),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(91)generate_shift_window_attn_mask()
-> slice(-window_size_h, -shift_size_h),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(92)generate_shift_window_attn_mask()
-> slice(-shift_size_h, None))
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(90)generate_shift_window_attn_mask()
-> h_slices = (slice(0, -window_size_h),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(93)generate_shift_window_attn_mask()
-> w_slices = (slice(0, -window_size_w),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(94)generate_shift_window_attn_mask()
-> slice(-window_size_w, -shift_size_w),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(95)generate_shift_window_attn_mask()
-> slice(-shift_size_w, None))
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(93)generate_shift_window_attn_mask()
-> w_slices = (slice(0, -window_size_w),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(96)generate_shift_window_attn_mask()
-> cnt = 0
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(97)generate_shift_window_attn_mask()
-> for h in h_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(97)generate_shift_window_attn_mask()
-> for h in h_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(97)generate_shift_window_attn_mask()
-> for h in h_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(99)generate_shift_window_attn_mask()
-> img_mask[:, h, w, :] = cnt
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(100)generate_shift_window_attn_mask()
-> cnt += 1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(98)generate_shift_window_attn_mask()
-> for w in w_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(97)generate_shift_window_attn_mask()
-> for h in h_slices:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(102)generate_shift_window_attn_mask()
-> mask_windows = split_feature(img_mask, num_splits=input_resolution[-1] // window_size_w, channel_last=True)
(Pdb) --Call--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(34)split_feature()
-> def split_feature(feature,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(38)split_feature()
-> if channel_last:  # [B, H, W, C]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(39)split_feature()
-> b, h, w, c = feature.size()
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(40)split_feature()
-> assert h % num_splits == 0 and w % num_splits == 0
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(42)split_feature()
-> b_new = b * num_splits * num_splits
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(43)split_feature()
-> h_new = h // num_splits
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(44)split_feature()
-> w_new = w // num_splits
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(46)split_feature()
-> feature = feature.view(b, num_splits, h // num_splits, num_splits, w // num_splits, c
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(47)split_feature()
-> ).permute(0, 1, 3, 2, 4, 5).reshape(b_new, h_new, w_new, c)  # [B*K*K, H/K, W/K, C]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(46)split_feature()
-> feature = feature.view(b, num_splits, h // num_splits, num_splits, w // num_splits, c
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(47)split_feature()
-> ).permute(0, 1, 3, 2, 4, 5).reshape(b_new, h_new, w_new, c)  # [B*K*K, H/K, W/K, C]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(46)split_feature()
-> feature = feature.view(b, num_splits, h // num_splits, num_splits, w // num_splits, c
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(59)split_feature()
-> return feature
(Pdb) --Return--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(59)split_feature()->tensor([[[[0....vice='cuda:0')
-> return feature
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(104)generate_shift_window_attn_mask()
-> mask_windows = mask_windows.view(-1, window_size_h * window_size_w)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(105)generate_shift_window_attn_mask()
-> attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(106)generate_shift_window_attn_mask()
-> attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(108)generate_shift_window_attn_mask()
-> return attn_mask
(Pdb) --Return--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py(108)generate_shift_window_attn_mask()->tensor([[[   ...vice='cuda:0')
-> return attn_mask
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(257)forward()
-> if 'swin1d' in attn_type and attn_num_splits > 1:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(258)forward()
-> window_size_w = w // attn_num_splits
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(261)forward()
-> shifted_window_attn_mask_1d = generate_shift_window_attn_mask_1d(
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(262)forward()
-> input_w=w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(263)forward()
-> window_size_w=window_size_w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(264)forward()
-> shift_size_w=window_size_w // 2,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(265)forward()
-> device=feature0.device,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(261)forward()
-> shifted_window_attn_mask_1d = generate_shift_window_attn_mask_1d(
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(271)forward()
-> concat0 = torch.cat((feature0, feature1), dim=0)  # [2B, H*W, C]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(272)forward()
-> concat1 = torch.cat((feature1, feature0), dim=0)  # [2B, H*W, C]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(274)forward()
-> for i, layer in enumerate(self.layers):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(276)forward()
-> height=h,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(277)forward()
-> width=w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(278)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(279)forward()
-> with_shift='swin' in attn_type and attn_num_splits > 1 and i % 2 == 1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(280)forward()
-> attn_num_splits=attn_num_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(281)forward()
-> shifted_window_attn_mask=shifted_window_attn_mask,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(282)forward()
-> shifted_window_attn_mask_1d=shifted_window_attn_mask_1d,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(286)forward()
-> concat1 = torch.cat(concat0.chunk(chunks=2, dim=0)[::-1], dim=0)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(274)forward()
-> for i, layer in enumerate(self.layers):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(276)forward()
-> height=h,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(277)forward()
-> width=w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(278)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(279)forward()
-> with_shift='swin' in attn_type and attn_num_splits > 1 and i % 2 == 1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(280)forward()
-> attn_num_splits=attn_num_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(281)forward()
-> shifted_window_attn_mask=shifted_window_attn_mask,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(282)forward()
-> shifted_window_attn_mask_1d=shifted_window_attn_mask_1d,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(286)forward()
-> concat1 = torch.cat(concat0.chunk(chunks=2, dim=0)[::-1], dim=0)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(274)forward()
-> for i, layer in enumerate(self.layers):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(276)forward()
-> height=h,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(277)forward()
-> width=w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(278)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(279)forward()
-> with_shift='swin' in attn_type and attn_num_splits > 1 and i % 2 == 1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(280)forward()
-> attn_num_splits=attn_num_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(281)forward()
-> shifted_window_attn_mask=shifted_window_attn_mask,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(282)forward()
-> shifted_window_attn_mask_1d=shifted_window_attn_mask_1d,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(286)forward()
-> concat1 = torch.cat(concat0.chunk(chunks=2, dim=0)[::-1], dim=0)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(274)forward()
-> for i, layer in enumerate(self.layers):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(276)forward()
-> height=h,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(277)forward()
-> width=w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(278)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(279)forward()
-> with_shift='swin' in attn_type and attn_num_splits > 1 and i % 2 == 1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(280)forward()
-> attn_num_splits=attn_num_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(281)forward()
-> shifted_window_attn_mask=shifted_window_attn_mask,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(282)forward()
-> shifted_window_attn_mask_1d=shifted_window_attn_mask_1d,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(286)forward()
-> concat1 = torch.cat(concat0.chunk(chunks=2, dim=0)[::-1], dim=0)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(274)forward()
-> for i, layer in enumerate(self.layers):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) 13_446_361_088
(Pdb) 13_446_361_088
(Pdb) 4
(Pdb) *** AttributeError: 'FeatureTransformer' object has no attribute 'layer'
(Pdb) ModuleList(
  (0): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (1): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (2): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (3): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (4): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (5): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(276)forward()
-> height=h,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(277)forward()
-> width=w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(278)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(279)forward()
-> with_shift='swin' in attn_type and attn_num_splits > 1 and i % 2 == 1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(280)forward()
-> attn_num_splits=attn_num_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(281)forward()
-> shifted_window_attn_mask=shifted_window_attn_mask,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(282)forward()
-> shifted_window_attn_mask_1d=shifted_window_attn_mask_1d,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(286)forward()
-> concat1 = torch.cat(concat0.chunk(chunks=2, dim=0)[::-1], dim=0)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(274)forward()
-> for i, layer in enumerate(self.layers):
(Pdb) 15_009_984_512
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(276)forward()
-> height=h,
(Pdb) 15_009_984_512
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(277)forward()
-> width=w,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(278)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(279)forward()
-> with_shift='swin' in attn_type and attn_num_splits > 1 and i % 2 == 1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(280)forward()
-> attn_num_splits=attn_num_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(281)forward()
-> shifted_window_attn_mask=shifted_window_attn_mask,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(282)forward()
-> shifted_window_attn_mask_1d=shifted_window_attn_mask_1d,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) --Call--
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1188)_call_impl()
-> def _call_impl(self, *input, **kwargs):
(Pdb) 15_009_984_512
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1189)_call_impl()
-> forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1193)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1193)_call_impl()
-> or _global_forward_hooks or _global_forward_pre_hooks):
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1192)_call_impl()
-> if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks
(Pdb) > /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 15.75 GiB total capacity; 14.19 GiB already allocated; 67.12 MiB free; 14.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()->None
-> return forward_call(*input, **kwargs)
(Pdb) torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 15.75 GiB total capacity; 14.19 GiB already allocated; 67.12 MiB free; 14.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(275)forward()
-> concat0 = layer(concat0, concat1,
(Pdb) 5
(Pdb) ModuleList(
  (0): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (1): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (2): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (3): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (4): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
  (5): TransformerBlock(
    (self_attn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
    (cross_attn_ffn): TransformerLayer(
      (q_proj): Linear(in_features=128, out_features=128, bias=False)
      (k_proj): Linear(in_features=128, out_features=128, bias=False)
      (v_proj): Linear(in_features=128, out_features=128, bias=False)
      (merge): Linear(in_features=128, out_features=128, bias=False)
      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (0): Linear(in_features=256, out_features=1024, bias=False)
        (1): GELU(approximate='none')
        (2): Linear(in_features=1024, out_features=128, bias=False)
      )
      (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    )
  )
)
(Pdb) 2023-03-02 13:45:51.675984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:45:51.759577: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:45:52.120435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:45:52.120470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:45:52.120473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
3_577_559_040
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(294)forward()
-> return feature0, feature1
(Pdb) 2023-03-02 13:46:32.483549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:46:32.567809: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:46:32.929037: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:46:32.929068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:46:32.929071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
8_346_304_512
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(295)forward()
-> return feature0, feature1
(Pdb) --Return--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py(295)forward()->(tensor([[[[-8...oneBackward0>), tensor([[[[ 7...oneBackward0>))
-> return feature0, feature1
(Pdb) --Return--
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()->(tensor([[[[-8...oneBackward0>), tensor([[[[ 7...oneBackward0>))
-> return forward_call(*input, **kwargs)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(186)forward()
-> print(f"{torch.cuda.memory_allocated(0):_d}")
(Pdb) 8_268_429_312
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(189)forward()
-> if task == 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(205)forward()
-> if corr_radius == -1:  # global matching
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(206)forward()
-> if task == 'flow':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(208)forward()
-> elif task == 'stereo':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(209)forward()
-> flow_pred = global_correlation_softmax_stereo(feature0, feature1)[0]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(221)forward()
-> flow = flow + flow_pred if flow is not None else flow_pred
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(223)forward()
-> if task == 'stereo':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(224)forward()
-> flow = flow.clamp(min=0)  # positive disparity
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(227)forward()
-> if self.training:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(228)forward()
-> flow_bilinear = self.upsample_flow(flow, None, bilinear=True, upsample_factor=upsample_factor,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(229)forward()
-> is_depth=task == 'depth')
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(228)forward()
-> flow_bilinear = self.upsample_flow(flow, None, bilinear=True, upsample_factor=upsample_factor,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(230)forward()
-> flow_preds.append(flow_bilinear)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(233)forward()
-> if (pred_bidir_flow or pred_bidir_depth) and scale_idx == 0:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(236)forward()
-> flow = self.feature_flow_attn(feature0, flow.detach(),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(237)forward()
-> local_window_attn=prop_radius > 0,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(238)forward()
-> local_window_radius=prop_radius,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(236)forward()
-> flow = self.feature_flow_attn(feature0, flow.detach(),
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(242)forward()
-> if self.training and scale_idx < self.num_scales - 1:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(243)forward()
-> flow_up = self.upsample_flow(flow, feature0, bilinear=True,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(244)forward()
-> upsample_factor=upsample_factor,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(245)forward()
-> is_depth=task == 'depth')
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(243)forward()
-> flow_up = self.upsample_flow(flow, feature0, bilinear=True,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(246)forward()
-> flow_preds.append(flow_up)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(248)forward()
-> if scale_idx == self.num_scales - 1:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(135)forward()
-> for scale_idx in range(self.num_scales):
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(136)forward()
-> feature0, feature1 = feature0_list[scale_idx], feature1_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(138)forward()
-> if pred_bidir_flow and scale_idx > 0:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(142)forward()
-> feature0_ori, feature1_ori = feature0, feature1
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(144)forward()
-> upsample_factor = self.upsample_factor * (2 ** (self.num_scales - 1 - scale_idx))
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(146)forward()
-> if task == 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(151)forward()
-> if scale_idx > 0:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(152)forward()
-> assert task != 'depth'  # not supported for multi-scale depth model
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(153)forward()
-> flow = F.interpolate(flow, scale_factor=2, mode='bilinear', align_corners=True) * 2
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(155)forward()
-> if flow is not None:
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(156)forward()
-> assert task != 'depth'
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(157)forward()
-> flow = flow.detach()
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(159)forward()
-> if task == 'stereo':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(162)forward()
-> zeros = torch.zeros_like(flow)  # [B, 1, H, W]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(164)forward()
-> displace = torch.cat((-flow, zeros), dim=1)  # [B, 2, H, W]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(165)forward()
-> feature1 = flow_warp(feature1, displace)  # [B, C, H, W]
(Pdb) /home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(171)forward()
-> attn_splits = attn_splits_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(172)forward()
-> if task != 'depth':
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(173)forward()
-> corr_radius = corr_radius_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(174)forward()
-> prop_radius = prop_radius_list[scale_idx]
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(177)forward()
-> feature0, feature1 = feature_add_position(feature0, feature1, attn_splits, self.feature_channels)
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(182)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(183)forward()
-> attn_type=attn_type,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(184)forward()
-> attn_num_splits=attn_splits,
(Pdb) > /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(182)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.09 GiB already allocated; 33.12 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(182)forward()
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) --Return--
> /home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py(182)forward()->None
-> feature0, feature1 = self.transformer(feature0, feature1,
(Pdb) torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.09 GiB already allocated; 33.12 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
> /home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py(1194)_call_impl()
-> return forward_call(*input, **kwargs)
(Pdb) Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 166, in main
    model = UniMatch(feature_channels=args.feature_channels,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
2023-03-02 13:48:46.347288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:48:46.431301: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:48:46.794640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:48:46.794672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:48:46.794676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
8_346_304_512
8_268_429_312
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 409, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 275, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 190, in forward
    source = self.cross_attn_ffn(source, target,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 138, in forward
    message = self.norm1(message)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.09 GiB already allocated; 33.12 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 13:50:04.140354: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:50:04.224247: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:50:04.584757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:50:04.584791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:50:04.584795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=64, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 409, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 126, in forward
    feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 66, in extract_feature
    features = self.backbone(concat)  # list of [2B, C, H, W], resolution from high to low
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/backbone.py", line 106, in forward
    x = self.layer1(x)  # 1/2
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/backbone.py", line 31, in forward
    y = self.relu(self.norm2(self.conv2(y)))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 74, in forward
    return self._apply_instance_norm(input)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/instancenorm.py", line 34, in _apply_instance_norm
    return F.instance_norm(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2495, in instance_norm
    return torch.instance_norm(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.25 GiB (GPU 0; 15.75 GiB total capacity; 12.24 GiB already allocated; 2.06 GiB free; 12.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 13:51:21.943174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:51:22.027310: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:51:22.394120: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:51:22.394160: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:51:22.394166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
4_214_526_976
4_164_963_328
12_344_931_840
12_210_433_536
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 409, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 282, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 1021.12 MiB free; 13.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 13:53:28.597901: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:53:28.681350: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:53:29.048169: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:53:29.048203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:53:29.048206: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
I'm in READ IMAGE (475, 605, 3)
I'm in READ IMAGE (950, 1210, 3)
2.0959978103637695 Go allocated in layer 0
2.460057258605957 Go allocated in layer 1
2.8241167068481445 Go allocated in layer 2
3.188176155090332 Go allocated in layer 3
3.5522356033325195 Go allocated in layer 4
3.916295051574707 Go allocated in layer 5
4_164_963_328
5.3973212242126465 Go allocated in layer 0
6.6096625328063965 Go allocated in layer 1
7.8220038414001465 Go allocated in layer 2
9.035321712493896 Go allocated in layer 3
10.248639583587646 Go allocated in layer 4
11.461957454681396 Go allocated in layer 5
12_210_433_536
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 409, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 282, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 1021.12 MiB free; 13.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 13:54:58.334482: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:54:58.420356: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:54:58.784862: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:54:58.784894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:54:58.784898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2.0959978103637695 Go allocated in layer 0
2.460057258605957 Go allocated in layer 1
2.8241167068481445 Go allocated in layer 2
3.188176155090332 Go allocated in layer 3
3.5522356033325195 Go allocated in layer 4
3.916295051574707 Go allocated in layer 5
5.3973212242126465 Go allocated in layer 0
6.6096625328063965 Go allocated in layer 1
7.8220038414001465 Go allocated in layer 2
9.035321712493896 Go allocated in layer 3
10.248639583587646 Go allocated in layer 4
11.461957454681396 Go allocated in layer 5
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 615, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 409, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 282, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 1021.12 MiB free; 13.32 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 13:56:43.524771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 13:56:43.609674: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 13:56:43.973275: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:56:43.973309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 13:56:43.973312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2.0959978103637695 Go allocated in layer 0
2.460057258605957 Go allocated in layer 1
2.8241167068481445 Go allocated in layer 2
3.188176155090332 Go allocated in layer 3
3.5522356033325195 Go allocated in layer 4
3.916295051574707 Go allocated in layer 5
5.3973212242126465 Go allocated in layer 0
6.6096625328063965 Go allocated in layer 1
7.8220038414001465 Go allocated in layer 2
9.035321712493896 Go allocated in layer 3
10.248639583587646 Go allocated in layer 4
11.461957454681396 Go allocated in layer 5
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 282, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 23, in <module>
    from unimatch.unimatch import UniMatch
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 6, in <module>
    from .transformer import FeatureTransformer
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 7
    from .gpu_management import free_memory
    ^
SyntaxError: invalid syntax
2023-03-02 14:07:50.631108: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:07:50.715864: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:07:51.077748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:07:51.077780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:07:51.077784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2.0959978103637695 Go allocated in layer 0
2.460057258605957 Go allocated in layer 1
2.8241167068481445 Go allocated in layer 2
3.188176155090332 Go allocated in layer 3
3.5522356033325195 Go allocated in layer 4
3.916295051574707 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 4205089792}
Current reserved memory: {'cuda:0': 8392802304}
Maximum allocated memory: {'cuda:0': 8193940480}
Maximum reserved memory: {'cuda:0': 8392802304}
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 4205089792}
Current reserved memory: {'cuda:0': 8392802304}
Maximum allocated memory: {'cuda:0': 8193940480}
Maximum reserved memory: {'cuda:0': 8392802304}
Suggested GPU: 0
5.3973212242126465 Go allocated in layer 0
6.6096625328063965 Go allocated in layer 1
7.8220038414001465 Go allocated in layer 2
9.035321712493896 Go allocated in layer 3
10.248639583587646 Go allocated in layer 4
11.461957454681396 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 12307183104}
Current reserved memory: {'cuda:0': 12431917056}
Maximum allocated memory: {'cuda:0': 12420429824}
Maximum reserved memory: {'cuda:0': 12545163264}
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 12307183104}
Current reserved memory: {'cuda:0': 12431917056}
Maximum allocated memory: {'cuda:0': 12420429824}
Maximum reserved memory: {'cuda:0': 12545163264}
Suggested GPU: 0
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 282, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:09:41.797634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:09:41.881151: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:09:42.245000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:09:42.245035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:09:42.245039: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2.0959978103637695 Go allocated in layer 0
2.460057258605957 Go allocated in layer 1
2.8241167068481445 Go allocated in layer 2
3.188176155090332 Go allocated in layer 3
3.5522356033325195 Go allocated in layer 4
3.916295051574707 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 4205089792}
Current reserved memory: {'cuda:0.0': 8392802304}
Maximum allocated memory: {'cuda:0.0': 8193940480}
Maximum reserved memory: {'cuda:0.0': 8392802304}
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 4205089792}
Current reserved memory: {'cuda:0.0': 8392802304}
Maximum allocated memory: {'cuda:0.0': 8193940480}
Maximum reserved memory: {'cuda:0.0': 8392802304}
Suggested GPU: 0
5.3973212242126465 Go allocated in layer 0
6.6096625328063965 Go allocated in layer 1
7.8220038414001465 Go allocated in layer 2
9.035321712493896 Go allocated in layer 3
10.248639583587646 Go allocated in layer 4
11.461957454681396 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 12307183104}
Current reserved memory: {'cuda:0.0': 12431917056}
Maximum allocated memory: {'cuda:0.0': 12420429824}
Maximum reserved memory: {'cuda:0.0': 12545163264}
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 12307183104}
Current reserved memory: {'cuda:0.0': 12431917056}
Maximum allocated memory: {'cuda:0.0': 12420429824}
Maximum reserved memory: {'cuda:0.0': 12545163264}
Suggested GPU: 0
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 282, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:12:49.698894: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:12:49.786610: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:12:50.156331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:12:50.156365: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:12:50.156368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2.0959978103637695 Go allocated in layer 0
2.460057258605957 Go allocated in layer 1
2.8241167068481445 Go allocated in layer 2
3.188176155090332 Go allocated in layer 3
3.5522356033325195 Go allocated in layer 4
3.916295051574707 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 4205089792}
Current reserved memory: {'cuda:0.0': 8392802304}
Maximum allocated memory: {'cuda:0.0': 8193940480}
Maximum reserved memory: {'cuda:0.0': 8392802304}
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 4205089792}
Current reserved memory: {'cuda:0.0': 8392802304}
Maximum allocated memory: {'cuda:0.0': 8193940480}
Maximum reserved memory: {'cuda:0.0': 8392802304}
Suggested GPU: 0
5.3973212242126465 Go allocated in layer 0
6.6096625328063965 Go allocated in layer 1
7.8220038414001465 Go allocated in layer 2
9.035321712493896 Go allocated in layer 3
10.248639583587646 Go allocated in layer 4
11.461957454681396 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 12307183104}
Current reserved memory: {'cuda:0.0': 12545163264}
Maximum allocated memory: {'cuda:0.0': 12420429824}
Maximum reserved memory: {'cuda:0.0': 12545163264}
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 12307183104}
Current reserved memory: {'cuda:0.0': 12431917056}
Maximum allocated memory: {'cuda:0.0': 12420429824}
Maximum reserved memory: {'cuda:0.0': 12545163264}
Suggested GPU: 0
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 282, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:15:14.567675: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:15:14.653562: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:15:15.021224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:15:15.021259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:15:15.021262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=32, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 126, in forward
    feature0_list, feature1_list = self.extract_feature(img0, img1)  # list of features
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 66, in extract_feature
    features = self.backbone(concat)  # list of [2B, C, H, W], resolution from high to low
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/backbone.py", line 107, in forward
    x = self.layer2(x)  # 1/4
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/backbone.py", line 30, in forward
    y = self.relu(self.norm1(self.conv1(y)))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB (GPU 0; 15.75 GiB total capacity; 14.02 GiB already allocated; 279.12 MiB free; 14.04 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:16:00.615375: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:16:00.699737: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:16:01.063711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:16:01.063752: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:16:01.063758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=16, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 276, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 181, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 108, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 15.75 GiB total capacity; 13.74 GiB already allocated; 431.12 MiB free; 13.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:17:24.034216: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:17:24.118610: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:17:24.484596: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:17:24.484628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:17:24.484632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=8, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
8.154186248779297 Go allocated in layer 0
9.610424041748047 Go allocated in layer 1
11.066661834716797 Go allocated in layer 2
12.522899627685547 Go allocated in layer 3
13.979137420654297 Go allocated in layer 4
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 276, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 181, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 108, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 15.75 GiB total capacity; 14.19 GiB already allocated; 65.12 MiB free; 14.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:19:04.524101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:19:04.610133: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:19:04.974579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:19:04.974613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:19:04.974617: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
4.11492919921875 Go allocated in layer 0
4.843048095703125 Go allocated in layer 1
5.5711669921875 Go allocated in layer 2
6.299285888671875 Go allocated in layer 3
7.02740478515625 Go allocated in layer 4
7.755523681640625 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 8327430144}
Current reserved memory: {'cuda:0.0': 9546235904}
Maximum allocated memory: {'cuda:0.0': 9533429760}
Maximum reserved memory: {'cuda:0.0': 9546235904}
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0.0': 8327430144}
Current reserved memory: {'cuda:0.0': 9546235904}
Maximum allocated memory: {'cuda:0.0': 9533429760}
Maximum reserved memory: {'cuda:0.0': 9546235904}
Suggested GPU: 0
10.717897891998291 Go allocated in layer 0
13.142580509185791 Go allocated in layer 1
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 276, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 191, in forward
    source = self.cross_attn_ffn(source, target,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 139, in forward
    message = self.norm1(message)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.09 GiB already allocated; 37.12 MiB free; 14.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 23, in <module>
    from unimatch.unimatch import UniMatch
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 6, in <module>
    from .transformer import FeatureTransformer
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 7, in <module>
    from .gpu_management import free_memory
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/gpu_management.py", line 37
    print('Current allocated memory:', {f'cuda:{k}': v/1024**3 for k, v in cur_allocated_mem.items(), ' Go'})
                                                                                                    ^
SyntaxError: invalid syntax
2023-03-02 14:20:57.740135: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:20:57.823631: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:20:58.190444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:20:58.190482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:20:58.190487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
4.11492919921875 Go allocated in layer 0
4.843048095703125 Go allocated in layer 1
5.5711669921875 Go allocated in layer 2
6.299285888671875 Go allocated in layer 3
7.02740478515625 Go allocated in layer 4
7.755523681640625 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 7.755523681640625}  Go
Current reserved memory: {'cuda:0': 8.89453125}  Go
Maximum allocated memory: {'cuda:0': 8.878698348999023}  Go
Maximum reserved memory: {'cuda:0': 8.89453125}  Go
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 7.755523681640625}  Go
Current reserved memory: {'cuda:0': 8.89453125}  Go
Maximum allocated memory: {'cuda:0': 8.878698348999023}  Go
Maximum reserved memory: {'cuda:0': 8.89453125}  Go
Suggested GPU: 0
10.717880725860596 Go allocated in layer 0
13.142563343048096 Go allocated in layer 1
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 276, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 191, in forward
    source = self.cross_attn_ffn(source, target,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 139, in forward
    message = self.norm1(message)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.09 GiB already allocated; 33.12 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:22:19.422334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:22:19.506500: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:22:19.871960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:22:19.871992: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:22:19.871996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
4.11492919921875 Go allocated in layer 0
4.843048095703125 Go allocated in layer 1
5.5711669921875 Go allocated in layer 2
6.299285888671875 Go allocated in layer 3
7.02740478515625 Go allocated in layer 4
7.755523681640625 Go allocated in layer 5
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 292, in forward
    free_memory([torch.cuda.device[0]], debug=True)
TypeError: 'type' object is not subscriptable
2023-03-02 14:23:51.152833: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:23:51.238077: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:23:51.604309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:23:51.604341: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:23:51.604345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
4.11492919921875 Go allocated in layer 0
4.843048095703125 Go allocated in layer 1
5.5711669921875 Go allocated in layer 2
6.299285888671875 Go allocated in layer 3
7.02740478515625 Go allocated in layer 4
7.755523681640625 Go allocated in layer 5
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 292, in forward
    free_memory([torch.cuda.device[0]], debug=True)
TypeError: 'type' object is not subscriptable
2023-03-02 14:24:30.013764: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:24:30.096700: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:24:30.459093: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:24:30.459132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:24:30.459148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
4.11492919921875 Go allocated in layer 0
4.843048095703125 Go allocated in layer 1
5.5711669921875 Go allocated in layer 2
6.299285888671875 Go allocated in layer 3
7.02740478515625 Go allocated in layer 4
7.755523681640625 Go allocated in layer 5
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 7.755523681640625}  Go
Current reserved memory: {'cuda:0': 8.89453125}  Go
Maximum allocated memory: {'cuda:0': 8.878698348999023}  Go
Maximum reserved memory: {'cuda:0': 8.89453125}  Go
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 7.755523681640625}  Go
Current reserved memory: {'cuda:0': 8.89453125}  Go
Maximum allocated memory: {'cuda:0': 8.878698348999023}  Go
Maximum reserved memory: {'cuda:0': 8.89453125}  Go
Suggested GPU: 0
10.717880725860596 Go allocated in layer 0
13.142563343048096 Go allocated in layer 1
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 276, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 191, in forward
    source = self.cross_attn_ffn(source, target,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 139, in forward
    message = self.norm1(message)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.09 GiB already allocated; 33.12 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:28:13.679406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:28:13.764100: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:28:14.148098: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:28:14.148131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:28:14.148134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=4, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
4.11492919921875 Go allocated in layer 0
4.843048095703125 Go allocated in layer 1
5.5711669921875 Go allocated in layer 2
6.299285888671875 Go allocated in layer 3
7.02740478515625 Go allocated in layer 4
7.755523681640625 Go allocated in layer 5
10.717880725860596 Go allocated in layer 0
13.142563343048096 Go allocated in layer 1
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 276, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 191, in forward
    source = self.cross_attn_ffn(source, target,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 139, in forward
    message = self.norm1(message)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 190, in forward
    return F.layer_norm(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/functional.py", line 2515, in layer_norm
    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 15.75 GiB total capacity; 14.09 GiB already allocated; 33.12 MiB free; 14.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:31:43.196666: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:31:43.281902: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:31:43.646709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:31:43.646744: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:31:43.646747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 3.916295051574707}  Go
Current reserved memory: {'cuda:0': 7.81640625}  Go
Maximum allocated memory: {'cuda:0': 7.63120174407959}  Go
Maximum reserved memory: {'cuda:0': 7.81640625}  Go
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 3.916295051574707}  Go
Current reserved memory: {'cuda:0': 7.81640625}  Go
Maximum allocated memory: {'cuda:0': 7.63120174407959}  Go
Maximum reserved memory: {'cuda:0': 7.81640625}  Go
Suggested GPU: 0
Before:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 11.461957454681396}  Go
Current reserved memory: {'cuda:0': 11.578125}  Go
Maximum allocated memory: {'cuda:0': 11.567426681518555}  Go
Maximum reserved memory: {'cuda:0': 11.68359375}  Go
Suggested GPU: 0
After:
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 11.461957454681396}  Go
Current reserved memory: {'cuda:0': 11.578125}  Go
Maximum allocated memory: {'cuda:0': 11.567426681518555}  Go
Maximum reserved memory: {'cuda:0': 11.68359375}  Go
Suggested GPU: 0
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 281, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:33:56.196569: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:33:56.281018: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:33:56.643094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:33:56.643151: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:33:56.643157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 3.916295051574707}  Go
Current reserved memory: {'cuda:0': 7.81640625}  Go
Maximum allocated memory: {'cuda:0': 7.63120174407959}  Go
Maximum reserved memory: {'cuda:0': 7.81640625}  Go
Suggested GPU: 0
72 72
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 11.461957454681396}  Go
Current reserved memory: {'cuda:0': 11.578125}  Go
Maximum allocated memory: {'cuda:0': 11.567426681518555}  Go
Maximum reserved memory: {'cuda:0': 11.68359375}  Go
Suggested GPU: 0
72 72
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 281, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:35:25.454174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:35:25.539437: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:35:25.906520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:35:25.906561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:35:25.906567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 3.916295051574707}  Go
Current reserved memory: {'cuda:0': 7.81640625}  Go
Maximum allocated memory: {'cuda:0': 7.63120174407959}  Go
Maximum reserved memory: {'cuda:0': 7.81640625}  Go
Suggested GPU: 0
72 72 FeatureTransformer(
  (layers): ModuleList(
    (0): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (4): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (5): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 11.461957454681396}  Go
Current reserved memory: {'cuda:0': 11.578125}  Go
Maximum allocated memory: {'cuda:0': 11.567426681518555}  Go
Maximum reserved memory: {'cuda:0': 11.68359375}  Go
Suggested GPU: 0
72 72 FeatureTransformer(
  (layers): ModuleList(
    (0): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (2): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (3): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (4): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
    (5): TransformerBlock(
      (self_attn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (cross_attn_ffn): TransformerLayer(
        (q_proj): Linear(in_features=128, out_features=128, bias=False)
        (k_proj): Linear(in_features=128, out_features=128, bias=False)
        (v_proj): Linear(in_features=128, out_features=128, bias=False)
        (merge): Linear(in_features=128, out_features=128, bias=False)
        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=1024, bias=False)
          (1): GELU(approximate='none')
          (2): Linear(in_features=1024, out_features=128, bias=False)
        )
        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
)
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 281, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:35:52.036033: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:35:52.120566: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:35:52.483555: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:35:52.483589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:35:52.483592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=2, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 3.916295051574707}  Go
Current reserved memory: {'cuda:0': 7.81640625}  Go
Maximum allocated memory: {'cuda:0': 7.63120174407959}  Go
Maximum reserved memory: {'cuda:0': 7.81640625}  Go
Suggested GPU: 0
72 72 48
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 11.461957454681396}  Go
Current reserved memory: {'cuda:0': 11.578125}  Go
Maximum allocated memory: {'cuda:0': 11.567426681518555}  Go
Maximum reserved memory: {'cuda:0': 11.68359375}  Go
Suggested GPU: 0
72 72 48
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 281, in forward
    correlation = local_correlation_with_flow(
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/matching.py", line 119, in local_correlation_with_flow
    corr = torch.matmul(feature0_view, window_feature).view(b, h * w, -1) / (c ** 0.5)  # [B, H*W, (2R+1)^2]
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 0; 15.75 GiB total capacity; 13.24 GiB already allocated; 895.12 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2023-03-02 14:37:11.856783: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:37:11.941205: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:37:12.308309: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:37:12.308343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:37:12.308347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 1.9972238540649414}  Go
Current reserved memory: {'cuda:0': 2.029296875}  Go
Maximum allocated memory: {'cuda:0': 6.865561485290527}  Go
Maximum reserved memory: {'cuda:0': 7.6015625}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.768407344818115}  Go
Current reserved memory: {'cuda:0': 5.833984375}  Go
Maximum allocated memory: {'cuda:0': 6.865561485290527}  Go
Maximum reserved memory: {'cuda:0': 7.6015625}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1005043983459473}  Go
Current reserved memory: {'cuda:0': 2.916015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.870627403259277}  Go
Current reserved memory: {'cuda:0': 5.93359375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.0984292030334473}  Go
Current reserved memory: {'cuda:0': 4.3671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.870955467224121}  Go
Current reserved memory: {'cuda:0': 5.99609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1014809608459473}  Go
Current reserved memory: {'cuda:0': 3.45703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.872786521911621}  Go
Current reserved memory: {'cuda:0': 5.984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1025185585021973}  Go
Current reserved memory: {'cuda:0': 3.494140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.874861717224121}  Go
Current reserved memory: {'cuda:0': 6.0234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1026406288146973}  Go
Current reserved memory: {'cuda:0': 2.1953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.875777244567871}  Go
Current reserved memory: {'cuda:0': 5.998046875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1020379066467285}  Go
Current reserved memory: {'cuda:0': 2.3203125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.874625205993652}  Go
Current reserved memory: {'cuda:0': 6.037109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1019082069396973}  Go
Current reserved memory: {'cuda:0': 2.26953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.872603416442871}  Go
Current reserved memory: {'cuda:0': 6.052734375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1039223670959473}  Go
Current reserved memory: {'cuda:0': 2.34765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877364158630371}  Go
Current reserved memory: {'cuda:0': 6.078125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1035027503967285}  Go
Current reserved memory: {'cuda:0': 2.4140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878226280212402}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1023354530334473}  Go
Current reserved memory: {'cuda:0': 2.41015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876509666442871}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1039834022521973}  Go
Current reserved memory: {'cuda:0': 2.4296875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877669334411621}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1058220863342285}  Go
Current reserved memory: {'cuda:0': 2.451171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879080772399902}  Go
Current reserved memory: {'cuda:0': 6.14453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1050057411193848}  Go
Current reserved memory: {'cuda:0': 2.482421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878630638122559}  Go
Current reserved memory: {'cuda:0': 6.11328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.104708194732666}  Go
Current reserved memory: {'cuda:0': 2.494140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.87888240814209}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.104830265045166}  Go
Current reserved memory: {'cuda:0': 2.419921875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.87943172454834}  Go
Current reserved memory: {'cuda:0': 6.1484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1038613319396973}  Go
Current reserved memory: {'cuda:0': 2.390625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877486228942871}  Go
Current reserved memory: {'cuda:0': 6.08984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.104403018951416}  Go
Current reserved memory: {'cuda:0': 2.35546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.87876033782959}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1042962074279785}  Go
Current reserved memory: {'cuda:0': 2.501953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878531455993652}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1057000160217285}  Go
Current reserved memory: {'cuda:0': 2.52734375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878714561462402}  Go
Current reserved memory: {'cuda:0': 6.140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1037392616271973}  Go
Current reserved memory: {'cuda:0': 2.484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878279685974121}  Go
Current reserved memory: {'cuda:0': 6.115234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1053872108459473}  Go
Current reserved memory: {'cuda:0': 2.572265625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.882063865661621}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1048378944396973}  Go
Current reserved memory: {'cuda:0': 2.392578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879195213317871}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1042275428771973}  Go
Current reserved memory: {'cuda:0': 2.42578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878035545349121}  Go
Current reserved memory: {'cuda:0': 6.087890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1033120155334473}  Go
Current reserved memory: {'cuda:0': 2.353515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877852439880371}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1050209999084473}  Go
Current reserved memory: {'cuda:0': 2.490234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878829002380371}  Go
Current reserved memory: {'cuda:0': 6.091796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1035561561584473}  Go
Current reserved memory: {'cuda:0': 2.37109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877547264099121}  Go
Current reserved memory: {'cuda:0': 6.087890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1031975746154785}  Go
Current reserved memory: {'cuda:0': 2.46484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877982139587402}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1050820350646973}  Go
Current reserved memory: {'cuda:0': 2.587890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879439353942871}  Go
Current reserved memory: {'cuda:0': 6.111328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1045327186584473}  Go
Current reserved memory: {'cuda:0': 2.5859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879683494567871}  Go
Current reserved memory: {'cuda:0': 6.130859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1068520545959473}  Go
Current reserved memory: {'cuda:0': 2.556640625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880049705505371}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1012978553771973}  Go
Current reserved memory: {'cuda:0': 2.416015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876631736755371}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1034951210021973}  Go
Current reserved memory: {'cuda:0': 2.412109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877913475036621}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.105989933013916}  Go
Current reserved memory: {'cuda:0': 2.455078125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.87943172454834}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1033196449279785}  Go
Current reserved memory: {'cuda:0': 2.484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880057334899902}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1063027381896973}  Go
Current reserved memory: {'cuda:0': 2.44921875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880660057067871}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1067299842834473}  Go
Current reserved memory: {'cuda:0': 2.474609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879805564880371}  Go
Current reserved memory: {'cuda:0': 6.091796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1047844886779785}  Go
Current reserved memory: {'cuda:0': 2.501953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879141807556152}  Go
Current reserved memory: {'cuda:0': 6.115234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.105318546295166}  Go
Current reserved memory: {'cuda:0': 2.40625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878645896911621}  Go
Current reserved memory: {'cuda:0': 6.091796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1040444374084473}  Go
Current reserved memory: {'cuda:0': 2.443359375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878767967224121}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1043496131896973}  Go
Current reserved memory: {'cuda:0': 2.361328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878523826599121}  Go
Current reserved memory: {'cuda:0': 6.08984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1059365272521973}  Go
Current reserved memory: {'cuda:0': 2.55859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879805564880371}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1036171913146973}  Go
Current reserved memory: {'cuda:0': 2.421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878951072692871}  Go
Current reserved memory: {'cuda:0': 6.107421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1058754920959473}  Go
Current reserved memory: {'cuda:0': 2.416015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879317283630371}  Go
Current reserved memory: {'cuda:0': 6.087890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1050896644592285}  Go
Current reserved memory: {'cuda:0': 2.529296875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880789756774902}  Go
Current reserved memory: {'cuda:0': 6.09375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1063637733459473}  Go
Current reserved memory: {'cuda:0': 2.451171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879988670349121}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1061806678771973}  Go
Current reserved memory: {'cuda:0': 2.5703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880415916442871}  Go
Current reserved memory: {'cuda:0': 6.111328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1052117347717285}  Go
Current reserved memory: {'cuda:0': 2.5546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879019737243652}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1039834022521973}  Go
Current reserved memory: {'cuda:0': 2.4453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878584861755371}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1055092811584473}  Go
Current reserved memory: {'cuda:0': 2.4921875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878584861755371}  Go
Current reserved memory: {'cuda:0': 6.09375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1053948402404785}  Go
Current reserved memory: {'cuda:0': 2.46484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879202842712402}  Go
Current reserved memory: {'cuda:0': 6.123046875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1054635047912598}  Go
Current reserved memory: {'cuda:0': 2.4140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879088401794434}  Go
Current reserved memory: {'cuda:0': 6.107421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1048455238342285}  Go
Current reserved memory: {'cuda:0': 2.44140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878287315368652}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1027779579162598}  Go
Current reserved memory: {'cuda:0': 2.484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876585960388184}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1050667762756348}  Go
Current reserved memory: {'cuda:0': 2.419921875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878691673278809}  Go
Current reserved memory: {'cuda:0': 6.1328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1059365272521973}  Go
Current reserved memory: {'cuda:0': 2.533203125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880293846130371}  Go
Current reserved memory: {'cuda:0': 6.1328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1047310829162598}  Go
Current reserved memory: {'cuda:0': 2.498046875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878355979919434}  Go
Current reserved memory: {'cuda:0': 6.142578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1020302772521973}  Go
Current reserved memory: {'cuda:0': 2.392578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.875838279724121}  Go
Current reserved memory: {'cuda:0': 6.107421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1047158241271973}  Go
Current reserved memory: {'cuda:0': 2.447265625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878157615661621}  Go
Current reserved memory: {'cuda:0': 6.08984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1036171913146973}  Go
Current reserved memory: {'cuda:0': 2.486328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877608299255371}  Go
Current reserved memory: {'cuda:0': 6.12890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1036782264709473}  Go
Current reserved memory: {'cuda:0': 2.353515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877486228942871}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1042275428771973}  Go
Current reserved memory: {'cuda:0': 2.431640625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878829002380371}  Go
Current reserved memory: {'cuda:0': 6.09375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1027626991271973}  Go
Current reserved memory: {'cuda:0': 2.376953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876570701599121}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1025795936584473}  Go
Current reserved memory: {'cuda:0': 2.421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878645896911621}  Go
Current reserved memory: {'cuda:0': 6.115234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1047768592834473}  Go
Current reserved memory: {'cuda:0': 2.443359375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878157615661621}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1050286293029785}  Go
Current reserved memory: {'cuda:0': 2.546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880911827087402}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1058754920959473}  Go
Current reserved memory: {'cuda:0': 2.607421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879683494567871}  Go
Current reserved memory: {'cuda:0': 6.11328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1055703163146973}  Go
Current reserved memory: {'cuda:0': 2.513671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879927635192871}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1042275428771973}  Go
Current reserved memory: {'cuda:0': 2.419921875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878035545349121}  Go
Current reserved memory: {'cuda:0': 6.1015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1028313636779785}  Go
Current reserved memory: {'cuda:0': 2.4296875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877371788024902}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1025185585021973}  Go
Current reserved memory: {'cuda:0': 2.482421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876326560974121}  Go
Current reserved memory: {'cuda:0': 6.123046875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1042275428771973}  Go
Current reserved memory: {'cuda:0': 2.42578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877058982849121}  Go
Current reserved memory: {'cuda:0': 6.087890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1022133827209473}  Go
Current reserved memory: {'cuda:0': 2.39453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877181053161621}  Go
Current reserved memory: {'cuda:0': 6.107421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1042351722717285}  Go
Current reserved memory: {'cuda:0': 2.576171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878043174743652}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1045327186584473}  Go
Current reserved memory: {'cuda:0': 2.453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878890037536621}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1053261756896973}  Go
Current reserved memory: {'cuda:0': 2.47265625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879195213317871}  Go
Current reserved memory: {'cuda:0': 6.09375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1034951210021973}  Go
Current reserved memory: {'cuda:0': 2.41796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877852439880371}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1025795936584473}  Go
Current reserved memory: {'cuda:0': 2.41796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877547264099121}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1018471717834473}  Go
Current reserved memory: {'cuda:0': 2.43359375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877608299255371}  Go
Current reserved memory: {'cuda:0': 6.107421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1041741371154785}  Go
Current reserved memory: {'cuda:0': 2.53125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878958702087402}  Go
Current reserved memory: {'cuda:0': 6.142578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1048378944396973}  Go
Current reserved memory: {'cuda:0': 2.353515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878584861755371}  Go
Current reserved memory: {'cuda:0': 6.087890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1044716835021973}  Go
Current reserved memory: {'cuda:0': 2.416015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878829002380371}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1050209999084473}  Go
Current reserved memory: {'cuda:0': 2.373046875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878829002380371}  Go
Current reserved memory: {'cuda:0': 6.09375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1044716835021973}  Go
Current reserved memory: {'cuda:0': 2.388671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876997947692871}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1051888465881348}  Go
Current reserved memory: {'cuda:0': 2.548828125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878813743591309}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1049599647521973}  Go
Current reserved memory: {'cuda:0': 2.466796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880293846130371}  Go
Current reserved memory: {'cuda:0': 6.107421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1036858558654785}  Go
Current reserved memory: {'cuda:0': 2.443359375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877676963806152}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1038002967834473}  Go
Current reserved memory: {'cuda:0': 2.607421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878401756286621}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1029458045959473}  Go
Current reserved memory: {'cuda:0': 2.341796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876021385192871}  Go
Current reserved memory: {'cuda:0': 6.087890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1056389808654785}  Go
Current reserved memory: {'cuda:0': 2.5546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879508018493652}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1049599647521973}  Go
Current reserved memory: {'cuda:0': 2.400390625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879744529724121}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1027626991271973}  Go
Current reserved memory: {'cuda:0': 2.3671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.878096580505371}  Go
Current reserved memory: {'cuda:0': 6.0859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1018471717834473}  Go
Current reserved memory: {'cuda:0': 2.392578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876631736755371}  Go
Current reserved memory: {'cuda:0': 6.107421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1048455238342285}  Go
Current reserved memory: {'cuda:0': 2.5078125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877127647399902}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1063637733459473}  Go
Current reserved memory: {'cuda:0': 2.419921875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880171775817871}  Go
Current reserved memory: {'cuda:0': 6.091796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.104952335357666}  Go
Current reserved memory: {'cuda:0': 2.494140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.87876033782959}  Go
Current reserved memory: {'cuda:0': 6.111328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1022133827209473}  Go
Current reserved memory: {'cuda:0': 2.376953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.876997947692871}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1036019325256348}  Go
Current reserved memory: {'cuda:0': 2.390625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.877287864685059}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1059975624084473}  Go
Current reserved memory: {'cuda:0': 2.505859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879988670349121}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1045937538146973}  Go
Current reserved memory: {'cuda:0': 2.53515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.879927635192871}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
step: 000100 	 epe: 19.725
Save checkpoint at step: 100
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1067004203796387}  Go
Current reserved memory: {'cuda:0': 2.4140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8801422119140625}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1054186820983887}  Go
Current reserved memory: {'cuda:0': 2.390625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8799591064453125}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1048693656921387}  Go
Current reserved memory: {'cuda:0': 2.376953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8799591064453125}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10762357711792}  Go
Current reserved memory: {'cuda:0': 2.6171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.881980895996094}  Go
Current reserved memory: {'cuda:0': 6.140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1069445610046387}  Go
Current reserved memory: {'cuda:0': 2.529296875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8815460205078125}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10634183883667}  Go
Current reserved memory: {'cuda:0': 2.482421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.881248474121094}  Go
Current reserved memory: {'cuda:0': 6.15234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1073107719421387}  Go
Current reserved memory: {'cuda:0': 2.40625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8811798095703125}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1090807914733887}  Go
Current reserved memory: {'cuda:0': 2.46875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8821563720703125}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1076769828796387}  Go
Current reserved memory: {'cuda:0': 2.546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8816680908203125}  Go
Current reserved memory: {'cuda:0': 6.123046875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1071887016296387}  Go
Current reserved memory: {'cuda:0': 2.552734375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8814239501953125}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1073107719421387}  Go
Current reserved memory: {'cuda:0': 2.490234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8818511962890625}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1057848930358887}  Go
Current reserved memory: {'cuda:0': 2.408203125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8798370361328125}  Go
Current reserved memory: {'cuda:0': 6.091796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1056017875671387}  Go
Current reserved memory: {'cuda:0': 2.4453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8814849853515625}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1051135063171387}  Go
Current reserved memory: {'cuda:0': 2.408203125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8811798095703125}  Go
Current reserved memory: {'cuda:0': 6.138671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10774564743042}  Go
Current reserved memory: {'cuda:0': 2.484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.881614685058594}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10554838180542}  Go
Current reserved memory: {'cuda:0': 2.470703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.881126403808594}  Go
Current reserved memory: {'cuda:0': 6.11328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1076159477233887}  Go
Current reserved memory: {'cuda:0': 2.458984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8840484619140625}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10872220993042}  Go
Current reserved memory: {'cuda:0': 2.412109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.884300231933594}  Go
Current reserved memory: {'cuda:0': 6.09375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1085314750671387}  Go
Current reserved memory: {'cuda:0': 2.466796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8848419189453125}  Go
Current reserved memory: {'cuda:0': 6.126953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1096301078796387}  Go
Current reserved memory: {'cuda:0': 2.4296875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8856353759765625}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1081652641296387}  Go
Current reserved memory: {'cuda:0': 2.537109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8836822509765625}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10640287399292}  Go
Current reserved memory: {'cuda:0': 2.435546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.883506774902344}  Go
Current reserved memory: {'cuda:0': 6.1484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1064562797546387}  Go
Current reserved memory: {'cuda:0': 2.458984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8806915283203125}  Go
Current reserved memory: {'cuda:0': 6.08984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1100573539733887}  Go
Current reserved memory: {'cuda:0': 2.49609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8842315673828125}  Go
Current reserved memory: {'cuda:0': 6.126953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1088976860046387}  Go
Current reserved memory: {'cuda:0': 2.537109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8842315673828125}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1064562797546387}  Go
Current reserved memory: {'cuda:0': 2.427734375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8819732666015625}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1093249320983887}  Go
Current reserved memory: {'cuda:0': 2.548828125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8831329345703125}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1081652641296387}  Go
Current reserved memory: {'cuda:0': 2.388671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8828887939453125}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1092028617858887}  Go
Current reserved memory: {'cuda:0': 2.521484375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8830108642578125}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10750150680542}  Go
Current reserved memory: {'cuda:0': 2.505859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880882263183594}  Go
Current reserved memory: {'cuda:0': 6.1015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10872220993042}  Go
Current reserved memory: {'cuda:0': 2.638671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.883872985839844}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1041369438171387}  Go
Current reserved memory: {'cuda:0': 2.421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8816070556640625}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1063342094421387}  Go
Current reserved memory: {'cuda:0': 2.4453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8820953369140625}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10805082321167}  Go
Current reserved memory: {'cuda:0': 2.5703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.882286071777344}  Go
Current reserved memory: {'cuda:0': 6.119140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1054186820983887}  Go
Current reserved memory: {'cuda:0': 2.37890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8807525634765625}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1062121391296387}  Go
Current reserved memory: {'cuda:0': 2.408203125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8809967041015625}  Go
Current reserved memory: {'cuda:0': 6.091796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1046252250671387}  Go
Current reserved memory: {'cuda:0': 2.423828125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8819122314453125}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10689115524292}  Go
Current reserved memory: {'cuda:0': 2.4609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880760192871094}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1082873344421387}  Go
Current reserved memory: {'cuda:0': 2.58984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8813629150390625}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1046862602233887}  Go
Current reserved memory: {'cuda:0': 2.37890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8817291259765625}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1059679985046387}  Go
Current reserved memory: {'cuda:0': 2.419921875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8809967041015625}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10689115524292}  Go
Current reserved memory: {'cuda:0': 2.611328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.882957458496094}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1101794242858887}  Go
Current reserved memory: {'cuda:0': 2.427734375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8832550048828125}  Go
Current reserved memory: {'cuda:0': 6.099609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10744047164917}  Go
Current reserved memory: {'cuda:0': 2.474609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.882530212402344}  Go
Current reserved memory: {'cuda:0': 6.091796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1078600883483887}  Go
Current reserved memory: {'cuda:0': 2.37890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8831939697265625}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1081652641296387}  Go
Current reserved memory: {'cuda:0': 2.513671875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8828887939453125}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1057848930358887}  Go
Current reserved memory: {'cuda:0': 2.4609375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8814849853515625}  Go
Current reserved memory: {'cuda:0': 6.119140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1065783500671387}  Go
Current reserved memory: {'cuda:0': 2.41015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8819122314453125}  Go
Current reserved memory: {'cuda:0': 6.103515625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1071887016296387}  Go
Current reserved memory: {'cuda:0': 2.53125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8804473876953125}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1071276664733887}  Go
Current reserved memory: {'cuda:0': 2.4453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8824005126953125}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10823392868042}  Go
Current reserved memory: {'cuda:0': 2.458984375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.882835388183594}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1061511039733887}  Go
Current reserved memory: {'cuda:0': 2.4140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8822174072265625}  Go
Current reserved memory: {'cuda:0': 6.09765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1063342094421387}  Go
Current reserved memory: {'cuda:0': 2.462890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8826446533203125}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10457181930542}  Go
Current reserved memory: {'cuda:0': 2.42578125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.881858825683594}  Go
Current reserved memory: {'cuda:0': 6.119140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1062121391296387}  Go
Current reserved memory: {'cuda:0': 2.51171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8805694580078125}  Go
Current reserved memory: {'cuda:0': 6.111328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1057848930358887}  Go
Current reserved memory: {'cuda:0': 2.431640625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8805084228515625}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.107539653778076}  Go
Current reserved memory: {'cuda:0': 2.55078125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.88079833984375}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.106746196746826}  Go
Current reserved memory: {'cuda:0': 2.462890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.882080078125}  Go
Current reserved memory: {'cuda:0': 6.1328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1079821586608887}  Go
Current reserved memory: {'cuda:0': 2.412109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8818511962890625}  Go
Current reserved memory: {'cuda:0': 6.09375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1062731742858887}  Go
Current reserved memory: {'cuda:0': 2.439453125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8812408447265625}  Go
Current reserved memory: {'cuda:0': 6.111328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10737943649292}  Go
Current reserved memory: {'cuda:0': 2.52734375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.881614685058594}  Go
Current reserved memory: {'cuda:0': 6.12109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1099963188171387}  Go
Current reserved memory: {'cuda:0': 2.5859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8863067626953125}  Go
Current reserved memory: {'cuda:0': 6.12890625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1062121391296387}  Go
Current reserved memory: {'cuda:0': 2.435546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8813629150390625}  Go
Current reserved memory: {'cuda:0': 6.130859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1079821586608887}  Go
Current reserved memory: {'cuda:0': 2.533203125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8821563720703125}  Go
Current reserved memory: {'cuda:0': 6.115234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1071276664733887}  Go
Current reserved memory: {'cuda:0': 2.421875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8830108642578125}  Go
Current reserved memory: {'cuda:0': 6.123046875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1064562797546387}  Go
Current reserved memory: {'cuda:0': 2.51171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8825836181640625}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1074328422546387}  Go
Current reserved memory: {'cuda:0': 2.580078125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8816070556640625}  Go
Current reserved memory: {'cuda:0': 6.109375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1056017875671387}  Go
Current reserved memory: {'cuda:0': 2.423828125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8811187744140625}  Go
Current reserved memory: {'cuda:0': 6.1171875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1068224906921387}  Go
Current reserved memory: {'cuda:0': 2.509765625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8793487548828125}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1071887016296387}  Go
Current reserved memory: {'cuda:0': 2.6015625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8831329345703125}  Go
Current reserved memory: {'cuda:0': 6.11328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1065173149108887}  Go
Current reserved memory: {'cuda:0': 2.435546875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8820953369140625}  Go
Current reserved memory: {'cuda:0': 6.095703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10615873336792}  Go
Current reserved memory: {'cuda:0': 2.466796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.881492614746094}  Go
Current reserved memory: {'cuda:0': 6.125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1056017875671387}  Go
Current reserved memory: {'cuda:0': 2.369140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8787384033203125}  Go
Current reserved memory: {'cuda:0': 6.0859375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1048083305358887}  Go
Current reserved memory: {'cuda:0': 2.466796875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8803253173828125}  Go
Current reserved memory: {'cuda:0': 6.119140625}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.10567045211792}  Go
Current reserved memory: {'cuda:0': 2.4296875}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.880638122558594}  Go
Current reserved memory: {'cuda:0': 6.111328125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1072497367858887}  Go
Current reserved memory: {'cuda:0': 2.45703125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8833160400390625}  Go
Current reserved memory: {'cuda:0': 6.126953125}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 2.1077990531921387}  Go
Current reserved memory: {'cuda:0': 2.5234375}  Go
Maximum allocated memory: {'cuda:0': 11.87872838973999}  Go
Maximum reserved memory: {'cuda:0': 12.580078125}  Go
Suggested GPU: 0
Falling back to default: all gpus
Current allocated memory: {'cuda:0': 5.8829498291015625}  Go
Current reserved memory: {'cuda:0': 6.10546875}  Go
Maximum allocated memory: 2023-03-02 14:40:41.983263: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:40:42.069680: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:40:42.440533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:40:42.440566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:40:42.440570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2023-03-02 14:43:53.381573: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:43:53.468170: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:43:53.839250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:43:53.839285: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:43:53.839288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
  0%|          | 0/3600 [00:00<?, ?it/s]  0%|          | 0/3600 [00:00<?, ?it/s]
2023-03-02 14:45:00.239386: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 14:45:00.323846: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 14:45:00.690745: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:45:00.690780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 14:45:00.690784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: pretrained/gmstereo-scale2-regrefine3-resumeflowthings-middleburyfthighres-a82bec03.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
0it [00:00, ?it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
1it [00:03,  3.93s/it]2it [00:04,  1.92s/it]3it [00:05,  1.30s/it]4it [00:05,  1.02s/it]5it [00:06,  1.15it/s]6it [00:06,  1.29it/s]7it [00:07,  1.40it/s]8it [00:07,  1.47it/s]9it [00:08,  1.52it/s]10it [00:09,  1.58it/s]11it [00:09,  1.61it/s]12it [00:10,  1.61it/s]13it [00:11,  1.60it/s]14it [00:11,  1.60it/s]15it [00:12,  1.59it/s]16it [00:12,  1.58it/s]17it [00:13,  1.59it/s]18it [00:14,  1.60it/s]19it [00:14,  1.60it/s]20it [00:15,  1.59it/s]21it [00:16,  1.59it/s]22it [00:16,  1.59it/s]23it [00:17,  1.58it/s]24it [00:17,  1.58it/s]25it [00:18,  1.58it/s]26it [00:19,  1.59it/s]27it [00:19,  1.59it/s]28it [00:20,  1.59it/s]29it [00:21,  1.58it/s]30it [00:21,  1.59it/s]31it [00:22,  1.59it/s]32it [00:22,  1.59it/s]33it [00:23,  1.58it/s]34it [00:24,  1.58it/s]35it [00:24,  1.58it/s]36it [00:25,  1.57it/s]37it [00:26,  1.57it/s]38it [00:26,  1.56it/s]39it [00:27,  1.57it/s]40it [00:28,  1.57it/s]41it [00:28,  1.57it/s]42it [00:29,  1.57it/s]43it [00:30,  1.57it/s]44it [00:30,  1.56it/s]45it [00:31,  1.56it/s]46it [00:31,  1.56it/s]47it [00:32,  1.56it/s]48it [00:33,  1.56it/s]49it [00:33,  1.56it/s]50it [00:34,  1.56it/s]51it [00:35,  1.56it/s]52it [00:35,  1.56it/s]53it [00:36,  1.56it/s]54it [00:37,  1.56it/s]55it [00:37,  1.56it/s]56it [00:38,  1.56it/s]57it [00:38,  1.56it/s]58it [00:39,  1.56it/s]59it [00:40,  1.56it/s]60it [00:40,  1.56it/s]61it [00:41,  1.56it/s]62it [00:42,  1.56it/s]63it [00:42,  1.56it/s]64it [00:43,  1.55it/s]65it [00:44,  1.56it/s]66it [00:44,  1.56it/s]67it [00:45,  1.56it/s]68it [00:46,  1.55it/s]69it [00:46,  1.56it/s]70it [00:47,  1.55it/s]71it [00:47,  1.56it/s]72it [00:48,  1.55it/s]73it [00:49,  1.55it/s]74it [00:49,  1.55it/s]75it [00:50,  1.55it/s]76it [00:51,  1.55it/s]77it [00:51,  1.55it/s]78it [00:52,  1.55it/s]79it [00:53,  1.55it/s]80it [00:53,  1.55it/s]81it [00:54,  1.56it/s]82it [00:55,  1.56it/s]83it [00:55,  1.55it/s]84it [00:56,  1.55it/s]85it [00:56,  1.55it/s]86it [00:57,  1.55it/s]87it [00:58,  1.55it/s]88it [00:58,  1.55it/s]89it [00:59,  1.55it/s]90it [01:00,  1.55it/s]91it [01:00,  1.55it/s]92it [01:01,  1.55it/s]93it [01:02,  1.55it/s]94it [01:02,  1.55it/s]95it [01:03,  1.55it/s]96it [01:04,  1.54it/s]97it [01:04,  1.55it/s]98it [01:05,  1.55it/s]99it [01:06,  1.55it/s]100it [01:07,  1.30it/s]101it [01:07,  1.37it/s]102it [01:08,  1.42it/s]103it [01:09,  1.45it/s]104it [01:09,  1.48it/s]105it [01:10,  1.50it/s]106it [01:10,  1.52it/s]107it [01:11,  1.52it/s]108it [01:12,  1.54it/s]109it [01:12,  1.54it/s]110it [01:13,  1.54it/s]111it [01:14,  1.54it/s]112it [01:14,  1.55it/s]113it [01:15,  1.55it/s]114it [01:16,  1.55it/s]115it [01:16,  1.56it/s]116it [01:17,  1.56it/s]117it [01:18,  1.56it/s]118it [01:18,  1.56it/s]119it [01:19,  1.56it/s]120it [01:19,  1.56it/s]121it [01:20,  1.56it/s]122it [01:21,  1.55it/s]123it [01:21,  1.55it/s]124it [01:22,  1.55it/s]125it [01:23,  1.55it/s]126it [01:23,  1.56it/s]127it [01:24,  1.57it/s]128it [01:25,  1.56it/s]129it [01:25,  1.55it/s]130it [01:26,  1.55it/s]131it [01:27,  1.55it/s]132it [01:27,  1.55it/s]133it [01:28,  1.56it/s]134it [01:28,  1.56it/s]135it [01:29,  1.56it/s]136it [01:30,  1.56it/s]137it [01:30,  1.55it/s]138it [01:31,  1.55it/s]139it [01:32,  1.55it/s]140it [01:32,  1.55it/s]141it [01:33,  1.56it/s]142it [01:34,  1.56it/s]143it [01:34,  1.55it/s]144it [01:35,  1.55it/s]145it [01:36,  1.55it/s]146it [01:36,  1.55it/s]147it [01:37,  1.54it/s]148it [01:37,  1.55it/s]149it [01:38,  1.55it/s]150it [01:39,  1.55it/s]151it [01:39,  1.55it/s]152it [01:40,  1.55it/s]153it [01:41,  1.55it/s]154it [01:41,  1.56it/s]155it [01:42,  1.55it/s]156it [01:43,  1.55it/s]157it [01:43,  1.55it/s]158it [01:44,  1.55it/s]159it [01:45,  1.55it/s]160it [01:45,  1.55it/s]161it [01:46,  1.55it/s]162it [01:47,  1.55it/s]163it [01:47,  1.56it/s]164it [01:48,  1.56it/s]165it [01:48,  1.55it/s]166it [01:49,  1.55it/s]167it [01:50,  1.55it/s]168it [01:50,  1.55it/s]169it [01:51,  1.55it/s]170it [01:52,  1.55it/s]171it [01:52,  1.55it/s]172it [01:53,  1.55it/s]173it [01:54,  1.55it/s]174it [01:54,  1.55it/s]175it [01:55,  1.55it/s]176it [01:56,  1.55it/s]177it [01:56,  1.55it/s]178it [01:57,  1.56it/s]179it [01:57,  1.56it/s]180it [01:58,  1.56it/s]181it [01:59,  1.56it/s]182it [01:59,  1.56it/s]183it [02:00,  1.55it/s]184it [02:01,  1.56it/s]185it [02:01,  1.56it/s]186it [02:02,  1.55it/s]187it [02:03,  1.55it/s]188it [02:03,  1.55it/s]189it [02:04,  1.55it/s]190it [02:05,  1.55it/s]191it [02:05,  1.55it/s]192it [02:06,  1.54it/s]193it [02:06,  1.54it/s]194it [02:07,  1.54it/s]195it [02:08,  1.55it/s]196it [02:08,  1.54it/s]197it [02:09,  1.52it/s]198it [02:10,  1.52it/s]199it [02:10,  1.53it/s]200it [02:12,  1.28it/s]201it [02:12,  1.35it/s]202it [02:13,  1.41it/s]203it [02:13,  1.45it/s]204it [02:14,  1.49it/s]205it [02:15,  1.51it/s]206it [02:15,  1.52it/s]207it [02:16,  1.54it/s]208it [02:17,  1.55it/s]209it [02:17,  1.55it/s]210it [02:18,  1.55it/s]211it [02:19,  1.55it/s]212it [02:19,  1.56it/s]213it [02:20,  1.56it/s]214it [02:20,  1.55it/s]215it [02:21,  1.55it/s]216it [02:22,  1.56it/s]217it [02:22,  1.55it/s]218it [02:23,  1.55it/s]219it [02:24,  1.55it/s]220it [02:24,  1.55it/s]221it [02:25,  1.55it/s]222it [02:26,  1.56it/s]223it [02:26,  1.56it/s]224it [02:27,  1.56it/s]225it [02:28,  1.55it/s]226it [02:28,  1.56it/s]227it [02:29,  1.56it/s]228it [02:29,  1.56it/s]229it [02:30,  1.55it/s]230it [02:31,  1.56it/s]231it [02:31,  1.56it/s]232it [02:32,  1.56it/s]233it [02:33,  1.56it/s]234it [02:33,  1.55it/s]235it [02:34,  1.55it/s]236it [02:35,  1.55it/s]237it [02:35,  1.55it/s]238it [02:36,  1.55it/s]239it [02:37,  1.56it/s]240it [02:37,  1.56it/s]241it [02:38,  1.57it/s]242it [02:38,  1.57it/s]243it [02:39,  1.57it/s]244it [02:40,  1.56it/s]245it [02:40,  1.56it/s]246it [02:41,  1.56it/s]247it [02:42,  1.56it/s]248it [02:42,  1.56it/s]249it [02:43,  1.56it/s]250it [02:44,  1.56it/s]251it [02:44,  1.56it/s]252it [02:45,  1.55it/s]253it [02:46,  1.55it/s]254it [02:46,  1.56it/s]255it [02:47,  1.55it/s]256it [02:47,  1.55it/s]257it [02:48,  1.56it/s]258it [02:49,  1.56it/s]259it [02:49,  1.56it/s]260it [02:50,  1.56it/s]261it [02:51,  1.56it/s]262it [02:51,  1.56it/s]263it [02:52,  1.56it/s]264it [02:53,  1.56it/s]265it [02:53,  1.56it/s]266it [02:54,  1.56it/s]267it [02:55,  1.56it/s]268it [02:55,  1.56it/s]269it [02:56,  1.56it/s]270it [02:56,  1.56it/s]271it [02:57,  1.55it/s]272it [02:58,  1.55it/s]273it [02:58,  1.55it/s]274it [02:59,  1.55it/s]275it [03:00,  1.55it/s]276it [03:00,  1.56it/s]277it [03:01,  1.55it/s]278it [03:02,  1.55it/s]279it [03:02,  1.55it/s]280it [03:03,  1.55it/s]281it [03:04,  1.56it/s]282it [03:04,  1.55it/s]283it [03:05,  1.55it/s]284it [03:05,  1.55it/s]285it [03:06,  1.56it/s]286it [03:07,  1.56it/s]287it [03:07,  1.56it/s]288it [03:08,  1.56it/s]289it [03:09,  1.56it/s]290it [03:09,  1.56it/s]291it [03:10,  1.56it/s]292it [03:11,  1.56it/s]293it [03:11,  1.56it/s]294it [03:12,  1.56it/s]295it [03:12,  1.56it/s]296it [03:13,  1.56it/s]297it [03:14,  1.56it/s]298it [03:14,  1.57it/s]299it [03:15,  1.57it/s]300it [03:16,  1.33it/s]301it [03:17,  1.39it/s]302it [03:17,  1.44it/s]303it [03:18,  1.47it/s]304it [03:19,  1.50it/s]305it [03:19,  1.51it/s]306it [03:20,  1.52it/s]307it [03:21,  1.54it/s]308it [03:21,  1.55it/s]309it [03:22,  1.54it/s]310it [03:22,  1.55it/s]311it [03:23,  1.55it/s]312it [03:24,  1.56it/s]313it [03:24,  1.56it/s]314it [03:25,  1.56it/s]315it [03:26,  1.56it/s]316it [03:26,  1.56it/s]317it [03:27,  1.56it/s]318it [03:28,  1.55it/s]319it [03:28,  1.55it/s]320it [03:29,  1.55it/s]321it [03:30,  1.55it/s]322it [03:30,  1.54it/s]323it [03:31,  1.55it/s]324it [03:31,  1.55it/s]325it [03:32,  1.55it/s]326it [03:33,  1.55it/s]327it [03:33,  1.55it/s]328it [03:34,  1.54it/s]329it [03:35,  1.55it/s]330it [03:35,  1.54it/s]331it [03:36,  1.54it/s]332it [03:37,  1.54it/s]333it [03:37,  1.54it/s]334it [03:38,  1.55it/s]335it [03:39,  1.55it/s]336it [03:39,  1.55it/s]337it [03:40,  1.55it/s]338it [03:41,  1.55it/s]339it [03:41,  1.55it/s]340it [03:42,  1.56it/s]341it [03:42,  1.55it/s]342it [03:43,  1.56it/s]343it [03:44,  1.56it/s]344it [03:44,  1.56it/s]345it [03:45,  1.56it/s]346it [03:46,  1.56it/s]347it [03:46,  1.56it/s]348it [03:47,  1.55it/s]349it [03:48,  1.55it/s]350it [03:48,  1.55it/s]351it [03:49,  1.55it/s]352it [03:50,  1.55it/s]353it [03:50,  1.55it/s]354it [03:51,  1.55it/s]355it [03:51,  1.55it/s]356it [03:52,  1.55it/s]357it [03:53,  1.55it/s]358it [03:53,  1.55it/s]359it [03:54,  1.55it/s]360it [03:55,  1.55it/s]361it [03:55,  1.55it/s]362it [03:56,  1.55it/s]363it [03:57,  1.56it/s]364it [03:57,  1.55it/s]365it [03:58,  1.56it/s]366it [03:59,  1.56it/s]367it [03:59,  1.56it/s]368it [04:00,  1.55it/s]369it [04:01,  1.55it/s]370it [04:01,  1.55it/s]371it [04:02,  1.55it/s]372it [04:02,  1.55it/s]373it [04:03,  1.55it/s]374it [04:04,  1.55it/s]375it [04:04,  1.55it/s]376it [04:05,  1.55it/s]377it [04:06,  1.55it/s]378it [04:06,  1.55it/s]379it [04:07,  1.55it/s]380it [04:08,  1.56it/s]381it [04:08,  1.55it/s]382it [04:09,  1.55it/s]383it [04:10,  1.55it/s]384it [04:10,  1.55it/s]385it [04:11,  1.55it/s]386it [04:11,  1.55it/s]387it [04:12,  1.55it/s]388it [04:13,  1.55it/s]389it [04:13,  1.55it/s]390it [04:14,  1.55it/s]391it [04:15,  1.55it/s]392it [04:15,  1.55it/s]393it [04:16,  1.55it/s]394it [04:17,  1.55it/s]395it [04:17,  1.55it/s]396it [04:18,  1.55it/s]397it [04:19,  1.55it/s]398it [04:19,  1.55it/s]399it [04:20,  1.55it/s]400it [04:21,  1.29it/s]401it [04:22,  1.36it/s]402it [04:22,  1.41it/s]403it [04:23,  1.45it/s]404it [04:24,  1.48it/s]405it [04:24,  1.51it/s]406it [04:25,  1.52it/s]407it [04:25,  1.53it/s]408it [04:26,  1.54it/s]409it [04:27,  1.54it/s]410it [04:27,  1.54it/s]411it [04:28,  1.54it/s]412it [04:29,  1.55it/s]413it [04:29,  1.55it/s]414it [04:30,  1.55it/s]415it [04:31,  1.55it/s]416it [04:31,  1.55it/s]417it [04:32,  1.55it/s]418it [04:33,  1.55it/s]419it [04:33,  1.55it/s]420it [04:34,  1.55it/s]421it [04:34,  1.55it/s]422it [04:35,  1.55it/s]423it [04:36,  1.55it/s]424it [04:36,  1.55it/s]425it [04:37,  1.55it/s]426it [04:38,  1.55it/s]427it [04:38,  1.56it/s]428it [04:39,  1.56it/s]429it [04:40,  1.56it/s]430it [04:40,  1.56it/s]431it [04:41,  1.56it/s]432it [04:42,  1.56it/s]433it [04:42,  1.56it/s]434it [04:43,  1.55it/s]435it [04:43,  1.55it/s]436it [04:44,  1.55it/s]437it [04:45,  1.55it/s]438it [04:45,  1.55it/s]439it [04:46,  1.55it/s]440it [04:47,  1.55it/s]441it [04:47,  1.56it/s]442it [04:48,  1.56it/s]443it [04:49,  1.56it/s]444it [04:49,  1.56it/s]445it [04:50,  1.56it/s]446it [04:51,  1.56it/s]447it [04:51,  1.56it/s]448it [04:52,  1.55it/s]449it [04:52,  1.55it/s]450it [04:53,  1.56it/s]451it [04:54,  1.56it/s]452it [04:54,  1.55it/s]453it [04:55,  1.55it/s]454it [04:56,  1.55it/s]455it [04:56,  1.55it/s]456it [04:57,  1.55it/s]457it [04:58,  1.55it/s]458it [04:58,  1.55it/s]459it [04:59,  1.56it/s]460it [05:00,  1.56it/s]461it [05:00,  1.56it/s]462it [05:01,  1.56it/s]463it [05:01,  1.56it/s]464it [05:02,  1.56it/s]465it [05:03,  1.56it/s]466it [05:03,  1.56it/s]467it [05:04,  1.56it/s]468it [05:05,  1.56it/s]469it [05:05,  1.56it/s]470it [05:06,  1.56it/s]471it [05:07,  1.56it/s]472it [05:07,  1.55it/s]473it [05:08,  1.55it/s]474it [05:09,  1.55it/s]475it [05:09,  1.55it/s]476it [05:10,  1.55it/s]477it [05:10,  1.55it/s]478it [05:11,  1.55it/s]479it [05:12,  1.55it/s]480it [05:12,  1.55it/s]481it [05:13,  1.55it/s]482it [05:14,  1.55it/s]483it [05:14,  1.55it/s]484it [05:15,  1.55it/s]485it [05:16,  1.56it/s]486it [05:16,  1.55it/s]487it [05:17,  1.55it/s]488it [05:18,  1.55it/s]489it [05:18,  1.55it/s]490it [05:19,  1.55it/s]491it [05:20,  1.55it/s]492it [05:20,  1.55it/s]493it [05:21,  1.55it/s]494it [05:21,  1.55it/s]495it [05:22,  1.55it/s]496it [05:23,  1.55it/s]497it [05:23,  1.55it/s]498it [05:24,  1.55it/s]499it [05:25,  1.55it/s]500it [05:26,  1.31it/s]501it [05:26,  1.38it/s]502it [05:27,  1.43it/s]503it [05:28,  1.47it/s]504it [05:28,  1.50it/s]505it [05:29,  1.51it/s]506it [05:30,  1.53it/s]507it [05:30,  1.54it/s]508it [05:31,  1.55it/s]509it [05:31,  1.56it/s]510it [05:32,  1.56it/s]511it [05:33,  1.56it/s]512it [05:33,  1.56it/s]513it [05:34,  1.56it/s]514it [05:35,  1.56it/s]515it [05:35,  1.56it/s]516it [05:36,  1.56it/s]517it [05:37,  1.57it/s]518it [05:37,  1.57it/s]519it [05:38,  1.56it/s]520it [05:38,  1.56it/s]521it [05:39,  1.56it/s]522it [05:40,  1.56it/s]523it [05:40,  1.56it/s]524it [05:41,  1.56it/s]525it [05:42,  1.56it/s]526it [05:42,  1.56it/s]527it [05:43,  1.56it/s]528it [05:44,  1.56it/s]529it [05:44,  1.55it/s]530it [05:45,  1.56it/s]531it [05:46,  1.56it/s]532it [05:46,  1.56it/s]533it [05:47,  1.56it/s]534it [05:47,  1.56it/s]535it [05:48,  1.56it/s]536it [05:49,  1.56it/s]537it [05:49,  1.56it/s]538it [05:50,  1.56it/s]539it [05:51,  1.56it/s]540it [05:51,  1.57it/s]541it [05:52,  1.56it/s]542it [05:53,  1.56it/s]543it [05:53,  1.55it/s]544it [05:54,  1.55it/s]545it [05:55,  1.56it/s]546it [05:55,  1.56it/s]547it [05:56,  1.56it/s]548it [05:56,  1.56it/s]549it [05:57,  1.56it/s]550it [05:58,  1.56it/s]551it [05:58,  1.56it/s]552it [05:59,  1.56it/s]553it [06:00,  1.56it/s]554it [06:00,  1.56it/s]555it [06:01,  1.56it/s]556it [06:02,  1.56it/s]557it [06:02,  1.56it/s]558it [06:03,  1.56it/s]559it [06:04,  1.56it/s]560it [06:04,  1.56it/s]561it [06:05,  1.56it/s]562it [06:05,  1.57it/s]563it [06:06,  1.56it/s]564it [06:07,  1.56it/s]565it [06:07,  1.56it/s]566it [06:08,  1.56it/s]567it [06:09,  1.56it/s]568it [06:09,  1.54it/s]569it [06:10,  1.55it/s]570it [06:11,  1.56it/s]571it [06:11,  1.56it/s]572it [06:12,  1.56it/s]573it [06:12,  1.56it/s]574it [06:13,  1.56it/s]575it [06:14,  1.56it/s]576it [06:14,  1.56it/s]577it [06:15,  1.56it/s]578it [06:16,  1.56it/s]579it [06:16,  1.56it/s]580it [06:17,  1.56it/s]581it [06:18,  1.56it/s]582it [06:18,  1.56it/s]583it [06:19,  1.56it/s]584it [06:20,  1.56it/s]585it [06:20,  1.56it/s]586it [06:21,  1.56it/s]587it [06:21,  1.56it/s]588it [06:22,  1.56it/s]589it [06:23,  1.57it/s]590it [06:23,  1.57it/s]591it [06:24,  1.57it/s]592it [06:25,  1.56it/s]593it [06:25,  1.56it/s]594it [06:26,  1.56it/s]595it [06:27,  1.56it/s]596it [06:27,  1.56it/s]597it [06:28,  1.56it/s]598it [06:29,  1.56it/s]599it [06:29,  1.56it/s]600it [06:30,  1.31it/s]601it [06:31,  1.37it/s]602it [06:31,  1.43it/s]603it [06:32,  1.46it/s]604it [06:33,  1.49it/s]605it [06:33,  1.51it/s]606it [06:34,  1.52it/s]607it [06:35,  1.54it/s]608it [06:35,  1.54it/s]609it [06:36,  1.54it/s]610it [06:37,  1.55it/s]611it [06:37,  1.55it/s]612it [06:38,  1.55it/s]613it [06:39,  1.55it/s]614it [06:39,  1.55it/s]615it [06:40,  1.56it/s]616it [06:40,  1.55it/s]617it [06:41,  1.55it/s]618it [06:42,  1.55it/s]619it [06:42,  1.55it/s]620it [06:43,  1.55it/s]621it [06:44,  1.55it/s]622it [06:44,  1.55it/s]623it [06:45,  1.55it/s]624it [06:46,  1.55it/s]625it [06:46,  1.55it/s]626it [06:47,  1.55it/s]627it [06:48,  1.56it/s]628it [06:48,  1.55it/s]629it [06:49,  1.55it/s]630it [06:50,  1.55it/s]631it [06:50,  1.55it/s]632it [06:51,  1.56it/s]633it [06:51,  1.56it/s]634it [06:52,  1.55it/s]635it [06:53,  1.55it/s]636it [06:53,  1.55it/s]637it [06:54,  1.55it/s]638it [06:55,  1.55it/s]639it [06:55,  1.55it/s]640it [06:56,  1.55it/s]641it [06:57,  1.55it/s]642it [06:57,  1.54it/s]643it [06:58,  1.55it/s]644it [06:59,  1.55it/s]645it [06:59,  1.55it/s]646it [07:00,  1.55it/s]647it [07:00,  1.56it/s]648it [07:01,  1.56it/s]649it [07:02,  1.56it/s]650it [07:02,  1.56it/s]651it [07:03,  1.56it/s]652it [07:04,  1.55it/s]653it [07:04,  1.55it/s]654it [07:05,  1.56it/s]655it [07:06,  1.56it/s]656it [07:06,  1.55it/s]657it [07:07,  1.55it/s]658it [07:08,  1.55it/s]659it [07:08,  1.55it/s]660it [07:09,  1.56it/s]661it [07:09,  1.56it/s]662it [07:10,  1.56it/s]663it [07:11,  1.56it/s]664it [07:11,  1.56it/s]665it [07:12,  1.56it/s]666it [07:13,  1.56it/s]667it [07:13,  1.55it/s]668it [07:14,  1.55it/s]669it [07:15,  1.55it/s]670it [07:15,  1.55it/s]671it [07:16,  1.55it/s]672it [07:17,  1.55it/s]673it [07:17,  1.55it/s]674it [07:18,  1.55it/s]675it [07:18,  1.55it/s]676it [07:19,  1.55it/s]677it [07:20,  1.55it/s]678it [07:20,  1.55it/s]679it [07:21,  1.55it/s]680it [07:22,  1.55it/s]681it [07:22,  1.55it/s]682it [07:23,  1.55it/s]683it [07:24,  1.55it/s]684it [07:24,  1.55it/s]685it [07:25,  1.55it/s]686it [07:26,  1.55it/s]687it [07:26,  1.55it/s]688it [07:27,  1.55it/s]689it [07:28,  1.55it/s]690it [07:28,  1.56it/s]691it [07:29,  1.56it/s]692it [07:29,  1.56it/s]693it [07:30,  1.56it/s]694it [07:31,  1.55it/s]695it [07:31,  1.55it/s]696it [07:32,  1.55it/s]697it [07:33,  1.55it/s]698it [07:33,  1.55it/s]699it [07:34,  1.55it/s]700it [07:35,  1.31it/s]701it [07:36,  1.37it/s]702it [07:36,  1.42it/s]703it [07:37,  1.46it/s]704it [07:38,  1.48it/s]705it [07:38,  1.50it/s]706it [07:39,  1.52it/s]707it [07:40,  1.53it/s]708it [07:40,  1.54it/s]709it [07:41,  1.54it/s]710it [07:41,  1.54it/s]711it [07:42,  1.54it/s]712it [07:43,  1.55it/s]713it [07:43,  1.55it/s]714it [07:44,  1.55it/s]715it [07:45,  1.55it/s]716it [07:45,  1.55it/s]717it [07:46,  1.56it/s]718it [07:47,  1.56it/s]719it [07:47,  1.56it/s]720it [07:48,  1.56it/s]721it [07:49,  1.56it/s]722it [07:49,  1.55it/s]723it [07:50,  1.56it/s]724it [07:50,  1.56it/s]725it [07:51,  1.56it/s]726it [07:52,  1.55it/s]727it [07:52,  1.56it/s]728it [07:53,  1.56it/s]729it [07:54,  1.55it/s]730it [07:54,  1.55it/s]731it [07:55,  1.55it/s]732it [07:56,  1.56it/s]733it [07:56,  1.55it/s]734it [07:57,  1.55it/s]735it [07:58,  1.56it/s]736it [07:58,  1.56it/s]737it [07:59,  1.55it/s]738it [07:59,  1.55it/s]739it [08:00,  1.55it/s]740it [08:01,  1.55it/s]741it [08:01,  1.55it/s]742it [08:02,  1.55it/s]743it [08:03,  1.55it/s]744it [08:03,  1.55it/s]745it [08:04,  1.55it/s]746it [08:05,  1.55it/s]747it [08:05,  1.55it/s]748it [08:06,  1.54it/s]749it [08:07,  1.55it/s]750it [08:07,  1.55it/s]751it [08:08,  1.54it/s]752it [08:08,  1.54it/s]753it [08:09,  1.54it/s]754it [08:10,  1.54it/s]755it [08:10,  1.54it/s]756it [08:11,  1.54it/s]757it [08:12,  1.54it/s]758it [08:12,  1.54it/s]759it [08:13,  1.54it/s]760it [08:14,  1.54it/s]761it [08:14,  1.54it/s]762it [08:15,  1.54it/s]763it [08:16,  1.54it/s]764it [08:16,  1.54it/s]765it [08:17,  1.55it/s]766it [08:18,  1.55it/s]767it [08:18,  1.55it/s]768it [08:19,  1.55it/s]769it [08:20,  1.55it/s]770it [08:20,  1.55it/s]771it [08:21,  1.55it/s]772it [08:21,  1.55it/s]773it [08:22,  1.55it/s]774it [08:23,  1.55it/s]775it [08:23,  1.55it/s]776it [08:24,  1.55it/s]777it [08:25,  1.55it/s]778it [08:25,  1.55it/s]779it [08:26,  1.55it/s]780it [08:27,  1.55it/s]781it [08:27,  1.55it/s]782it [08:28,  1.55it/s]783it [08:29,  1.55it/s]784it [08:29,  1.55it/s]785it [08:30,  1.55it/s]786it [08:30,  1.55it/s]787it [08:31,  1.55it/s]788it [08:32,  1.55it/s]789it [08:32,  1.55it/s]790it [08:33,  1.55it/s]791it [08:34,  1.56it/s]792it [08:34,  1.55it/s]793it [08:35,  1.55it/s]794it [08:36,  1.55it/s]795it [08:36,  1.55it/s]796it [08:37,  1.55it/s]797it [08:38,  1.55it/s]798it [08:38,  1.55it/s]799it [08:39,  1.54it/s]800it [08:40,  1.31it/s]801it [08:41,  1.38it/s]802it [08:41,  1.42it/s]803it [08:42,  1.46it/s]804it [08:42,  1.49it/s]805it [08:43,  1.51it/s]806it [08:44,  1.52it/s]807it [08:44,  1.53it/s]808it [08:45,  1.54it/s]809it [08:46,  1.54it/s]810it [08:46,  1.54it/s]811it [08:47,  1.54it/s]812it [08:48,  1.54it/s]813it [08:48,  1.55it/s]814it [08:49,  1.55it/s]815it [08:50,  1.56it/s]816it [08:50,  1.56it/s]817it [08:51,  1.56it/s]818it [08:51,  1.56it/s]819it [08:52,  1.56it/s]820it [08:53,  1.56it/s]821it [08:53,  1.56it/s]822it [08:54,  1.55it/s]823it [08:55,  1.55it/s]824it [08:55,  1.55it/s]825it [08:56,  1.55it/s]826it [08:57,  1.55it/s]827it [08:57,  1.55it/s]828it [08:58,  1.55it/s]829it [08:59,  1.55it/s]830it [08:59,  1.56it/s]831it [09:00,  1.55it/s]832it [09:00,  1.55it/s]833it [09:01,  1.55it/s]834it [09:02,  1.55it/s]835it [09:02,  1.55it/s]836it [09:03,  1.55it/s]837it [09:04,  1.55it/s]838it [09:04,  1.55it/s]839it [09:05,  1.55it/s]840it [09:06,  1.55it/s]841it [09:06,  1.55it/s]842it [09:07,  1.55it/s]843it [09:08,  1.56it/s]844it [09:08,  1.55it/s]845it [09:09,  1.56it/s]846it [09:10,  1.55it/s]847it [09:10,  1.55it/s]848it [09:11,  1.55it/s]849it [09:11,  1.54it/s]850it [09:12,  1.55it/s]851it [09:13,  1.55it/s]852it [09:13,  1.55it/s]853it [09:14,  1.55it/s]854it [09:15,  1.55it/s]855it [09:15,  1.56it/s]856it [09:16,  1.56it/s]857it [09:17,  1.57it/s]858it [09:17,  1.56it/s]859it [09:18,  1.56it/s]860it [09:19,  1.55it/s]861it [09:19,  1.55it/s]862it [09:20,  1.55it/s]863it [09:20,  1.55it/s]864it [09:21,  1.55it/s]865it [09:22,  1.55it/s]866it [09:22,  1.55it/s]867it [09:23,  1.55it/s]868it [09:24,  1.55it/s]869it [09:24,  1.55it/s]870it [09:25,  1.55it/s]871it [09:26,  1.55it/s]872it [09:26,  1.55it/s]873it [09:27,  1.55it/s]874it [09:28,  1.55it/s]875it [09:28,  1.56it/s]876it [09:29,  1.56it/s]877it [09:30,  1.55it/s]878it [09:30,  1.54it/s]879it [09:31,  1.55it/s]880it [09:31,  1.54it/s]881it [09:32,  1.54it/s]882it [09:33,  1.54it/s]883it [09:33,  1.55it/s]884it [09:34,  1.55it/s]885it [09:35,  1.55it/s]886it [09:35,  1.55it/s]887it [09:36,  1.55it/s]888it [09:37,  1.54it/s]889it [09:37,  1.54it/s]890it [09:38,  1.54it/s]891it [09:39,  1.54it/s]892it [09:39,  1.54it/s]893it [09:40,  1.54it/s]894it [09:41,  1.54it/s]895it [09:41,  1.54it/s]896it [09:42,  1.54it/s]897it [09:42,  1.55it/s]898it [09:43,  1.55it/s]899it [09:44,  1.55it/s]900it [09:45,  1.31it/s]901it [09:45,  1.38it/s]902it [09:46,  1.43it/s]903it [09:47,  1.47it/s]904it [09:47,  1.49it/s]905it [09:48,  1.51it/s]906it [09:49,  1.52it/s]907it [09:49,  1.53it/s]908it [09:50,  1.53it/s]909it [09:51,  1.54it/s]910it [09:51,  1.54it/s]911it [09:52,  1.55it/s]912it [09:53,  1.55it/s]913it [09:53,  1.55it/s]914it [09:54,  1.56it/s]915it [09:54,  1.56it/s]916it [09:55,  1.56it/s]917it [09:56,  1.57it/s]918it [09:56,  1.57it/s]919it [09:57,  1.56it/s]920it [09:58,  1.56it/s]921it [09:58,  1.56it/s]922it [09:59,  1.55it/s]923it [10:00,  1.55it/s]924it [10:00,  1.55it/s]925it [10:01,  1.55it/s]926it [10:02,  1.55it/s]927it [10:02,  1.55it/s]928it [10:03,  1.55it/s]929it [10:03,  1.55it/s]930it [10:04,  1.55it/s]931it [10:05,  1.56it/s]932it [10:05,  1.57it/s]933it [10:06,  1.55it/s]934it [10:07,  1.55it/s]935it [10:07,  1.55it/s]936it [10:08,  1.55it/s]937it [10:09,  1.55it/s]938it [10:09,  1.54it/s]939it [10:10,  1.55it/s]940it [10:11,  1.55it/s]941it [10:11,  1.55it/s]942it [10:12,  1.55it/s]943it [10:12,  1.55it/s]944it [10:13,  1.55it/s]945it [10:14,  1.56it/s]946it [10:14,  1.56it/s]947it [10:15,  1.56it/s]948it [10:16,  1.55it/s]949it [10:16,  1.55it/s]950it [10:17,  1.54it/s]951it [10:18,  1.54it/s]952it [10:18,  1.54it/s]953it [10:19,  1.54it/s]954it [10:20,  1.54it/s]955it [10:20,  1.55it/s]956it [10:21,  1.56it/s]957it [10:21,  1.56it/s]958it [10:22,  1.55it/s]959it [10:23,  1.56it/s]960it [10:23,  1.56it/s]961it [10:24,  1.56it/s]962it [10:25,  1.56it/s]963it [10:25,  1.56it/s]964it [10:26,  1.56it/s]965it [10:27,  1.56it/s]966it [10:27,  1.56it/s]967it [10:28,  1.55it/s]968it [10:29,  1.55it/s]969it [10:29,  1.55it/s]970it [10:30,  1.55it/s]971it [10:30,  1.55it/s]972it [10:31,  1.55it/s]973it [10:32,  1.55it/s]974it [10:32,  1.55it/s]975it [10:33,  1.55it/s]976it [10:34,  1.56it/s]977it [10:34,  1.56it/s]978it [10:35,  1.55it/s]979it [10:36,  1.55it/s]980it [10:36,  1.55it/s]981it [10:37,  1.55it/s]982it [10:38,  1.55it/s]983it [10:38,  1.55it/s]984it [10:39,  1.55it/s]985it [10:40,  1.55it/s]986it [10:40,  1.55it/s]987it [10:41,  1.55it/s]988it [10:41,  1.55it/s]989it [10:42,  1.55it/s]990it [10:43,  1.55it/s]991it [10:43,  1.55it/s]992it [10:44,  1.55it/s]993it [10:45,  1.55it/s]994it [10:45,  1.55it/s]995it [10:46,  1.55it/s]996it [10:47,  1.55it/s]997it [10:47,  1.54it/s]998it [10:48,  1.55it/s]999it [10:49,  1.55it/s]1000it [10:50,  1.31it/s]1001it [10:50,  1.39it/s]1002it [10:51,  1.44it/s]1003it [10:51,  1.47it/s]1004it [10:52,  1.49it/s]1005it [10:53,  1.51it/s]1006it [10:53,  1.52it/s]1007it [10:54,  1.52it/s]1008it [10:55,  1.53it/s]1009it [10:55,  1.54it/s]1010it [10:56,  1.54it/s]1011it [10:57,  1.53it/s]1012it [10:57,  1.54it/s]1013it [10:58,  1.54it/s]1014it [10:59,  1.54it/s]1015it [10:59,  1.53it/s]1016it [11:00,  1.54it/s]1017it [11:01,  1.54it/s]1018it [11:01,  1.53it/s]1019it [11:02,  1.53it/s]1020it [11:03,  1.53it/s]1021it [11:03,  1.53it/s]1022it [11:04,  1.53it/s]1023it [11:04,  1.54it/s]1024it [11:05,  1.54it/s]1025it [11:06,  1.55it/s]1026it [11:06,  1.55it/s]1027it [11:07,  1.55it/s]1028it [11:08,  1.55it/s]1029it [11:08,  1.54it/s]1030it [11:09,  1.54it/s]1031it [11:10,  1.53it/s]1032it [11:10,  1.53it/s]1033it [11:11,  1.52it/s]1034it [11:12,  1.52it/s]1035it [11:12,  1.53it/s]1036it [11:13,  1.54it/s]1037it [11:14,  1.54it/s]1038it [11:14,  1.54it/s]1039it [11:15,  1.54it/s]1040it [11:16,  1.54it/s]1041it [11:16,  1.54it/s]1042it [11:17,  1.53it/s]1043it [11:18,  1.53it/s]1044it [11:18,  1.54it/s]1045it [11:19,  1.54it/s]1046it [11:19,  1.54it/s]1047it [11:20,  1.54it/s]1048it [11:21,  1.54it/s]1049it [11:21,  1.54it/s]1050it [11:22,  1.54it/s]1051it [11:23,  1.54it/s]1052it [11:23,  1.54it/s]1053it [11:24,  1.53it/s]1054it [11:25,  1.53it/s]1055it [11:25,  1.53it/s]1056it [11:26,  1.53it/s]1057it [11:27,  1.53it/s]1058it [11:27,  1.53it/s]1059it [11:28,  1.53it/s]1060it [11:29,  1.53it/s]1061it [11:29,  1.53it/s]1062it [11:30,  1.53it/s]1063it [11:31,  1.54it/s]1064it [11:31,  1.54it/s]1065it [11:32,  1.54it/s]1066it [11:32,  1.54it/s]1067it [11:33,  1.55it/s]1068it [11:34,  1.55it/s]1069it [11:34,  1.54it/s]1070it [11:35,  1.54it/s]1071it [11:36,  1.54it/s]1072it [11:36,  1.54it/s]1073it [11:37,  1.53it/s]1074it [11:38,  1.53it/s]1075it [11:38,  1.50it/s]1076it [11:39,  1.51it/s]1077it [11:40,  1.52it/s]1078it [11:40,  1.53it/s]1079it [11:41,  1.53it/s]1080it [11:42,  1.53it/s]1081it [11:42,  1.53it/s]1082it [11:43,  1.53it/s]1083it [11:44,  1.54it/s]1084it [11:44,  1.54it/s]1085it [11:45,  1.54it/s]1086it [11:46,  1.54it/s]1087it [11:46,  1.54it/s]1088it [11:47,  1.53it/s]1089it [11:47,  1.54it/s]1090it [11:48,  1.53it/s]1091it [11:49,  1.54it/s]1092it [11:49,  1.54it/s]1093it [11:50,  1.53it/s]1094it [11:51,  1.53it/s]1095it [11:51,  1.53it/s]1096it [11:52,  1.54it/s]1097it [11:53,  1.54it/s]1098it [11:53,  1.54it/s]1099it [11:54,  1.54it/s]1100it [11:55,  1.28it/s]1101it [11:56,  1.35it/s]1102it [11:56,  1.41it/s]1103it [11:57,  1.45it/s]1104it [11:58,  1.48it/s]1105it [11:58,  1.50it/s]1106it [11:59,  1.51it/s]1107it [12:00,  1.53it/s]1108it [12:00,  1.54it/s]1109it [12:01,  1.54it/s]1110it [12:01,  1.54it/s]1111it [12:02,  1.54it/s]1112it [12:03,  1.54it/s]1113it [12:03,  1.54it/s]1114it [12:04,  1.54it/s]1115it [12:05,  1.55it/s]1116it [12:05,  1.55it/s]1117it [12:06,  1.55it/s]1118it [12:07,  1.56it/s]1119it [12:07,  1.56it/s]1120it [12:08,  1.55it/s]1121it [12:09,  1.55it/s]1122it [12:09,  1.55it/s]1123it [12:10,  1.55it/s]1124it [12:11,  1.55it/s]1125it [12:11,  1.55it/s]1126it [12:12,  1.54it/s]1127it [12:12,  1.54it/s]1128it [12:13,  1.55it/s]1129it [12:14,  1.55it/s]1130it [12:14,  1.55it/s]1131it [12:15,  1.55it/s]1132it [12:16,  1.55it/s]1133it [12:16,  1.55it/s]1134it [12:17,  1.55it/s]1135it [12:18,  1.55it/s]1136it [12:18,  1.55it/s]1137it [12:19,  1.55it/s]1138it [12:20,  1.56it/s]1139it [12:20,  1.56it/s]1140it [12:21,  1.55it/s]1141it [12:21,  1.55it/s]1142it [12:22,  1.56it/s]1143it [12:23,  1.56it/s]1144it [12:23,  1.56it/s]1145it [12:24,  1.55it/s]1146it [12:25,  1.56it/s]1147it [12:25,  1.55it/s]1148it [12:26,  1.55it/s]1149it [12:27,  1.55it/s]1150it [12:27,  1.55it/s]1151it [12:28,  1.55it/s]1152it [12:29,  1.54it/s]1153it [12:29,  1.54it/s]1154it [12:30,  1.55it/s]1155it [12:31,  1.55it/s]1156it [12:31,  1.55it/s]1157it [12:32,  1.55it/s]1158it [12:32,  1.55it/s]1159it [12:33,  1.55it/s]1160it [12:34,  1.55it/s]1161it [12:34,  1.54it/s]1162it [12:35,  1.54it/s]1163it [12:36,  1.55it/s]1164it [12:36,  1.55it/s]1165it [12:37,  1.55it/s]1166it [12:38,  1.55it/s]1167it [12:38,  1.55it/s]1168it [12:39,  1.55it/s]1169it [12:40,  1.55it/s]1170it [12:40,  1.55it/s]1171it [12:41,  1.55it/s]1172it [12:41,  1.55it/s]1173it [12:42,  1.56it/s]1174it [12:43,  1.56it/s]1175it [12:43,  1.55it/s]1176it [12:44,  1.55it/s]1177it [12:45,  1.55it/s]1178it [12:45,  1.56it/s]1179it [12:46,  1.56it/s]1180it [12:47,  1.56it/s]1181it [12:47,  1.55it/s]1182it [12:48,  1.55it/s]1183it [12:49,  1.55it/s]1184it [12:49,  1.55it/s]1185it [12:50,  1.55it/s]1186it [12:51,  1.55it/s]1187it [12:51,  1.54it/s]1188it [12:52,  1.55it/s]1189it [12:52,  1.55it/s]1190it [12:53,  1.54it/s]1191it [12:54,  1.54it/s]1192it [12:54,  1.54it/s]1193it [12:55,  1.54it/s]1194it [12:56,  1.55it/s]1195it [12:56,  1.54it/s]1196it [12:57,  1.55it/s]1197it [12:58,  1.55it/s]1198it [12:58,  1.55it/s]1199it [12:59,  1.55it/s]1200it [13:00,  1.31it/s]1201it [13:01,  1.38it/s]1202it [13:01,  1.42it/s]1203it [13:02,  1.46it/s]1204it [13:03,  1.48it/s]1205it [13:03,  1.50it/s]1206it [13:04,  1.52it/s]1207it [13:04,  1.53it/s]1208it [13:05,  1.53it/s]1209it [13:06,  1.54it/s]1210it [13:06,  1.54it/s]1211it [13:07,  1.55it/s]1212it [13:08,  1.54it/s]1213it [13:08,  1.55it/s]1214it [13:09,  1.55it/s]1215it [13:10,  1.55it/s]1216it [13:10,  1.55it/s]1217it [13:11,  1.55it/s]1218it [13:12,  1.54it/s]1219it [13:12,  1.55it/s]1220it [13:13,  1.54it/s]1221it [13:14,  1.55it/s]1222it [13:14,  1.54it/s]1223it [13:15,  1.54it/s]1224it [13:15,  1.55it/s]1225it [13:16,  1.55it/s]1226it [13:17,  1.56it/s]1227it [13:17,  1.56it/s]1228it [13:18,  1.56it/s]1229it [13:19,  1.56it/s]1230it [13:19,  1.56it/s]1231it [13:20,  1.56it/s]1232it [13:21,  1.56it/s]1233it [13:21,  1.56it/s]1234it [13:22,  1.55it/s]1235it [13:23,  1.55it/s]1236it [13:23,  1.55it/s]1237it [13:24,  1.55it/s]1238it [13:24,  1.55it/s]1239it [13:25,  1.55it/s]1240it [13:26,  1.55it/s]1241it [13:26,  1.55it/s]1242it [13:27,  1.55it/s]1243it [13:28,  1.55it/s]1244it [13:28,  1.56it/s]1245it [13:29,  1.56it/s]1246it [13:30,  1.56it/s]1247it [13:30,  1.56it/s]1248it [13:31,  1.55it/s]1249it [13:32,  1.55it/s]1250it [13:32,  1.55it/s]1251it [13:33,  1.55it/s]1252it [13:33,  1.54it/s]1253it [13:34,  1.54it/s]1254it [13:35,  1.54it/s]1255it [13:35,  1.55it/s]1256it [13:36,  1.55it/s]1257it [13:37,  1.55it/s]1258it [13:37,  1.55it/s]1259it [13:38,  1.55it/s]1260it [13:39,  1.55it/s]1261it [13:39,  1.56it/s]1262it [13:40,  1.57it/s]1263it [13:41,  1.57it/s]1264it [13:41,  1.57it/s]1265it [13:42,  1.57it/s]1266it [13:42,  1.57it/s]1267it [13:43,  1.56it/s]1268it [13:44,  1.56it/s]1269it [13:44,  1.56it/s]1270it [13:45,  1.56it/s]1271it [13:46,  1.56it/s]1272it [13:46,  1.55it/s]1273it [13:47,  1.56it/s]1274it [13:48,  1.56it/s]1275it [13:48,  1.56it/s]1276it [13:49,  1.56it/s]1277it [13:50,  1.56it/s]1278it [13:50,  1.56it/s]1279it [13:51,  1.56it/s]1280it [13:51,  1.56it/s]1281it [13:52,  1.56it/s]1282it [13:53,  1.56it/s]1283it [13:53,  1.57it/s]1284it [13:54,  1.56it/s]1285it [13:55,  1.56it/s]1286it [13:55,  1.56it/s]1287it [13:56,  1.57it/s]1288it [13:57,  1.57it/s]1289it [13:57,  1.57it/s]1290it [13:58,  1.56it/s]1291it [13:58,  1.56it/s]1292it [13:59,  1.56it/s]1293it [14:00,  1.55it/s]1294it [14:00,  1.56it/s]1295it [14:01,  1.56it/s]1296it [14:02,  1.55it/s]1297it [14:02,  1.56it/s]1298it [14:03,  1.56it/s]1299it [14:04,  1.56it/s]1300it [14:05,  1.31it/s]1301it [14:05,  1.38it/s]1302it [14:06,  1.43it/s]1303it [14:07,  1.47it/s]1304it [14:07,  1.50it/s]1305it [14:08,  1.51it/s]1306it [14:08,  1.53it/s]1307it [14:09,  1.53it/s]1308it [14:10,  1.54it/s]1309it [14:10,  1.55it/s]1310it [14:11,  1.56it/s]1311it [14:12,  1.56it/s]1312it [14:12,  1.57it/s]1313it [14:13,  1.57it/s]1314it [14:14,  1.56it/s]1315it [14:14,  1.56it/s]1316it [14:15,  1.56it/s]1317it [14:16,  1.55it/s]1318it [14:16,  1.55it/s]1319it [14:17,  1.55it/s]1320it [14:17,  1.55it/s]1321it [14:18,  1.55it/s]1322it [14:19,  1.55it/s]1323it [14:19,  1.55it/s]1324it [14:20,  1.55it/s]1325it [14:21,  1.55it/s]1326it [14:21,  1.55it/s]1327it [14:22,  1.55it/s]1328it [14:23,  1.54it/s]1329it [14:23,  1.54it/s]1330it [14:24,  1.54it/s]1331it [14:25,  1.54it/s]1332it [14:25,  1.54it/s]1333it [14:26,  1.54it/s]1334it [14:27,  1.54it/s]1335it [14:27,  1.54it/s]1336it [14:28,  1.55it/s]1337it [14:28,  1.54it/s]1338it [14:29,  1.55it/s]1339it [14:30,  1.55it/s]1340it [14:30,  1.54it/s]1341it [14:31,  1.54it/s]1342it [14:32,  1.54it/s]1343it [14:32,  1.54it/s]1344it [14:33,  1.55it/s]1345it [14:34,  1.55it/s]1346it [14:34,  1.55it/s]1347it [14:35,  1.56it/s]1348it [14:36,  1.56it/s]1349it [14:36,  1.56it/s]1350it [14:37,  1.56it/s]1351it [14:38,  1.55it/s]1352it [14:38,  1.55it/s]1353it [14:39,  1.55it/s]1354it [14:39,  1.55it/s]1355it [14:40,  1.55it/s]1356it [14:41,  1.55it/s]1357it [14:41,  1.55it/s]1358it [14:42,  1.55it/s]1359it [14:43,  1.55it/s]1360it [14:43,  1.55it/s]1361it [14:44,  1.55it/s]1362it [14:45,  1.55it/s]1363it [14:45,  1.55it/s]1364it [14:46,  1.55it/s]1365it [14:47,  1.55it/s]1366it [14:47,  1.55it/s]1367it [14:48,  1.55it/s]1368it [14:48,  1.55it/s]1369it [14:49,  1.55it/s]1370it [14:50,  1.54it/s]1371it [14:50,  1.54it/s]1372it [14:51,  1.54it/s]1373it [14:52,  1.54it/s]1374it [14:52,  1.55it/s]1375it [14:53,  1.55it/s]1376it [14:54,  1.55it/s]1377it [14:54,  1.55it/s]1378it [14:55,  1.55it/s]1379it [14:56,  1.55it/s]1380it [14:56,  1.56it/s]1381it [14:57,  1.57it/s]1382it [14:57,  1.57it/s]1383it [14:58,  1.56it/s]1384it [14:59,  1.56it/s]1385it [14:59,  1.55it/s]1386it [15:00,  1.55it/s]1387it [15:01,  1.55it/s]1388it [15:01,  1.56it/s]1389it [15:02,  1.55it/s]1390it [15:03,  1.56it/s]1391it [15:03,  1.56it/s]1392it [15:04,  1.56it/s]1393it [15:05,  1.56it/s]1394it [15:05,  1.56it/s]1395it [15:06,  1.57it/s]1396it [15:06,  1.57it/s]1397it [15:07,  1.57it/s]1398it [15:08,  1.57it/s]1399it [15:08,  1.56it/s]1400it [15:09,  1.31it/s]1401it [15:10,  1.38it/s]1402it [15:11,  1.42it/s]1403it [15:11,  1.46it/s]1404it [15:12,  1.48it/s]1405it [15:13,  1.50it/s]1406it [15:13,  1.51it/s]1407it [15:14,  1.52it/s]1408it [15:15,  1.53it/s]1409it [15:15,  1.54it/s]1410it [15:16,  1.54it/s]1411it [15:17,  1.55it/s]1412it [15:17,  1.55it/s]1413it [15:18,  1.55it/s]1414it [15:18,  1.55it/s]1415it [15:19,  1.55it/s]1416it [15:20,  1.55it/s]1417it [15:20,  1.56it/s]1418it [15:21,  1.56it/s]1419it [15:22,  1.56it/s]1420it [15:22,  1.55it/s]1421it [15:23,  1.55it/s]1422it [15:24,  1.56it/s]1423it [15:24,  1.56it/s]1424it [15:25,  1.56it/s]1425it [15:26,  1.56it/s]1426it [15:26,  1.56it/s]1427it [15:27,  1.56it/s]1428it [15:27,  1.56it/s]1429it [15:28,  1.55it/s]1430it [15:29,  1.55it/s]1431it [15:29,  1.55it/s]1432it [15:30,  1.55it/s]1433it [15:31,  1.55it/s]1434it [15:31,  1.55it/s]1435it [15:32,  1.55it/s]1436it [15:33,  1.55it/s]1437it [15:33,  1.55it/s]1438it [15:34,  1.55it/s]1439it [15:35,  1.55it/s]1440it [15:35,  1.55it/s]1441it [15:36,  1.55it/s]1442it [15:37,  1.55it/s]1443it [15:37,  1.55it/s]1444it [15:38,  1.54it/s]1445it [15:38,  1.55it/s]1446it [15:39,  1.55it/s]1447it [15:40,  1.55it/s]1448it [15:40,  1.54it/s]1449it [15:41,  1.55it/s]1450it [15:42,  1.55it/s]1451it [15:42,  1.55it/s]1452it [15:43,  1.55it/s]1453it [15:44,  1.55it/s]1454it [15:44,  1.55it/s]1455it [15:45,  1.55it/s]1456it [15:46,  1.55it/s]1457it [15:46,  1.55it/s]1458it [15:47,  1.55it/s]1459it [15:47,  1.56it/s]1460it [15:48,  1.55it/s]1461it [15:49,  1.55it/s]1462it [15:49,  1.55it/s]1463it [15:50,  1.55it/s]1464it [15:51,  1.55it/s]1465it [15:51,  1.55it/s]1466it [15:52,  1.56it/s]1467it [15:53,  1.55it/s]1468it [15:53,  1.55it/s]1469it [15:54,  1.55it/s]1470it [15:55,  1.55it/s]1471it [15:55,  1.55it/s]1472it [15:56,  1.55it/s]1473it [15:57,  1.55it/s]1474it [15:57,  1.55it/s]1475it [15:58,  1.55it/s]1476it [15:58,  1.55it/s]1477it [15:59,  1.55it/s]1478it [16:00,  1.56it/s]1479it [16:00,  1.56it/s]1480it [16:01,  1.56it/s]1481it [16:02,  1.56it/s]1482it [16:02,  1.55it/s]1483it [16:03,  1.56it/s]1484it [16:04,  1.56it/s]1485it [16:04,  1.55it/s]1486it [16:05,  1.55it/s]1487it [16:06,  1.55it/s]1488it [16:06,  1.55it/s]1489it [16:07,  1.55it/s]1490it [16:07,  1.55it/s]1491it [16:08,  1.55it/s]1492it [16:09,  1.55it/s]1493it [16:09,  1.55it/s]1494it [16:10,  1.56it/s]1495it [16:11,  1.56it/s]1496it [16:11,  1.56it/s]1497it [16:12,  1.56it/s]1498it [16:13,  1.56it/s]1499it [16:13,  1.55it/s]1500it [16:14,  1.32it/s]1501it [16:15,  1.38it/s]1502it [16:16,  1.43it/s]1503it [16:16,  1.46it/s]1504it [16:17,  1.49it/s]1505it [16:17,  1.51it/s]1506it [16:18,  1.52it/s]1507it [16:19,  1.53it/s]1508it [16:19,  1.53it/s]1509it [16:20,  1.54it/s]1510it [16:21,  1.54it/s]1511it [16:21,  1.55it/s]1512it [16:22,  1.55it/s]1513it [16:23,  1.55it/s]1514it [16:23,  1.55it/s]1515it [16:24,  1.55it/s]1516it [16:25,  1.55it/s]1517it [16:25,  1.54it/s]1518it [16:26,  1.55it/s]1519it [16:27,  1.55it/s]1520it [16:27,  1.55it/s]1521it [16:28,  1.55it/s]1522it [16:28,  1.55it/s]1523it [16:29,  1.55it/s]1524it [16:30,  1.55it/s]1525it [16:30,  1.55it/s]1526it [16:31,  1.56it/s]1527it [16:32,  1.56it/s]1528it [16:32,  1.56it/s]1529it [16:33,  1.56it/s]1530it [16:34,  1.56it/s]1531it [16:34,  1.56it/s]1532it [16:35,  1.56it/s]1533it [16:36,  1.56it/s]1534it [16:36,  1.55it/s]1535it [16:37,  1.55it/s]1536it [16:37,  1.55it/s]1537it [16:38,  1.55it/s]1538it [16:39,  1.55it/s]1539it [16:39,  1.55it/s]1540it [16:40,  1.55it/s]1541it [16:41,  1.55it/s]1542it [16:41,  1.55it/s]1543it [16:42,  1.56it/s]1544it [16:43,  1.56it/s]1545it [16:43,  1.56it/s]1546it [16:44,  1.55it/s]1547it [16:45,  1.55it/s]1548it [16:45,  1.55it/s]1549it [16:46,  1.55it/s]1550it [16:46,  1.56it/s]1551it [16:47,  1.56it/s]1552it [16:48,  1.56it/s]1553it [16:48,  1.56it/s]1554it [16:49,  1.56it/s]1555it [16:50,  1.55it/s]1556it [16:50,  1.55it/s]1557it [16:51,  1.55it/s]1558it [16:52,  1.55it/s]1559it [16:52,  1.55it/s]1560it [16:53,  1.56it/s]1561it [16:54,  1.56it/s]1562it [16:54,  1.55it/s]1563it [16:55,  1.55it/s]1564it [16:55,  1.55it/s]1565it [16:56,  1.55it/s]1566it [16:57,  1.55it/s]1567it [16:57,  1.55it/s]1568it [16:58,  1.56it/s]1569it [16:59,  1.56it/s]1570it [16:59,  1.55it/s]1571it [17:00,  1.56it/s]1572it [17:01,  1.56it/s]1573it [17:01,  1.55it/s]1574it [17:02,  1.55it/s]1575it [17:03,  1.55it/s]1576it [17:03,  1.55it/s]1577it [17:04,  1.55it/s]1578it [17:04,  1.55it/s]1579it [17:05,  1.55it/s]1580it [17:06,  1.55it/s]1581it [17:06,  1.56it/s]1582it [17:07,  1.56it/s]1583it [17:08,  1.56it/s]1584it [17:08,  1.56it/s]1585it [17:09,  1.56it/s]1586it [17:10,  1.56it/s]1587it [17:10,  1.56it/s]1588it [17:11,  1.56it/s]1589it [17:12,  1.56it/s]1590it [17:12,  1.55it/s]1591it [17:13,  1.56it/s]1592it [17:13,  1.56it/s]1593it [17:14,  1.55it/s]1594it [17:15,  1.55it/s]1595it [17:15,  1.55it/s]1596it [17:16,  1.56it/s]1597it [17:17,  1.55it/s]1598it [17:17,  1.56it/s]1599it [17:18,  1.55it/s]1600it [17:19,  1.29it/s]1601it [17:20,  1.36it/s]1602it [17:20,  1.41it/s]1603it [17:21,  1.45it/s]1604it [17:22,  1.48it/s]1605it [17:22,  1.51it/s]1606it [17:23,  1.52it/s]1607it [17:24,  1.54it/s]1608it [17:24,  1.55it/s]1609it [17:25,  1.55it/s]1610it [17:25,  1.55it/s]1611it [17:26,  1.55it/s]1612it [17:27,  1.55it/s]1613it [17:27,  1.56it/s]1614it [17:28,  1.55it/s]1615it [17:29,  1.55it/s]1616it [17:29,  1.55it/s]1617it [17:30,  1.55it/s]1618it [17:31,  1.55it/s]1619it [17:31,  1.55it/s]1620it [17:32,  1.55it/s]1621it [17:33,  1.55it/s]1622it [17:33,  1.56it/s]1623it [17:34,  1.56it/s]1624it [17:34,  1.56it/s]1625it [17:35,  1.55it/s]1626it [17:36,  1.56it/s]1627it [17:36,  1.56it/s]1628it [17:37,  1.55it/s]1629it [17:38,  1.56it/s]1630it [17:38,  1.55it/s]1631it [17:39,  1.55it/s]1632it [17:40,  1.55it/s]1633it [17:40,  1.55it/s]1634it [17:41,  1.55it/s]1635it [17:42,  1.56it/s]1636it [17:42,  1.56it/s]1637it [17:43,  1.56it/s]1638it [17:43,  1.56it/s]1639it [17:44,  1.56it/s]1640it [17:45,  1.56it/s]1641it [17:45,  1.56it/s]1642it [17:46,  1.56it/s]1643it [17:47,  1.56it/s]1644it [17:47,  1.56it/s]1645it [17:48,  1.56it/s]1646it [17:49,  1.55it/s]1647it [17:49,  1.55it/s]1648it [17:50,  1.56it/s]1649it [17:51,  1.56it/s]1650it [17:51,  1.55it/s]1651it [17:52,  1.56it/s]1652it [17:52,  1.56it/s]1653it [17:53,  1.56it/s]1654it [17:54,  1.56it/s]1655it [17:54,  1.56it/s]1656it [17:55,  1.55it/s]1657it [17:56,  1.56it/s]1658it [17:56,  1.56it/s]1659it [17:57,  1.56it/s]1660it [17:58,  1.55it/s]1661it [17:58,  1.55it/s]1662it [17:59,  1.55it/s]1663it [18:00,  1.55it/s]1664it [18:00,  1.56it/s]1665it [18:01,  1.55it/s]1666it [18:01,  1.55it/s]1667it [18:02,  1.56it/s]1668it [18:03,  1.56it/s]1669it [18:03,  1.56it/s]1670it [18:04,  1.55it/s]1671it [18:05,  1.55it/s]1672it [18:05,  1.55it/s]1673it [18:06,  1.56it/s]1674it [18:07,  1.56it/s]1675it [18:07,  1.56it/s]1676it [18:08,  1.56it/s]1677it [18:09,  1.56it/s]1678it [18:09,  1.56it/s]1679it [18:10,  1.57it/s]1680it [18:10,  1.56it/s]1681it [18:11,  1.56it/s]1682it [18:12,  1.56it/s]1683it [18:12,  1.56it/s]1684it [18:13,  1.55it/s]1685it [18:14,  1.55it/s]1686it [18:14,  1.55it/s]1687it [18:15,  1.55it/s]1688it [18:16,  1.56it/s]1689it [18:16,  1.56it/s]1690it [18:17,  1.55it/s]1691it [18:18,  1.55it/s]1692it [18:18,  1.56it/s]1693it [18:19,  1.56it/s]1694it [18:19,  1.56it/s]1695it [18:20,  1.56it/s]1696it [18:21,  1.56it/s]1697it [18:21,  1.55it/s]1698it [18:22,  1.55it/s]1699it [18:23,  1.55it/s]1700it [18:24,  1.31it/s]1701it [18:24,  1.38it/s]1702it [18:25,  1.43it/s]1703it [18:26,  1.47it/s]1704it [18:26,  1.50it/s]1705it [18:27,  1.51it/s]1706it [18:28,  1.53it/s]1707it [18:28,  1.53it/s]1708it [18:29,  1.54it/s]1709it [18:29,  1.54it/s]1710it [18:30,  1.54it/s]1711it [18:31,  1.55it/s]1712it [18:31,  1.55it/s]1713it [18:32,  1.55it/s]1714it [18:33,  1.55it/s]1715it [18:33,  1.55it/s]1716it [18:34,  1.55it/s]1717it [18:35,  1.55it/s]1718it [18:35,  1.55it/s]1719it [18:36,  1.55it/s]1720it [18:37,  1.55it/s]1721it [18:37,  1.55it/s]1722it [18:38,  1.55it/s]1723it [18:39,  1.55it/s]1724it [18:39,  1.55it/s]1725it [18:40,  1.56it/s]1726it [18:40,  1.56it/s]1727it [18:41,  1.56it/s]1728it [18:42,  1.55it/s]1729it [18:42,  1.55it/s]1730it [18:43,  1.56it/s]1731it [18:44,  1.55it/s]1732it [18:44,  1.55it/s]1733it [18:45,  1.55it/s]1734it [18:46,  1.55it/s]1735it [18:46,  1.55it/s]1736it [18:47,  1.56it/s]1737it [18:48,  1.55it/s]1738it [18:48,  1.55it/s]1739it [18:49,  1.55it/s]1740it [18:49,  1.55it/s]1741it [18:50,  1.55it/s]1742it [18:51,  1.56it/s]1743it [18:51,  1.56it/s]1744it [18:52,  1.56it/s]1745it [18:53,  1.56it/s]1746it [18:53,  1.55it/s]1747it [18:54,  1.55it/s]1748it [18:55,  1.55it/s]1749it [18:55,  1.56it/s]1750it [18:56,  1.56it/s]1751it [18:57,  1.56it/s]1752it [18:57,  1.56it/s]1753it [18:58,  1.55it/s]1754it [18:58,  1.55it/s]1755it [18:59,  1.55it/s]1756it [19:00,  1.55it/s]1757it [19:00,  1.55it/s]1758it [19:01,  1.55it/s]1759it [19:02,  1.56it/s]1760it [19:02,  1.56it/s]1761it [19:03,  1.56it/s]1762it [19:04,  1.56it/s]1763it [19:04,  1.55it/s]1764it [19:05,  1.55it/s]1765it [19:06,  1.55it/s]1766it [19:06,  1.55it/s]1767it [19:07,  1.55it/s]1768it [19:07,  1.55it/s]1769it [19:08,  1.54it/s]1770it [19:09,  1.54it/s]1771it [19:09,  1.55it/s]1772it [19:10,  1.55it/s]1773it [19:11,  1.54it/s]1774it [19:11,  1.55it/s]1775it [19:12,  1.55it/s]1776it [19:13,  1.55it/s]1777it [19:13,  1.55it/s]1778it [19:14,  1.55it/s]1779it [19:15,  1.56it/s]1780it [19:15,  1.56it/s]1781it [19:16,  1.56it/s]1782it [19:16,  1.56it/s]1783it [19:17,  1.55it/s]1784it [19:18,  1.55it/s]1785it [19:18,  1.55it/s]1786it [19:19,  1.55it/s]1787it [19:20,  1.55it/s]1788it [19:20,  1.55it/s]1789it [19:21,  1.56it/s]1790it [19:22,  1.56it/s]1791it [19:22,  1.56it/s]1792it [19:23,  1.56it/s]1793it [19:24,  1.55it/s]1794it [19:24,  1.55it/s]1795it [19:25,  1.55it/s]1796it [19:26,  1.55it/s]1797it [19:26,  1.55it/s]1798it [19:27,  1.55it/s]1799it [19:27,  1.55it/s]1800it [19:29,  1.29it/s]1801it [19:29,  1.36it/s]1802it [19:30,  1.41it/s]1803it [19:30,  1.45it/s]1804it [19:31,  1.48it/s]1805it [19:32,  1.50it/s]1806it [19:32,  1.51it/s]1807it [19:33,  1.52it/s]1808it [19:34,  1.53it/s]1809it [19:34,  1.53it/s]1810it [19:35,  1.53it/s]1811it [19:36,  1.53it/s]1812it [19:36,  1.53it/s]1813it [19:37,  1.54it/s]1814it [19:38,  1.53it/s]1815it [19:38,  1.54it/s]1816it [19:39,  1.54it/s]1817it [19:40,  1.54it/s]1818it [19:40,  1.54it/s]1819it [19:41,  1.54it/s]1820it [19:41,  1.54it/s]1821it [19:42,  1.55it/s]1822it [19:43,  1.55it/s]1823it [19:43,  1.55it/s]1824it [19:44,  1.55it/s]1825it [19:45,  1.55it/s]1826it [19:45,  1.55it/s]1827it [19:46,  1.55it/s]1828it [19:47,  1.55it/s]1829it [19:47,  1.55it/s]1830it [19:48,  1.55it/s]1831it [19:49,  1.55it/s]1832it [19:49,  1.55it/s]1833it [19:50,  1.55it/s]1834it [19:51,  1.55it/s]1835it [19:51,  1.55it/s]1836it [19:52,  1.55it/s]1837it [19:52,  1.55it/s]1838it [19:53,  1.55it/s]1839it [19:54,  1.55it/s]1840it [19:54,  1.55it/s]1841it [19:55,  1.54it/s]1842it [19:56,  1.55it/s]1843it [19:56,  1.54it/s]1844it [19:57,  1.54it/s]1845it [19:58,  1.55it/s]1846it [19:58,  1.55it/s]1847it [19:59,  1.55it/s]1848it [20:00,  1.55it/s]1849it [20:00,  1.54it/s]1850it [20:01,  1.54it/s]1851it [20:02,  1.54it/s]1852it [20:02,  1.55it/s]1853it [20:03,  1.55it/s]1854it [20:03,  1.54it/s]1855it [20:04,  1.54it/s]1856it [20:05,  1.54it/s]1857it [20:05,  1.54it/s]1858it [20:06,  1.54it/s]1859it [20:07,  1.54it/s]1860it [20:07,  1.54it/s]1861it [20:08,  1.54it/s]1862it [20:09,  1.54it/s]1863it [20:09,  1.55it/s]1864it [20:10,  1.54it/s]1865it [20:11,  1.54it/s]1866it [20:11,  1.54it/s]1867it [20:12,  1.54it/s]1868it [20:13,  1.54it/s]1869it [20:13,  1.54it/s]1870it [20:14,  1.54it/s]1871it [20:14,  1.54it/s]1872it [20:15,  1.54it/s]1873it [20:16,  1.55it/s]1874it [20:16,  1.55it/s]1875it [20:17,  1.55it/s]1876it [20:18,  1.55it/s]1877it [20:18,  1.55it/s]1878it [20:19,  1.54it/s]1879it [20:20,  1.54it/s]1880it [20:20,  1.54it/s]1881it [20:21,  1.53it/s]1882it [20:22,  1.54it/s]1883it [20:22,  1.53it/s]1884it [20:23,  1.54it/s]1885it [20:24,  1.53it/s]1886it [20:24,  1.54it/s]1887it [20:25,  1.54it/s]1888it [20:26,  1.54it/s]1889it [20:26,  1.54it/s]1890it [20:27,  1.54it/s]1891it [20:27,  1.54it/s]1892it [20:28,  1.54it/s]1893it [20:29,  1.54it/s]1894it [20:29,  1.54it/s]1895it [20:30,  1.54it/s]1896it [20:31,  1.54it/s]1897it [20:31,  1.55it/s]1898it [20:32,  1.55it/s]1899it [20:33,  1.55it/s]1900it [20:34,  1.29it/s]1901it [20:34,  1.36it/s]1902it [20:35,  1.41it/s]1903it [20:36,  1.45it/s]1904it [20:36,  1.47it/s]1905it [20:37,  1.49it/s]1906it [20:38,  1.51it/s]1907it [20:38,  1.52it/s]1908it [20:39,  1.53it/s]1909it [20:40,  1.53it/s]1910it [20:40,  1.54it/s]1911it [20:41,  1.54it/s]1912it [20:41,  1.55it/s]1913it [20:42,  1.55it/s]1914it [20:43,  1.54it/s]1915it [20:43,  1.55it/s]1916it [20:44,  1.54it/s]1917it [20:45,  1.55it/s]1918it [20:45,  1.55it/s]1919it [20:46,  1.55it/s]1920it [20:47,  1.54it/s]1921it [20:47,  1.54it/s]1922it [20:48,  1.54it/s]1923it [20:49,  1.54it/s]1924it [20:49,  1.54it/s]1925it [20:50,  1.55it/s]1926it [20:51,  1.55it/s]1927it [20:51,  1.56it/s]1928it [20:52,  1.56it/s]1929it [20:52,  1.56it/s]1930it [20:53,  1.56it/s]1931it [20:54,  1.56it/s]1932it [20:54,  1.56it/s]1933it [20:55,  1.56it/s]1934it [20:56,  1.56it/s]1935it [20:56,  1.56it/s]1936it [20:57,  1.56it/s]1937it [20:58,  1.56it/s]1938it [20:58,  1.56it/s]1939it [20:59,  1.56it/s]1940it [21:00,  1.56it/s]1941it [21:00,  1.56it/s]1942it [21:01,  1.56it/s]1943it [21:01,  1.55it/s]1944it [21:02,  1.56it/s]1945it [21:03,  1.56it/s]1946it [21:03,  1.56it/s]1947it [21:04,  1.55it/s]1948it [21:05,  1.55it/s]1949it [21:05,  1.55it/s]1950it [21:06,  1.55it/s]1951it [21:07,  1.55it/s]1952it [21:07,  1.55it/s]1953it [21:08,  1.55it/s]1954it [21:09,  1.55it/s]1955it [21:09,  1.54it/s]1956it [21:10,  1.54it/s]1957it [21:10,  1.55it/s]1958it [21:11,  1.54it/s]1959it [21:12,  1.55it/s]1960it [21:12,  1.55it/s]1961it [21:13,  1.55it/s]1962it [21:14,  1.55it/s]1963it [21:14,  1.55it/s]1964it [21:15,  1.55it/s]1965it [21:16,  1.55it/s]1966it [21:16,  1.55it/s]1967it [21:17,  1.55it/s]1968it [21:18,  1.55it/s]1969it [21:18,  1.55it/s]1970it [21:19,  1.55it/s]1971it [21:20,  1.55it/s]1972it [21:20,  1.54it/s]1973it [21:21,  1.55it/s]1974it [21:21,  1.54it/s]1975it [21:22,  1.54it/s]1976it [21:23,  1.55it/s]1977it [21:23,  1.55it/s]1978it [21:24,  1.54it/s]1979it [21:25,  1.55it/s]1980it [21:25,  1.55it/s]1981it [21:26,  1.55it/s]1982it [21:27,  1.55it/s]1983it [21:27,  1.55it/s]1984it [21:28,  1.55it/s]1985it [21:29,  1.55it/s]1986it [21:29,  1.55it/s]1987it [21:30,  1.55it/s]1988it [21:31,  1.55it/s]1989it [21:31,  1.55it/s]1990it [21:32,  1.55it/s]1991it [21:32,  1.56it/s]1992it [21:33,  1.56it/s]1993it [21:34,  1.56it/s]1994it [21:34,  1.55it/s]1995it [21:35,  1.55it/s]1996it [21:36,  1.55it/s]1997it [21:36,  1.55it/s]1998it [21:37,  1.55it/s]1999it [21:38,  1.55it/s]2000it [21:39,  1.28it/s]2001it [21:39,  1.35it/s]2002it [21:40,  1.41it/s]2003it [21:41,  1.45it/s]2004it [21:41,  1.47it/s]2005it [21:42,  1.50it/s]2006it [21:43,  1.52it/s]2007it [21:43,  1.54it/s]2008it [21:44,  1.55it/s]2009it [21:44,  1.55it/s]2010it [21:45,  1.55it/s]2011it [21:46,  1.55it/s]2012it [21:46,  1.55it/s]2013it [21:47,  1.55it/s]2014it [21:48,  1.55it/s]2015it [21:48,  1.55it/s]2016it [21:49,  1.53it/s]2017it [21:50,  1.53it/s]2018it [21:50,  1.54it/s]2019it [21:51,  1.54it/s]2020it [21:52,  1.54it/s]2021it [21:52,  1.55it/s]2022it [21:53,  1.55it/s]2023it [21:54,  1.55it/s]2024it [21:54,  1.55it/s]2025it [21:55,  1.55it/s]2026it [21:55,  1.56it/s]2027it [21:56,  1.56it/s]2028it [21:57,  1.56it/s]2029it [21:57,  1.56it/s]2030it [21:58,  1.55it/s]2031it [21:59,  1.55it/s]2032it [21:59,  1.55it/s]2033it [22:00,  1.55it/s]2034it [22:01,  1.55it/s]2035it [22:01,  1.55it/s]2036it [22:02,  1.55it/s]2037it [22:03,  1.55it/s]2038it [22:03,  1.55it/s]2039it [22:04,  1.55it/s]2040it [22:05,  1.54it/s]2041it [22:05,  1.54it/s]2042it [22:06,  1.54it/s]2043it [22:06,  1.54it/s]2044it [22:07,  1.54it/s]2045it [22:08,  1.54it/s]2046it [22:08,  1.54it/s]2047it [22:09,  1.55it/s]2048it [22:10,  1.55it/s]2049it [22:10,  1.55it/s]2050it [22:11,  1.55it/s]2051it [22:12,  1.55it/s]2052it [22:12,  1.55it/s]2053it [22:13,  1.55it/s]2054it [22:14,  1.55it/s]2055it [22:14,  1.54it/s]2056it [22:15,  1.54it/s]2057it [22:16,  1.55it/s]2058it [22:16,  1.55it/s]2059it [22:17,  1.55it/s]2060it [22:17,  1.55it/s]2061it [22:18,  1.55it/s]2062it [22:19,  1.55it/s]2063it [22:19,  1.55it/s]2064it [22:20,  1.55it/s]2065it [22:21,  1.55it/s]2066it [22:21,  1.55it/s]2067it [22:22,  1.55it/s]2068it [22:23,  1.55it/s]2069it [22:23,  1.55it/s]2070it [22:24,  1.55it/s]2071it [22:25,  1.55it/s]2072it [22:25,  1.55it/s]2073it [22:26,  1.55it/s]2074it [22:26,  1.56it/s]2075it [22:27,  1.56it/s]2076it [22:28,  1.56it/s]2077it [22:28,  1.55it/s]2078it [22:29,  1.55it/s]2079it [22:30,  1.55it/s]2080it [22:30,  1.54it/s]2081it [22:31,  1.54it/s]2082it [22:32,  1.54it/s]2083it [22:32,  1.54it/s]2084it [22:33,  1.54it/s]2085it [22:34,  1.54it/s]2086it [22:34,  1.55it/s]2087it [22:35,  1.55it/s]2088it [22:36,  1.55it/s]2089it [22:36,  1.55it/s]2090it [22:37,  1.55it/s]2091it [22:37,  1.55it/s]2092it [22:38,  1.55it/s]2093it [22:39,  1.56it/s]2094it [22:39,  1.56it/s]2095it [22:40,  1.55it/s]2096it [22:41,  1.55it/s]2097it [22:41,  1.55it/s]2098it [22:42,  1.55it/s]2099it [22:43,  1.54it/s]2100it [22:44,  1.29it/s]2101it [22:44,  1.36it/s]2102it [22:45,  1.41it/s]2103it [22:46,  1.44it/s]2104it [22:46,  1.48it/s]2105it [22:47,  1.50it/s]2106it [22:48,  1.51it/s]2107it [22:48,  1.53it/s]2108it [22:49,  1.53it/s]2109it [22:49,  1.55it/s]2110it [22:50,  1.55it/s]2111it [22:51,  1.55it/s]2112it [22:51,  1.55it/s]2113it [22:52,  1.55it/s]2114it [22:53,  1.55it/s]2115it [22:53,  1.55it/s]2116it [22:54,  1.55it/s]2117it [22:55,  1.55it/s]2118it [22:55,  1.55it/s]2119it [22:56,  1.54it/s]2120it [22:57,  1.54it/s]2121it [22:57,  1.54it/s]2122it [22:58,  1.55it/s]2123it [22:59,  1.55it/s]2124it [22:59,  1.55it/s]2125it [23:00,  1.55it/s]2126it [23:00,  1.55it/s]2127it [23:01,  1.55it/s]2128it [23:02,  1.55it/s]2129it [23:02,  1.54it/s]2130it [23:03,  1.55it/s]2131it [23:04,  1.55it/s]2132it [23:04,  1.55it/s]2133it [23:05,  1.55it/s]2134it [23:06,  1.55it/s]2135it [23:06,  1.55it/s]2136it [23:07,  1.55it/s]2137it [23:08,  1.55it/s]2138it [23:08,  1.55it/s]2139it [23:09,  1.55it/s]2140it [23:09,  1.55it/s]2141it [23:10,  1.56it/s]2142it [23:11,  1.56it/s]2143it [23:11,  1.55it/s]2144it [23:12,  1.55it/s]2145it [23:13,  1.56it/s]2146it [23:13,  1.56it/s]2147it [23:14,  1.56it/s]2148it [23:15,  1.56it/s]2149it [23:15,  1.56it/s]2150it [23:16,  1.56it/s]2151it [23:17,  1.56it/s]2152it [23:17,  1.56it/s]2153it [23:18,  1.56it/s]2154it [23:18,  1.55it/s]2155it [23:19,  1.55it/s]2156it [23:20,  1.55it/s]2157it [23:20,  1.55it/s]2158it [23:21,  1.55it/s]2159it [23:22,  1.55it/s]2160it [23:22,  1.55it/s]2161it [23:23,  1.55it/s]2162it [23:24,  1.55it/s]2163it [23:24,  1.55it/s]2164it [23:25,  1.55it/s]2165it [23:26,  1.55it/s]2166it [23:26,  1.55it/s]2167it [23:27,  1.55it/s]2168it [23:28,  1.54it/s]2169it [23:28,  1.55it/s]2170it [23:29,  1.55it/s]2171it [23:29,  1.55it/s]2172it [23:30,  1.55it/s]2173it [23:31,  1.55it/s]2174it [23:31,  1.55it/s]2175it [23:32,  1.55it/s]2176it [23:33,  1.55it/s]2177it [23:33,  1.55it/s]2178it [23:34,  1.55it/s]2179it [23:35,  1.55it/s]2180it [23:35,  1.55it/s]2181it [23:36,  1.55it/s]2182it [23:37,  1.55it/s]2183it [23:37,  1.55it/s]2184it [23:38,  1.55it/s]2185it [23:38,  1.55it/s]2186it [23:39,  1.54it/s]2187it [23:40,  1.54it/s]2188it [23:40,  1.54it/s]2189it [23:41,  1.54it/s]2190it [23:42,  1.54it/s]2191it [23:42,  1.54it/s]2192it [23:43,  1.54it/s]2193it [23:44,  1.55it/s]2194it [23:44,  1.55it/s]2195it [23:45,  1.55it/s]2196it [23:46,  1.55it/s]2197it [23:46,  1.55it/s]2198it [23:47,  1.55it/s]2199it [23:48,  1.55it/s]2200it [23:49,  1.29it/s]2201it [23:49,  1.37it/s]2202it [23:50,  1.42it/s]2203it [23:51,  1.46it/s]2204it [23:51,  1.49it/s]2205it [23:52,  1.51it/s]2206it [23:52,  1.52it/s]2207it [23:53,  1.53it/s]2208it [23:54,  1.53it/s]2209it [23:54,  1.54it/s]2210it [23:55,  1.54it/s]2211it [23:56,  1.54it/s]2212it [23:56,  1.55it/s]2213it [23:57,  1.55it/s]2214it [23:58,  1.55it/s]2215it [23:58,  1.55it/s]2216it [23:59,  1.55it/s]2217it [24:00,  1.55it/s]2218it [24:00,  1.55it/s]2219it [24:01,  1.55it/s]2220it [24:01,  1.55it/s]2221it [24:02,  1.55it/s]2222it [24:03,  1.55it/s]2223it [24:03,  1.55it/s]2224it [24:04,  1.55it/s]2225it [24:05,  1.56it/s]2226it [24:05,  1.56it/s]2227it [24:06,  1.55it/s]2228it [24:07,  1.56it/s]2229it [24:07,  1.55it/s]2230it [24:08,  1.55it/s]2231it [24:09,  1.55it/s]2232it [24:09,  1.55it/s]2233it [24:10,  1.55it/s]2234it [24:11,  1.54it/s]2235it [24:11,  1.55it/s]2236it [24:12,  1.54it/s]2237it [24:12,  1.55it/s]2238it [24:13,  1.55it/s]2239it [24:14,  1.54it/s]2240it [24:14,  1.54it/s]2241it [24:15,  1.55it/s]2242it [24:16,  1.55it/s]2243it [24:16,  1.55it/s]2244it [24:17,  1.55it/s]2245it [24:18,  1.55it/s]2246it [24:18,  1.55it/s]2247it [24:19,  1.55it/s]2248it [24:20,  1.55it/s]2249it [24:20,  1.56it/s]2250it [24:21,  1.55it/s]2251it [24:22,  1.55it/s]2252it [24:22,  1.55it/s]2253it [24:23,  1.55it/s]2254it [24:23,  1.55it/s]2255it [24:24,  1.55it/s]2256it [24:25,  1.55it/s]2257it [24:25,  1.55it/s]2258it [24:26,  1.55it/s]2259it [24:27,  1.55it/s]2260it [24:27,  1.55it/s]2261it [24:28,  1.55it/s]2262it [24:29,  1.55it/s]2263it [24:29,  1.56it/s]2264it [24:30,  1.56it/s]2265it [24:31,  1.56it/s]2266it [24:31,  1.56it/s]2267it [24:32,  1.55it/s]2268it [24:32,  1.56it/s]2269it [24:33,  1.56it/s]2270it [24:34,  1.55it/s]2271it [24:34,  1.55it/s]2272it [24:35,  1.55it/s]2273it [24:36,  1.55it/s]2274it [24:36,  1.55it/s]2275it [24:37,  1.55it/s]2276it [24:38,  1.56it/s]2277it [24:38,  1.55it/s]2278it [24:39,  1.55it/s]2279it [24:40,  1.55it/s]2280it [24:40,  1.55it/s]2281it [24:41,  1.54it/s]2282it [24:41,  1.55it/s]2283it [24:42,  1.55it/s]2284it [24:43,  1.55it/s]2285it [24:43,  1.55it/s]2286it [24:44,  1.56it/s]2287it [24:45,  1.56it/s]2288it [24:45,  1.57it/s]2289it [24:46,  1.57it/s]2290it [24:47,  1.57it/s]2291it [24:47,  1.57it/s]2292it [24:48,  1.57it/s]2293it [24:49,  1.56it/s]2294it [24:49,  1.56it/s]2295it [24:50,  1.55it/s]2296it [24:50,  1.55it/s]2297it [24:51,  1.55it/s]2298it [24:52,  1.55it/s]2299it [24:52,  1.55it/s]2300it [24:53,  1.29it/s]2301it [24:54,  1.36it/s]2302it [24:55,  1.41it/s]2303it [24:55,  1.45it/s]2304it [24:56,  1.48it/s]2305it [24:57,  1.50it/s]2306it [24:57,  1.52it/s]2307it [24:58,  1.53it/s]2308it [24:59,  1.54it/s]2309it [24:59,  1.54it/s]2310it [25:00,  1.54it/s]2311it [25:01,  1.54it/s]2312it [25:01,  1.54it/s]2313it [25:02,  1.54it/s]2314it [25:03,  1.54it/s]2315it [25:03,  1.55it/s]2316it [25:04,  1.55it/s]2317it [25:04,  1.55it/s]2318it [25:05,  1.55it/s]2319it [25:06,  1.55it/s]2320it [25:06,  1.55it/s]2321it [25:07,  1.54it/s]2322it [25:08,  1.55it/s]2323it [25:08,  1.54it/s]2324it [25:09,  1.55it/s]2325it [25:10,  1.55it/s]2326it [25:10,  1.55it/s]2327it [25:11,  1.55it/s]2328it [25:12,  1.55it/s]2329it [25:12,  1.55it/s]2330it [25:13,  1.55it/s]2331it [25:13,  1.55it/s]2332it [25:14,  1.55it/s]2333it [25:15,  1.55it/s]2334it [25:15,  1.55it/s]2335it [25:16,  1.55it/s]2336it [25:17,  1.55it/s]2337it [25:17,  1.55it/s]2338it [25:18,  1.56it/s]2339it [25:19,  1.56it/s]2340it [25:19,  1.56it/s]2341it [25:20,  1.55it/s]2342it [25:21,  1.55it/s]2343it [25:21,  1.55it/s]2344it [25:22,  1.55it/s]2345it [25:23,  1.55it/s]2346it [25:23,  1.55it/s]2347it [25:24,  1.55it/s]2348it [25:24,  1.54it/s]2349it [25:25,  1.54it/s]2350it [25:26,  1.54it/s]2351it [25:26,  1.54it/s]2352it [25:27,  1.54it/s]2353it [25:28,  1.54it/s]2354it [25:28,  1.55it/s]2355it [25:29,  1.55it/s]2356it [25:30,  1.55it/s]2357it [25:30,  1.55it/s]2358it [25:31,  1.55it/s]2359it [25:32,  1.55it/s]2360it [25:32,  1.55it/s]2361it [25:33,  1.55it/s]2362it [25:34,  1.55it/s]2363it [25:34,  1.55it/s]2364it [25:35,  1.55it/s]2365it [25:35,  1.55it/s]2366it [25:36,  1.56it/s]2367it [25:37,  1.55it/s]2368it [25:37,  1.55it/s]2369it [25:38,  1.56it/s]2370it [25:39,  1.56it/s]2371it [25:39,  1.55it/s]2372it [25:40,  1.55it/s]2373it [25:41,  1.56it/s]2374it [25:41,  1.55it/s]2375it [25:42,  1.55it/s]2376it [25:43,  1.55it/s]2377it [25:43,  1.55it/s]2378it [25:44,  1.55it/s]2379it [25:44,  1.55it/s]2380it [25:45,  1.55it/s]2381it [25:46,  1.55it/s]2382it [25:46,  1.55it/s]2383it [25:47,  1.55it/s]2384it [25:48,  1.55it/s]2385it [25:48,  1.55it/s]2386it [25:49,  1.56it/s]2387it [25:50,  1.55it/s]2388it [25:50,  1.55it/s]2389it [25:51,  1.55it/s]2390it [25:52,  1.55it/s]2391it [25:52,  1.55it/s]2392it [25:53,  1.55it/s]2393it [25:53,  1.55it/s]2394it [25:54,  1.55it/s]2395it [25:55,  1.54it/s]2396it [25:55,  1.55it/s]2397it [25:56,  1.54it/s]2398it [25:57,  1.54it/s]2399it [25:57,  1.55it/s]2400it [25:58,  1.31it/s]2401it [25:59,  1.38it/s]2402it [26:00,  1.43it/s]2403it [26:00,  1.46it/s]2404it [26:01,  1.48it/s]2405it [26:02,  1.50it/s]2406it [26:02,  1.51it/s]2407it [26:03,  1.53it/s]2408it [26:04,  1.54it/s]2409it [26:04,  1.55it/s]2410it [26:05,  1.55it/s]2411it [26:05,  1.55it/s]2412it [26:06,  1.56it/s]2413it [26:07,  1.56it/s]2414it [26:07,  1.55it/s]2415it [26:08,  1.55it/s]2416it [26:09,  1.55it/s]2417it [26:09,  1.55it/s]2418it [26:10,  1.55it/s]2419it [26:11,  1.55it/s]2420it [26:11,  1.55it/s]2421it [26:12,  1.55it/s]2422it [26:13,  1.56it/s]2423it [26:13,  1.55it/s]2424it [26:14,  1.56it/s]2425it [26:15,  1.55it/s]2426it [26:15,  1.55it/s]2427it [26:16,  1.55it/s]2428it [26:16,  1.55it/s]2429it [26:17,  1.55it/s]2430it [26:18,  1.55it/s]2431it [26:18,  1.55it/s]2432it [26:19,  1.56it/s]2433it [26:20,  1.55it/s]2434it [26:20,  1.55it/s]2435it [26:21,  1.55it/s]2436it [26:22,  1.55it/s]2437it [26:22,  1.55it/s]2438it [26:23,  1.56it/s]2439it [26:24,  1.55it/s]2440it [26:24,  1.55it/s]2441it [26:25,  1.55it/s]2442it [26:25,  1.55it/s]2443it [26:26,  1.55it/s]2444it [26:27,  1.55it/s]2445it [26:27,  1.55it/s]2446it [26:28,  1.54it/s]2447it [26:29,  1.54it/s]2448it [26:29,  1.54it/s]2449it [26:30,  1.54it/s]2450it [26:31,  1.54it/s]2451it [26:31,  1.55it/s]2452it [26:32,  1.55it/s]2453it [26:33,  1.55it/s]2454it [26:33,  1.55it/s]2455it [26:34,  1.56it/s]2456it [26:35,  1.55it/s]2457it [26:35,  1.55it/s]2458it [26:36,  1.55it/s]2459it [26:36,  1.55it/s]2460it [26:37,  1.56it/s]2461it [26:38,  1.56it/s]2462it [26:38,  1.56it/s]2463it [26:39,  1.55it/s]2464it [26:40,  1.55it/s]2465it [26:40,  1.55it/s]2466it [26:41,  1.55it/s]2467it [26:42,  1.56it/s]2468it [26:42,  1.56it/s]2469it [26:43,  1.55it/s]2470it [26:44,  1.55it/s]2471it [26:44,  1.56it/s]2472it [26:45,  1.55it/s]2473it [26:45,  1.55it/s]2474it [26:46,  1.55it/s]2475it [26:47,  1.55it/s]2476it [26:47,  1.55it/s]2477it [26:48,  1.55it/s]2478it [26:49,  1.55it/s]2479it [26:49,  1.55it/s]2480it [26:50,  1.55it/s]2481it [26:51,  1.55it/s]2482it [26:51,  1.54it/s]2483it [26:52,  1.54it/s]2484it [26:53,  1.54it/s]2485it [26:53,  1.55it/s]2486it [26:54,  1.55it/s]2487it [26:55,  1.55it/s]2488it [26:55,  1.55it/s]2489it [26:56,  1.55it/s]2490it [26:56,  1.55it/s]2491it [26:57,  1.55it/s]2492it [26:58,  1.55it/s]2493it [26:58,  1.56it/s]2494it [26:59,  1.56it/s]2495it [27:00,  1.56it/s]2496it [27:00,  1.56it/s]2497it [27:01,  1.56it/s]2498it [27:02,  1.56it/s]2499it [27:02,  1.56it/s]2500it [27:03,  1.28it/s]2501it [27:04,  1.36it/s]2502it [27:05,  1.41it/s]2503it [27:05,  1.45it/s]2504it [27:06,  1.48it/s]2505it [27:07,  1.50it/s]2506it [27:07,  1.52it/s]2507it [27:08,  1.54it/s]2508it [27:08,  1.54it/s]2509it [27:09,  1.55it/s]2510it [27:10,  1.55it/s]2511it [27:10,  1.55it/s]2512it [27:11,  1.55it/s]2513it [27:12,  1.55it/s]2514it [27:12,  1.55it/s]2515it [27:13,  1.55it/s]2516it [27:14,  1.55it/s]2517it [27:14,  1.55it/s]2518it [27:15,  1.55it/s]2519it [27:16,  1.55it/s]2520it [27:16,  1.55it/s]2521it [27:17,  1.55it/s]2522it [27:17,  1.55it/s]2523it [27:18,  1.55it/s]2524it [27:19,  1.55it/s]2525it [27:19,  1.56it/s]2526it [27:20,  1.56it/s]2527it [27:21,  1.56it/s]2528it [27:21,  1.56it/s]2529it [27:22,  1.56it/s]2530it [27:23,  1.56it/s]2531it [27:23,  1.56it/s]2532it [27:24,  1.56it/s]2533it [27:25,  1.56it/s]2534it [27:25,  1.55it/s]2535it [27:26,  1.55it/s]2536it [27:26,  1.56it/s]2537it [27:27,  1.56it/s]2538it [27:28,  1.55it/s]2539it [27:28,  1.56it/s]2540it [27:29,  1.56it/s]2541it [27:30,  1.56it/s]2542it [27:30,  1.55it/s]2543it [27:31,  1.55it/s]2544it [27:32,  1.55it/s]2545it [27:32,  1.55it/s]2546it [27:33,  1.55it/s]2547it [27:34,  1.55it/s]2548it [27:34,  1.55it/s]2549it [27:35,  1.55it/s]2550it [27:35,  1.55it/s]2551it [27:36,  1.55it/s]2552it [27:37,  1.55it/s]2553it [27:37,  1.55it/s]2554it [27:38,  1.55it/s]2555it [27:39,  1.55it/s]2556it [27:39,  1.55it/s]2557it [27:40,  1.55it/s]2558it [27:41,  1.55it/s]2559it [27:41,  1.55it/s]2560it [27:42,  1.55it/s]2561it [27:43,  1.55it/s]2562it [27:43,  1.55it/s]2563it [27:44,  1.55it/s]2564it [27:45,  1.55it/s]2565it [27:45,  1.55it/s]2566it [27:46,  1.55it/s]2567it [27:46,  1.55it/s]2568it [27:47,  1.55it/s]2569it [27:48,  1.55it/s]2570it [27:48,  1.55it/s]2571it [27:49,  1.56it/s]2572it [27:50,  1.56it/s]2573it [27:50,  1.56it/s]2574it [27:51,  1.56it/s]2575it [27:52,  1.56it/s]2576it [27:52,  1.56it/s]2577it [27:53,  1.56it/s]2578it [27:53,  1.56it/s]2579it [27:54,  1.56it/s]2580it [27:55,  1.56it/s]2581it [27:55,  1.56it/s]2582it [27:56,  1.56it/s]2583it [27:57,  1.55it/s]2584it [27:57,  1.56it/s]2585it [27:58,  1.55it/s]2586it [27:59,  1.56it/s]2587it [27:59,  1.56it/s]2588it [28:00,  1.55it/s]2589it [28:01,  1.55it/s]2590it [28:01,  1.55it/s]2591it [28:02,  1.55it/s]2592it [28:03,  1.55it/s]2593it [28:03,  1.55it/s]2594it [28:04,  1.54it/s]2595it [28:04,  1.55it/s]2596it [28:05,  1.55it/s]2597it [28:06,  1.55it/s]2598it [28:06,  1.56it/s]2599it [28:07,  1.55it/s]2600it [28:08,  1.29it/s]2601it [28:09,  1.36it/s]2602it [28:09,  1.41it/s]2603it [28:10,  1.45it/s]2604it [28:11,  1.48it/s]2605it [28:11,  1.50it/s]2606it [28:12,  1.51it/s]2607it [28:13,  1.52it/s]2608it [28:13,  1.53it/s]2609it [28:14,  1.53it/s]2610it [28:15,  1.53it/s]2611it [28:15,  1.53it/s]2612it [28:16,  1.53it/s]2613it [28:17,  1.54it/s]2614it [28:17,  1.54it/s]2615it [28:18,  1.54it/s]2616it [28:18,  1.54it/s]2617it [28:19,  1.54it/s]2618it [28:20,  1.55it/s]2619it [28:20,  1.55it/s]2620it [28:21,  1.54it/s]2621it [28:22,  1.54it/s]2622it [28:22,  1.54it/s]2623it [28:23,  1.54it/s]2624it [28:24,  1.54it/s]2625it [28:24,  1.54it/s]2626it [28:25,  1.54it/s]2627it [28:26,  1.54it/s]2628it [28:26,  1.55it/s]2629it [28:27,  1.55it/s]2630it [28:28,  1.55it/s]2631it [28:28,  1.54it/s]2632it [28:29,  1.54it/s]2633it [28:29,  1.54it/s]2634it [28:30,  1.54it/s]2635it [28:31,  1.54it/s]2636it [28:31,  1.54it/s]2637it [28:32,  1.55it/s]2638it [28:33,  1.55it/s]2639it [28:33,  1.55it/s]2640it [28:34,  1.55it/s]2641it [28:35,  1.55it/s]2642it [28:35,  1.55it/s]2643it [28:36,  1.55it/s]2644it [28:37,  1.55it/s]2645it [28:37,  1.55it/s]2646it [28:38,  1.55it/s]2647it [28:39,  1.54it/s]2648it [28:39,  1.54it/s]2649it [28:40,  1.54it/s]2650it [28:40,  1.54it/s]2651it [28:41,  1.54it/s]2652it [28:42,  1.54it/s]2653it [28:42,  1.54it/s]2654it [28:43,  1.54it/s]2655it [28:44,  1.54it/s]2656it [28:44,  1.54it/s]2657it [28:45,  1.53it/s]2658it [28:46,  1.54it/s]2659it [28:46,  1.54it/s]2660it [28:47,  1.54it/s]2661it [28:48,  1.54it/s]2662it [28:48,  1.54it/s]2663it [28:49,  1.54it/s]2664it [28:50,  1.54it/s]2665it [28:50,  1.54it/s]2666it [28:51,  1.54it/s]2667it [28:52,  1.54it/s]2668it [28:52,  1.54it/s]2669it [28:53,  1.54it/s]2670it [28:53,  1.53it/s]2671it [28:54,  1.53it/s]2672it [28:55,  1.53it/s]2673it [28:55,  1.54it/s]2674it [28:56,  1.54it/s]2675it [28:57,  1.54it/s]2676it [28:57,  1.54it/s]2677it [28:58,  1.53it/s]2678it [28:59,  1.54it/s]2679it [28:59,  1.54it/s]2680it [29:00,  1.54it/s]2681it [29:01,  1.54it/s]2682it [29:01,  1.54it/s]2683it [29:02,  1.54it/s]2684it [29:03,  1.54it/s]2685it [29:03,  1.54it/s]2686it [29:04,  1.54it/s]2687it [29:05,  1.54it/s]2688it [29:05,  1.54it/s]2689it [29:06,  1.54it/s]2690it [29:06,  1.54it/s]2691it [29:07,  1.54it/s]2692it [29:08,  1.54it/s]2693it [29:08,  1.54it/s]2694it [29:09,  1.54it/s]2695it [29:10,  1.55it/s]2696it [29:10,  1.55it/s]2697it [29:11,  1.55it/s]2698it [29:12,  1.56it/s]2699it [29:12,  1.55it/s]2700it [29:13,  1.29it/s]2701it [29:14,  1.36it/s]2702it [29:15,  1.41it/s]2703it [29:15,  1.45it/s]2704it [29:16,  1.48it/s]2705it [29:17,  1.50it/s]2706it [29:17,  1.51it/s]2707it [29:18,  1.52it/s]2708it [29:19,  1.53it/s]2709it [29:19,  1.53it/s]2710it [29:20,  1.53it/s]2711it [29:20,  1.54it/s]2712it [29:21,  1.54it/s]2713it [29:22,  1.54it/s]2714it [29:22,  1.54it/s]2715it [29:23,  1.54it/s]2716it [29:24,  1.54it/s]2717it [29:24,  1.55it/s]2718it [29:25,  1.55it/s]2719it [29:26,  1.54it/s]2720it [29:26,  1.55it/s]2721it [29:27,  1.54it/s]2722it [29:28,  1.54it/s]2723it [29:28,  1.54it/s]2724it [29:29,  1.55it/s]2725it [29:30,  1.55it/s]2726it [29:30,  1.54it/s]2727it [29:31,  1.55it/s]2728it [29:31,  1.55it/s]2729it [29:32,  1.55it/s]2730it [29:33,  1.55it/s]2731it [29:33,  1.55it/s]2732it [29:34,  1.55it/s]2733it [29:35,  1.55it/s]2734it [29:35,  1.55it/s]2735it [29:36,  1.54it/s]2736it [29:37,  1.55it/s]2737it [29:37,  1.55it/s]2738it [29:38,  1.55it/s]2739it [29:39,  1.55it/s]2740it [29:39,  1.54it/s]2741it [29:40,  1.55it/s]2742it [29:41,  1.55it/s]2743it [29:41,  1.55it/s]2744it [29:42,  1.55it/s]2745it [29:42,  1.55it/s]2746it [29:43,  1.55it/s]2747it [29:44,  1.55it/s]2748it [29:44,  1.55it/s]2749it [29:45,  1.54it/s]2750it [29:46,  1.54it/s]2751it [29:46,  1.54it/s]2752it [29:47,  1.54it/s]2753it [29:48,  1.54it/s]2754it [29:48,  1.54it/s]2755it [29:49,  1.55it/s]2756it [29:50,  1.55it/s]2757it [29:50,  1.55it/s]2758it [29:51,  1.54it/s]2759it [29:52,  1.55it/s]2760it [29:52,  1.54it/s]2761it [29:53,  1.55it/s]2762it [29:53,  1.54it/s]2763it [29:54,  1.54it/s]2764it [29:55,  1.54it/s]2765it [29:55,  1.55it/s]2766it [29:56,  1.54it/s]2767it [29:57,  1.55it/s]2768it [29:57,  1.55it/s]2769it [29:58,  1.55it/s]2770it [29:59,  1.55it/s]2771it [29:59,  1.56it/s]2772it [30:00,  1.56it/s]2773it [30:01,  1.55it/s]2774it [30:01,  1.55it/s]2775it [30:02,  1.55it/s]2776it [30:02,  1.55it/s]2777it [30:03,  1.55it/s]2778it [30:04,  1.56it/s]2779it [30:04,  1.56it/s]2780it [30:05,  1.56it/s]2781it [30:06,  1.56it/s]2782it [30:06,  1.56it/s]2783it [30:07,  1.55it/s]2784it [30:08,  1.55it/s]2785it [30:08,  1.55it/s]2786it [30:09,  1.55it/s]2787it [30:10,  1.55it/s]2788it [30:10,  1.55it/s]2789it [30:11,  1.55it/s]2790it [30:12,  1.55it/s]2791it [30:12,  1.54it/s]2792it [30:13,  1.54it/s]2793it [30:13,  1.54it/s]2794it [30:14,  1.54it/s]2795it [30:15,  1.54it/s]2796it [30:15,  1.55it/s]2797it [30:16,  1.54it/s]2798it [30:17,  1.54it/s]2799it [30:17,  1.54it/s]2800it [30:18,  1.30it/s]2801it [30:19,  1.37it/s]2802it [30:20,  1.42it/s]2803it [30:20,  1.46it/s]2804it [30:21,  1.49it/s]2805it [30:22,  1.51it/s]2806it [30:22,  1.52it/s]2807it [30:23,  1.53it/s]2808it [30:24,  1.54it/s]2809it [30:24,  1.55it/s]2810it [30:25,  1.55it/s]2811it [30:25,  1.56it/s]2812it [30:26,  1.55it/s]2813it [30:27,  1.55it/s]2814it [30:27,  1.55it/s]2815it [30:28,  1.55it/s]2816it [30:29,  1.55it/s]2817it [30:29,  1.55it/s]2818it [30:30,  1.55it/s]2819it [30:31,  1.55it/s]2820it [30:31,  1.55it/s]2821it [30:32,  1.55it/s]2822it [30:33,  1.56it/s]2823it [30:33,  1.56it/s]2824it [30:34,  1.56it/s]2825it [30:34,  1.56it/s]2826it [30:35,  1.56it/s]2827it [30:36,  1.56it/s]2828it [30:36,  1.56it/s]2829it [30:37,  1.55it/s]2830it [30:38,  1.55it/s]2831it [30:38,  1.55it/s]2832it [30:39,  1.55it/s]2833it [30:40,  1.55it/s]2834it [30:40,  1.55it/s]2835it [30:41,  1.55it/s]2836it [30:42,  1.55it/s]2837it [30:42,  1.55it/s]2838it [30:43,  1.55it/s]2839it [30:43,  1.55it/s]2840it [30:44,  1.55it/s]2841it [30:45,  1.55it/s]2842it [30:45,  1.55it/s]2843it [30:46,  1.55it/s]2844it [30:47,  1.56it/s]2845it [30:47,  1.55it/s]2846it [30:48,  1.56it/s]2847it [30:49,  1.56it/s]2848it [30:49,  1.56it/s]2849it [30:50,  1.56it/s]2850it [30:51,  1.56it/s]2851it [30:51,  1.55it/s]2852it [30:52,  1.55it/s]2853it [30:53,  1.55it/s]2854it [30:53,  1.55it/s]2855it [30:54,  1.55it/s]2856it [30:54,  1.55it/s]2857it [30:55,  1.55it/s]2858it [30:56,  1.56it/s]2859it [30:56,  1.56it/s]2860it [30:57,  1.56it/s]2861it [30:58,  1.56it/s]2862it [30:58,  1.55it/s]2863it [30:59,  1.55it/s]2864it [31:00,  1.56it/s]2865it [31:00,  1.56it/s]2866it [31:01,  1.56it/s]2867it [31:02,  1.56it/s]2868it [31:02,  1.56it/s]2869it [31:03,  1.56it/s]2870it [31:03,  1.57it/s]2871it [31:04,  1.56it/s]2872it [31:05,  1.56it/s]2873it [31:05,  1.56it/s]2874it [31:06,  1.56it/s]2875it [31:07,  1.56it/s]2876it [31:07,  1.56it/s]2877it [31:08,  1.55it/s]2878it [31:09,  1.55it/s]2879it [31:09,  1.55it/s]2880it [31:10,  1.55it/s]2881it [31:10,  1.56it/s]2882it [31:11,  1.55it/s]2883it [31:12,  1.55it/s]2884it [31:12,  1.55it/s]2885it [31:13,  1.55it/s]2886it [31:14,  1.55it/s]2887it [31:14,  1.55it/s]2888it [31:15,  1.55it/s]2889it [31:16,  1.55it/s]2890it [31:16,  1.55it/s]2891it [31:17,  1.55it/s]2892it [31:18,  1.55it/s]2893it [31:18,  1.55it/s]2894it [31:19,  1.55it/s]2895it [31:20,  1.54it/s]2896it [31:20,  1.55it/s]2897it [31:21,  1.55it/s]2898it [31:21,  1.55it/s]2899it [31:22,  1.55it/s]2900it [31:23,  1.30it/s]2901it [31:24,  1.37it/s]2902it [31:24,  1.42it/s]2903it [31:25,  1.45it/s]2904it [31:26,  1.48it/s]2905it [31:26,  1.50it/s]2906it [31:27,  1.52it/s]2907it [31:28,  1.53it/s]2908it [31:28,  1.53it/s]2909it [31:29,  1.53it/s]2910it [31:30,  1.54it/s]2911it [31:30,  1.49it/s]2912it [31:31,  1.50it/s]2913it [31:32,  1.51it/s]2914it [31:32,  1.52it/s]2915it [31:33,  1.53it/s]2916it [31:34,  1.53it/s]2917it [31:34,  1.53it/s]2918it [31:35,  1.53it/s]2919it [31:36,  1.54it/s]2920it [31:36,  1.55it/s]2921it [31:37,  1.55it/s]2922it [31:37,  1.55it/s]2923it [31:38,  1.55it/s]2924it [31:39,  1.55it/s]2925it [31:39,  1.55it/s]2926it [31:40,  1.55it/s]2927it [31:41,  1.55it/s]2928it [31:41,  1.55it/s]2929it [31:42,  1.55it/s]2930it [31:43,  1.55it/s]2931it [31:43,  1.55it/s]2932it [31:44,  1.54it/s]2933it [31:45,  1.54it/s]2934it [31:45,  1.55it/s]2935it [31:46,  1.55it/s]2936it [31:46,  1.55it/s]2937it [31:47,  1.55it/s]2938it [31:48,  1.55it/s]2939it [31:48,  1.55it/s]2940it [31:49,  1.55it/s]2941it [31:50,  1.55it/s]2942it [31:50,  1.54it/s]2943it [31:51,  1.55it/s]2944it [31:52,  1.55it/s]2945it [31:52,  1.54it/s]2946it [31:53,  1.54it/s]2947it [31:54,  1.54it/s]2948it [31:54,  1.54it/s]2949it [31:55,  1.54it/s]2950it [31:56,  1.54it/s]2951it [31:56,  1.54it/s]2952it [31:57,  1.54it/s]2953it [31:58,  1.55it/s]2954it [31:58,  1.54it/s]2955it [31:59,  1.54it/s]2956it [31:59,  1.55it/s]2957it [32:00,  1.55it/s]2958it [32:01,  1.55it/s]2959it [32:01,  1.55it/s]2960it [32:02,  1.56it/s]2961it [32:03,  1.56it/s]2962it [32:03,  1.56it/s]2963it [32:04,  1.55it/s]2964it [32:05,  1.56it/s]2965it [32:05,  1.55it/s]2966it [32:06,  1.56it/s]2967it [32:07,  1.56it/s]2968it [32:07,  1.55it/s]2969it [32:08,  1.55it/s]2970it [32:08,  1.56it/s]2971it [32:09,  1.56it/s]2972it [32:10,  1.56it/s]2973it [32:10,  1.56it/s]2974it [32:11,  1.56it/s]2975it [32:12,  1.56it/s]2976it [32:12,  1.56it/s]2977it [32:13,  1.55it/s]2978it [32:14,  1.55it/s]2979it [32:14,  1.56it/s]2980it [32:15,  1.56it/s]2981it [32:16,  1.56it/s]2982it [32:16,  1.56it/s]2983it [32:17,  1.56it/s]2984it [32:17,  1.56it/s]2985it [32:18,  1.55it/s]2986it [32:19,  1.55it/s]2987it [32:19,  1.55it/s]2988it [32:20,  1.55it/s]2989it [32:21,  1.55it/s]2990it [32:21,  1.55it/s]2991it [32:22,  1.56it/s]2992it [32:23,  1.56it/s]2993it [32:23,  1.57it/s]2994it [32:24,  1.56it/s]2995it [32:25,  1.56it/s]2996it [32:25,  1.55it/s]2997it [32:26,  1.55it/s]2998it [32:26,  1.55it/s]2999it [32:27,  1.55it/s]3000it [32:28,  1.33it/s]3001it [32:29,  1.40it/s]3002it [32:29,  1.44it/s]3003it [32:30,  1.48it/s]3004it [32:31,  1.50it/s]3005it [32:31,  1.51it/s]3006it [32:32,  1.53it/s]3007it [32:33,  1.53it/s]3008it [32:33,  1.54it/s]3009it [32:34,  1.54it/s]3010it [32:35,  1.54it/s]3011it [32:35,  1.55it/s]3012it [32:36,  1.55it/s]3013it [32:36,  1.55it/s]3014it [32:37,  1.55it/s]3015it [32:38,  1.55it/s]3016it [32:38,  1.56it/s]3017it [32:39,  1.56it/s]3018it [32:40,  1.56it/s]3019it [32:40,  1.56it/s]3020it [32:41,  1.57it/s]3021it [32:42,  1.56it/s]3022it [32:42,  1.56it/s]3023it [32:43,  1.55it/s]3024it [32:44,  1.55it/s]3025it [32:44,  1.55it/s]3026it [32:45,  1.55it/s]3027it [32:45,  1.55it/s]3028it [32:46,  1.55it/s]3029it [32:47,  1.55it/s]3030it [32:47,  1.56it/s]3031it [32:48,  1.56it/s]3032it [32:49,  1.56it/s]3033it [32:49,  1.56it/s]3034it [32:50,  1.56it/s]3035it [32:51,  1.56it/s]3036it [32:51,  1.55it/s]3037it [32:52,  1.55it/s]3038it [32:53,  1.56it/s]3039it [32:53,  1.56it/s]3040it [32:54,  1.56it/s]3041it [32:54,  1.56it/s]3042it [32:55,  1.56it/s]3043it [32:56,  1.56it/s]3044it [32:56,  1.56it/s]3045it [32:57,  1.56it/s]3046it [32:58,  1.56it/s]3047it [32:58,  1.57it/s]3048it [32:59,  1.57it/s]3049it [33:00,  1.56it/s]3050it [33:00,  1.56it/s]3051it [33:01,  1.56it/s]3052it [33:01,  1.56it/s]3053it [33:02,  1.56it/s]3054it [33:03,  1.56it/s]3055it [33:03,  1.56it/s]3056it [33:04,  1.56it/s]3057it [33:05,  1.57it/s]3058it [33:05,  1.56it/s]3059it [33:06,  1.56it/s]3060it [33:07,  1.56it/s]3061it [33:07,  1.56it/s]3062it [33:08,  1.56it/s]3063it [33:09,  1.56it/s]3064it [33:09,  1.56it/s]3065it [33:10,  1.55it/s]3066it [33:10,  1.55it/s]3067it [33:11,  1.55it/s]3068it [33:12,  1.55it/s]3069it [33:12,  1.55it/s]3070it [33:13,  1.55it/s]3071it [33:14,  1.56it/s]3072it [33:14,  1.56it/s]3073it [33:15,  1.55it/s]3074it [33:16,  1.55it/s]3075it [33:16,  1.55it/s]3076it [33:17,  1.55it/s]3077it [33:18,  1.55it/s]3078it [33:18,  1.55it/s]3079it [33:19,  1.56it/s]3080it [33:19,  1.56it/s]3081it [33:20,  1.55it/s]3082it [33:21,  1.55it/s]3083it [33:21,  1.56it/s]3084it [33:22,  1.55it/s]3085it [33:23,  1.55it/s]3086it [33:23,  1.55it/s]3087it [33:24,  1.55it/s]3088it [33:25,  1.55it/s]3089it [33:25,  1.55it/s]3090it [33:26,  1.55it/s]3091it [33:27,  1.55it/s]3092it [33:27,  1.55it/s]3093it [33:28,  1.55it/s]3094it [33:28,  1.55it/s]3095it [33:29,  1.55it/s]3096it [33:30,  1.56it/s]3097it [33:30,  1.56it/s]3098it [33:31,  1.56it/s]3099it [33:32,  1.56it/s]3100it [33:33,  1.31it/s]3101it [33:33,  1.38it/s]3102it [33:34,  1.43it/s]3103it [33:35,  1.46it/s]3104it [33:35,  1.49it/s]3105it [33:36,  1.50it/s]3106it [33:37,  1.51it/s]3107it [33:37,  1.52it/s]3108it [33:38,  1.53it/s]3109it [33:39,  1.53it/s]3110it [33:39,  1.54it/s]3111it [33:40,  1.54it/s]3112it [33:40,  1.54it/s]3113it [33:41,  1.54it/s]3114it [33:42,  1.54it/s]3115it [33:42,  1.54it/s]3116it [33:43,  1.54it/s]3117it [33:44,  1.54it/s]3118it [33:44,  1.54it/s]3119it [33:45,  1.54it/s]3120it [33:46,  1.54it/s]3121it [33:46,  1.55it/s]3122it [33:47,  1.55it/s]3123it [33:48,  1.55it/s]3124it [33:48,  1.55it/s]3125it [33:49,  1.55it/s]3126it [33:50,  1.56it/s]3127it [33:50,  1.56it/s]3128it [33:51,  1.56it/s]3129it [33:51,  1.56it/s]3130it [33:52,  1.55it/s]3131it [33:53,  1.55it/s]3132it [33:53,  1.54it/s]3133it [33:54,  1.54it/s]3134it [33:55,  1.54it/s]3135it [33:55,  1.54it/s]3136it [33:56,  1.54it/s]3137it [33:57,  1.54it/s]3138it [33:57,  1.54it/s]3139it [33:58,  1.54it/s]3140it [33:59,  1.55it/s]3141it [33:59,  1.54it/s]3142it [34:00,  1.55it/s]3143it [34:01,  1.55it/s]3144it [34:01,  1.55it/s]3145it [34:02,  1.55it/s]3146it [34:02,  1.54it/s]3147it [34:03,  1.54it/s]3148it [34:04,  1.54it/s]3149it [34:04,  1.54it/s]3150it [34:05,  1.54it/s]3151it [34:06,  1.54it/s]3152it [34:06,  1.54it/s]3153it [34:07,  1.55it/s]3154it [34:08,  1.54it/s]3155it [34:08,  1.54it/s]3156it [34:09,  1.54it/s]3157it [34:10,  1.55it/s]3158it [34:10,  1.55it/s]3159it [34:11,  1.55it/s]3160it [34:12,  1.56it/s]3161it [34:12,  1.56it/s]3162it [34:13,  1.56it/s]3163it [34:13,  1.55it/s]3164it [34:14,  1.55it/s]3165it [34:15,  1.55it/s]3166it [34:15,  1.56it/s]3167it [34:16,  1.55it/s]3168it [34:17,  1.55it/s]3169it [34:17,  1.55it/s]3170it [34:18,  1.55it/s]3171it [34:19,  1.56it/s]3172it [34:19,  1.55it/s]3173it [34:20,  1.55it/s]3174it [34:21,  1.55it/s]3175it [34:21,  1.55it/s]3176it [34:22,  1.55it/s]3177it [34:22,  1.54it/s]3178it [34:23,  1.54it/s]3179it [34:24,  1.54it/s]3180it [34:24,  1.54it/s]3181it [34:25,  1.54it/s]3182it [34:26,  1.54it/s]3183it [34:26,  1.54it/s]3184it [34:27,  1.54it/s]3185it [34:28,  1.54it/s]3186it [34:28,  1.55it/s]3187it [34:29,  1.54it/s]3188it [34:30,  1.55it/s]3189it [34:30,  1.55it/s]3190it [34:31,  1.54it/s]3191it [34:32,  1.54it/s]3192it [34:32,  1.54it/s]3193it [34:33,  1.54it/s]3194it [34:33,  1.55it/s]3195it [34:34,  1.55it/s]3196it [34:35,  1.55it/s]3197it [34:35,  1.55it/s]3198it [34:36,  1.55it/s]3199it [34:37,  1.56it/s]3200it [34:38,  1.31it/s]3201it [34:38,  1.38it/s]3202it [34:39,  1.43it/s]3203it [34:40,  1.46it/s]3204it [34:40,  1.49it/s]3205it [34:41,  1.51it/s]3206it [34:42,  1.53it/s]3207it [34:42,  1.53it/s]3208it [34:43,  1.54it/s]3209it [34:44,  1.55it/s]3210it [34:44,  1.55it/s]3211it [34:45,  1.55it/s]3212it [34:45,  1.56it/s]3213it [34:46,  1.56it/s]3214it [34:47,  1.56it/s]3215it [34:47,  1.56it/s]3216it [34:48,  1.55it/s]3217it [34:49,  1.55it/s]3218it [34:49,  1.55it/s]3219it [34:50,  1.55it/s]3220it [34:51,  1.55it/s]3221it [34:51,  1.55it/s]3222it [34:52,  1.55it/s]3223it [34:53,  1.56it/s]3224it [34:53,  1.56it/s]3225it [34:54,  1.56it/s]3226it [34:54,  1.55it/s]3227it [34:55,  1.55it/s]3228it [34:56,  1.55it/s]3229it [34:56,  1.55it/s]3230it [34:57,  1.55it/s]3231it [34:58,  1.56it/s]3232it [34:58,  1.56it/s]3233it [34:59,  1.56it/s]3234it [35:00,  1.56it/s]3235it [35:00,  1.56it/s]3236it [35:01,  1.56it/s]3237it [35:01,  1.57it/s]3238it [35:02,  1.56it/s]3239it [35:03,  1.56it/s]3240it [35:03,  1.55it/s]3241it [35:04,  1.55it/s]3242it [35:05,  1.55it/s]3243it [35:05,  1.55it/s]3244it [35:06,  1.55it/s]3245it [35:07,  1.55it/s]3246it [35:07,  1.55it/s]3247it [35:08,  1.55it/s]3248it [35:09,  1.55it/s]3249it [35:09,  1.55it/s]3250it [35:10,  1.56it/s]3251it [35:11,  1.56it/s]3252it [35:11,  1.56it/s]3253it [35:12,  1.56it/s]3254it [35:12,  1.56it/s]3255it [35:13,  1.56it/s]3256it [35:14,  1.56it/s]3257it [35:14,  1.56it/s]3258it [35:15,  1.55it/s]3259it [35:16,  1.55it/s]3260it [35:16,  1.55it/s]3261it [35:17,  1.55it/s]3262it [35:18,  1.55it/s]3263it [35:18,  1.55it/s]3264it [35:19,  1.55it/s]3265it [35:20,  1.55it/s]3266it [35:20,  1.55it/s]3267it [35:21,  1.55it/s]3268it [35:21,  1.56it/s]3269it [35:22,  1.56it/s]3270it [35:23,  1.56it/s]3271it [35:23,  1.56it/s]3272it [35:24,  1.57it/s]3273it [35:25,  1.57it/s]3274it [35:25,  1.56it/s]3275it [35:26,  1.56it/s]3276it [35:27,  1.55it/s]3277it [35:27,  1.55it/s]3278it [35:28,  1.55it/s]3279it [35:29,  1.55it/s]3280it [35:29,  1.55it/s]3281it [35:30,  1.55it/s]3282it [35:30,  1.55it/s]3283it [35:31,  1.55it/s]3284it [35:32,  1.54it/s]3285it [35:32,  1.54it/s]3286it [35:33,  1.55it/s]3287it [35:34,  1.55it/s]3288it [35:34,  1.55it/s]3289it [35:35,  1.56it/s]3290it [35:36,  1.56it/s]3291it [35:36,  1.56it/s]3292it [35:37,  1.56it/s]3293it [35:38,  1.56it/s]3294it [35:38,  1.56it/s]3295it [35:39,  1.56it/s]3296it [35:39,  1.56it/s]3297it [35:40,  1.56it/s]3298it [35:41,  1.56it/s]3299it [35:41,  1.56it/s]3300it [35:42,  1.31it/s]3301it [35:43,  1.37it/s]3302it [35:44,  1.43it/s]3303it [35:44,  1.46it/s]3304it [35:45,  1.49it/s]3305it [35:46,  1.51it/s]3306it [35:46,  1.52it/s]3307it [35:47,  1.53it/s]3308it [35:48,  1.55it/s]3309it [35:48,  1.55it/s]3310it [35:49,  1.56it/s]3311it [35:49,  1.56it/s]3312it [35:50,  1.56it/s]3313it [35:51,  1.56it/s]3314it [35:51,  1.56it/s]3315it [35:52,  1.55it/s]3316it [35:53,  1.55it/s]3317it [35:53,  1.55it/s]3318it [35:54,  1.55it/s]3319it [35:55,  1.55it/s]3320it [35:55,  1.55it/s]3321it [35:56,  1.55it/s]3322it [35:57,  1.55it/s]3323it [35:57,  1.55it/s]3324it [35:58,  1.55it/s]3325it [35:59,  1.55it/s]3326it [35:59,  1.55it/s]3327it [36:00,  1.55it/s]3328it [36:00,  1.56it/s]3329it [36:01,  1.56it/s]3330it [36:02,  1.56it/s]3331it [36:02,  1.56it/s]3332it [36:03,  1.56it/s]3333it [36:04,  1.56it/s]3334it [36:04,  1.56it/s]3335it [36:05,  1.56it/s]3336it [36:06,  1.56it/s]3337it [36:06,  1.56it/s]3338it [36:07,  1.56it/s]3339it [36:07,  1.56it/s]3340it [36:08,  1.56it/s]3341it [36:09,  1.55it/s]3342it [36:09,  1.56it/s]3343it [36:10,  1.56it/s]3344it [36:11,  1.56it/s]3345it [36:11,  1.55it/s]3346it [36:12,  1.56it/s]3347it [36:13,  1.56it/s]3348it [36:13,  1.56it/s]3349it [36:14,  1.56it/s]3350it [36:15,  1.56it/s]3351it [36:15,  1.56it/s]3352it [36:16,  1.56it/s]3353it [36:16,  1.56it/s]3354it [36:17,  1.56it/s]3355it [36:18,  1.56it/s]3356it [36:18,  1.55it/s]3357it [36:19,  1.55it/s]3358it [36:20,  1.55it/s]3359it [36:20,  1.55it/s]3360it [36:21,  1.55it/s]3361it [36:22,  1.55it/s]3362it [36:22,  1.55it/s]3363it [36:23,  1.55it/s]3364it [36:24,  1.56it/s]3365it [36:24,  1.56it/s]3366it [36:25,  1.56it/s]3367it [36:25,  1.57it/s]3368it [36:26,  1.57it/s]3369it [36:27,  1.56it/s]3370it [36:27,  1.56it/s]3371it [36:28,  1.56it/s]3372it [36:29,  1.56it/s]3373it [36:29,  1.55it/s]3374it [36:30,  1.55it/s]3375it [36:31,  1.55it/s]3376it [36:31,  1.55it/s]3377it [36:32,  1.56it/s]3378it [36:33,  1.56it/s]3379it [36:33,  1.55it/s]3380it [36:34,  1.55it/s]3381it [36:34,  1.55it/s]3382it [36:35,  1.55it/s]3383it [36:36,  1.55it/s]3384it [36:36,  1.55it/s]3385it [36:37,  1.55it/s]3386it [36:38,  1.55it/s]3387it [36:38,  1.55it/s]3388it [36:39,  1.55it/s]3389it [36:40,  1.55it/s]3390it [36:40,  1.55it/s]3391it [36:41,  1.55it/s]3392it [36:42,  1.55it/s]3393it [36:42,  1.55it/s]3394it [36:43,  1.55it/s]3395it [36:44,  1.55it/s]3396it [36:44,  1.55it/s]3397it [36:45,  1.55it/s]3398it [36:45,  1.55it/s]3399it [36:46,  1.55it/s]3400it [36:47,  1.28it/s]3401it [36:48,  1.35it/s]3402it [36:48,  1.41it/s]3403it [36:49,  1.44it/s]3404it [36:50,  1.47it/s]3405it [36:50,  1.49it/s]3406it [36:51,  1.51it/s]3407it [36:52,  1.52it/s]3408it [36:52,  1.53it/s]3409it [36:53,  1.53it/s]3410it [36:54,  1.54it/s]3411it [36:54,  1.54it/s]3412it [36:55,  1.54it/s]3413it [36:56,  1.54it/s]3414it [36:56,  1.54it/s]3415it [36:57,  1.55it/s]3416it [36:58,  1.54it/s]3417it [36:58,  1.54it/s]3418it [36:59,  1.54it/s]3419it [36:59,  1.54it/s]3420it [37:00,  1.54it/s]3421it [37:01,  1.54it/s]3422it [37:01,  1.55it/s]3423it [37:02,  1.55it/s]3424it [37:03,  1.55it/s]3425it [37:03,  1.55it/s]3426it [37:04,  1.54it/s]3427it [37:05,  1.54it/s]3428it [37:05,  1.55it/s]3429it [37:06,  1.55it/s]3430it [37:07,  1.55it/s]3431it [37:07,  1.55it/s]3432it [37:08,  1.55it/s]3433it [37:09,  1.55it/s]3434it [37:09,  1.55it/s]3435it [37:10,  1.55it/s]3436it [37:10,  1.55it/s]3437it [37:11,  1.55it/s]3438it [37:12,  1.55it/s]3439it [37:12,  1.55it/s]3440it [37:13,  1.53it/s]3441it [37:14,  1.54it/s]3442it [37:14,  1.54it/s]3443it [37:15,  1.54it/s]3444it [37:16,  1.54it/s]3445it [37:16,  1.54it/s]3446it [37:17,  1.54it/s]3447it [37:18,  1.54it/s]3448it [37:18,  1.54it/s]3449it [37:19,  1.54it/s]3450it [37:20,  1.55it/s]3451it [37:20,  1.55it/s]3452it [37:21,  1.54it/s]3453it [37:21,  1.55it/s]3454it [37:22,  1.55it/s]3455it [37:23,  1.55it/s]3456it [37:23,  1.55it/s]3457it [37:24,  1.55it/s]3458it [37:25,  1.55it/s]3459it [37:25,  1.55it/s]3460it [37:26,  1.55it/s]3461it [37:27,  1.55it/s]3462it [37:27,  1.54it/s]3463it [37:28,  1.55it/s]3464it [37:29,  1.54it/s]3465it [37:29,  1.55it/s]3466it [37:30,  1.55it/s]3467it [37:31,  1.54it/s]3468it [37:31,  1.54it/s]3469it [37:32,  1.54it/s]3470it [37:33,  1.54it/s]3471it [37:33,  1.54it/s]3472it [37:34,  1.55it/s]3473it [37:34,  1.55it/s]3474it [37:35,  1.55it/s]3475it [37:36,  1.55it/s]3476it [37:36,  1.55it/s]3477it [37:37,  1.55it/s]3478it [37:38,  1.55it/s]3479it [37:38,  1.55it/s]3480it [37:39,  1.55it/s]3481it [37:40,  1.55it/s]3482it [37:40,  1.55it/s]3483it [37:41,  1.55it/s]3484it [37:42,  1.55it/s]3485it [37:42,  1.55it/s]3486it [37:43,  1.55it/s]3487it [37:43,  1.54it/s]3488it [37:44,  1.54it/s]3489it [37:45,  1.54it/s]3490it [37:45,  1.54it/s]3491it [37:46,  1.54it/s]3492it [37:47,  1.54it/s]3493it [37:47,  1.55it/s]3494it [37:48,  1.55it/s]3495it [37:49,  1.55it/s]3496it [37:49,  1.55it/s]3497it [37:50,  1.54it/s]3498it [37:51,  1.54it/s]3499it [37:51,  1.54it/s]3500it [37:52,  1.29it/s]3501it [37:53,  1.36it/s]3502it [37:54,  1.41it/s]3503it [37:54,  1.45it/s]3504it [37:55,  1.48it/s]3505it [37:56,  1.50it/s]3506it [37:56,  1.51it/s]3507it [37:57,  1.52it/s]3508it [37:57,  1.53it/s]3509it [37:58,  1.54it/s]3510it [37:59,  1.55it/s]3511it [37:59,  1.56it/s]3512it [38:00,  1.56it/s]3513it [38:01,  1.56it/s]3514it [38:01,  1.57it/s]3515it [38:02,  1.57it/s]3516it [38:03,  1.57it/s]3517it [38:03,  1.56it/s]3518it [38:04,  1.56it/s]3519it [38:05,  1.56it/s]3520it [38:05,  1.56it/s]3521it [38:06,  1.56it/s]3522it [38:06,  1.56it/s]3523it [38:07,  1.56it/s]3524it [38:08,  1.56it/s]3525it [38:08,  1.56it/s]3526it [38:09,  1.56it/s]3527it [38:10,  1.56it/s]3528it [38:10,  1.55it/s]3529it [38:11,  1.55it/s]3530it [38:12,  1.55it/s]3531it [38:12,  1.55it/s]3532it [38:13,  1.55it/s]3533it [38:14,  1.54it/s]3534it [38:14,  1.54it/s]3535it [38:15,  1.55it/s]3536it [38:15,  1.55it/s]3537it [38:16,  1.55it/s]3538it [38:17,  1.55it/s]3539it [38:17,  1.55it/s]3540it [38:18,  1.55it/s]3541it [38:19,  1.55it/s]3542it [38:19,  1.55it/s]3543it [38:20,  1.55it/s]3544it [38:21,  1.55it/s]3545it [38:21,  1.55it/s]3546it [38:22,  1.55it/s]3547it [38:23,  1.55it/s]3548it [38:23,  1.55it/s]3549it [38:24,  1.55it/s]3550it [38:25,  1.55it/s]3551it [38:25,  1.55it/s]3552it [38:26,  1.56it/s]3553it [38:26,  1.56it/s]3554it [38:27,  1.56it/s]3555it [38:28,  1.57it/s]3556it [38:28,  1.56it/s]3557it [38:29,  1.56it/s]3558it [38:30,  1.55it/s]3559it [38:30,  1.56it/s]3560it [38:31,  1.54it/s]3561it [38:32,  1.55it/s]3562it [38:32,  1.55it/s]3563it [38:33,  1.55it/s]3564it [38:34,  1.55it/s]3565it [38:34,  1.55it/s]3566it [38:35,  1.55it/s]3567it [38:35,  1.56it/s]3568it [38:36,  1.57it/s]3569it [38:37,  1.57it/s]3570it [38:37,  1.56it/s]3571it [38:38,  1.56it/s]3572it [38:39,  1.56it/s]3573it [38:39,  1.56it/s]3574it [38:40,  1.56it/s]3575it [38:41,  1.55it/s]3576it [38:41,  1.55it/s]3577it [38:42,  1.55it/s]3578it [38:42,  1.55it/s]3579it [38:43,  1.56it/s]3580it [38:44,  1.56it/s]3581it [38:44,  1.56it/s]3582it [38:45,  1.56it/s]3583it [38:46,  1.56it/s]3584it [38:46,  1.56it/s]3585it [38:47,  1.55it/s]3586it [38:48,  1.55it/s]3587it [38:48,  1.55it/s]3588it [38:49,  1.55it/s]3589it [38:50,  1.55it/s]3590it [38:50,  1.55it/s]3591it [38:51,  1.55it/s]3592it [38:51,  1.55it/s]3593it [38:52,  1.53it/s]3594it [38:53,  1.53it/s]3595it [38:53,  1.54it/s]3596it [38:54,  1.54it/s]3597it [38:55,  1.55it/s]3598it [38:55,  1.56it/s]3599it [38:56,  1.56it/s]3600it [38:57,  1.32it/s]3600it [38:57,  1.54it/s]
step: 000100 	 epe: 19.073
Save checkpoint at step: 100
step: 000200 	 epe: 38.101
Save checkpoint at step: 200
step: 000300 	 epe: 7.755
Save checkpoint at step: 300
step: 000400 	 epe: 7.502
Save checkpoint at step: 400
step: 000500 	 epe: 8.375
Save checkpoint at step: 500
step: 000600 	 epe: 20.010
Save checkpoint at step: 600
step: 000700 	 epe: 13.446
Save checkpoint at step: 700
step: 000800 	 epe: 11.436
Save checkpoint at step: 800
step: 000900 	 epe: 7.165
Save checkpoint at step: 900
step: 001000 	 epe: 7.432
Save checkpoint at step: 1000
step: 001100 	 epe: 23.833
Save checkpoint at step: 1100
step: 001200 	 epe: 16.694
Save checkpoint at step: 1200
step: 001300 	 epe: 11.536
Save checkpoint at step: 1300
step: 001400 	 epe: 9.126
Save checkpoint at step: 1400
step: 001500 	 epe: 10.558
Save checkpoint at step: 1500
step: 001600 	 epe: 8.499
Save checkpoint at step: 1600
step: 001700 	 epe: 9.458
Save checkpoint at step: 1700
step: 001800 	 epe: 7.965
Save checkpoint at step: 1800
step: 001900 	 epe: 4.733
Save checkpoint at step: 1900
step: 002000 	 epe: 6.925
Save checkpoint at step: 2000
step: 002100 	 epe: 6.451
Save checkpoint at step: 2100
step: 002200 	 epe: 6.762
Save checkpoint at step: 2200
step: 002300 	 epe: 6.331
Save checkpoint at step: 2300
step: 002400 	 epe: 4.992
Save checkpoint at step: 2400
step: 002500 	 epe: 17.659
Save checkpoint at step: 2500
step: 002600 	 epe: 6.210
Save checkpoint at step: 2600
step: 002700 	 epe: 14.385
Save checkpoint at step: 2700
step: 002800 	 epe: 12.059
Save checkpoint at step: 2800
step: 002900 	 epe: 10.509
Save checkpoint at step: 2900
step: 003000 	 epe: 21.403
Save checkpoint at step: 3000
step: 003100 	 epe: 4.501
Save checkpoint at step: 3100
step: 003200 	 epe: 9.971
Save checkpoint at step: 3200
step: 003300 	 epe: 9.126
Save checkpoint at step: 3300
step: 003400 	 epe: 6.728
Save checkpoint at step: 3400
step: 003500 	 epe: 9.181
Save checkpoint at step: 3500
step: 003600 	 epe: 13.952
Save checkpoint at step: 3600
  0%|          | 0/100000 [00:00<?, ?it/s]  0%|          | 0/100000 [00:00<?, ?it/s]
0it [00:00, ?it/s]1it [00:00,  1.25it/s]2it [00:01,  1.41it/s]3it [00:02,  1.47it/s]4it [00:02,  1.51it/s]5it [00:03,  1.52it/s]6it [00:04,  1.53it/s]7it [00:04,  1.54it/s]8it [00:05,  1.55it/s]9it [00:05,  1.55it/s]10it [00:06,  1.55it/s]11it [00:07,  1.55it/s]12it [00:07,  1.55it/s]13it [00:08,  1.55it/s]14it [00:09,  1.55it/s]15it [00:09,  1.55it/s]16it [00:10,  1.55it/s]17it [00:11,  1.55it/s]18it [00:11,  1.55it/s]19it [00:12,  1.56it/s]20it [00:13,  1.56it/s]21it [00:13,  1.55it/s]22it [00:14,  1.55it/s]23it [00:14,  1.56it/s]24it [00:15,  1.56it/s]25it [00:16,  1.56it/s]26it [00:16,  1.55it/s]27it [00:17,  1.56it/s]28it [00:18,  1.55it/s]29it [00:18,  1.55it/s]30it [00:19,  1.54it/s]31it [00:20,  1.54it/s]32it [00:20,  1.54it/s]33it [00:21,  1.55it/s]34it [00:22,  1.55it/s]35it [00:22,  1.54it/s]36it [00:23,  1.55it/s]37it [00:24,  1.55it/s]38it [00:24,  1.55it/s]39it [00:25,  1.55it/s]40it [00:25,  1.55it/s]41it [00:26,  1.55it/s]42it [00:27,  1.55it/s]43it [00:27,  1.55it/s]44it [00:28,  1.54it/s]45it [00:29,  1.54it/s]46it [00:29,  1.54it/s]47it [00:30,  1.54it/s]48it [00:31,  1.55it/s]49it [00:31,  1.55it/s]50it [00:32,  1.55it/s]51it [00:33,  1.55it/s]52it [00:33,  1.56it/s]53it [00:34,  1.56it/s]54it [00:34,  1.56it/s]55it [00:35,  1.56it/s]56it [00:36,  1.56it/s]57it [00:36,  1.55it/s]58it [00:37,  1.55it/s]59it [00:38,  1.55it/s]60it [00:38,  1.55it/s]61it [00:39,  1.55it/s]62it [00:40,  1.55it/s]63it [00:40,  1.56it/s]64it [00:41,  1.56it/s]65it [00:42,  1.56it/s]66it [00:42,  1.56it/s]67it [00:43,  1.56it/s]68it [00:43,  1.57it/s]69it [00:44,  1.56it/s]70it [00:45,  1.56it/s]71it [00:45,  1.56it/s]72it [00:46,  1.56it/s]73it [00:47,  1.55it/s]74it [00:47,  1.55it/s]75it [00:48,  1.55it/s]76it [00:49,  1.55it/s]77it [00:49,  1.55it/s]78it [00:50,  1.56it/s]79it [00:51,  1.56it/s]80it [00:51,  1.55it/s]81it [00:52,  1.55it/s]82it [00:52,  1.55it/s]83it [00:53,  1.55it/s]84it [00:54,  1.56it/s]85it [00:54,  1.56it/s]86it [00:55,  1.56it/s]87it [00:56,  1.56it/s]88it [00:56,  1.55it/s]89it [00:57,  1.55it/s]90it [00:58,  1.55it/s]91it [00:58,  1.55it/s]92it [00:59,  1.55it/s]93it [01:00,  1.55it/s]94it [01:00,  1.55it/s]95it [01:01,  1.55it/s]96it [01:01,  1.55it/s]97it [01:02,  1.56it/s]98it [01:03,  1.56it/s]99it [01:03,  1.56it/s]100it [01:04,  1.31it/s]101it [01:05,  1.38it/s]102it [01:06,  1.42it/s]103it [01:06,  1.46it/s]104it [01:07,  1.48it/s]105it [01:08,  1.50it/s]106it [01:08,  1.51it/s]107it [01:09,  1.53it/s]108it [01:10,  1.54it/s]109it [01:10,  1.55it/s]110it [01:11,  1.54it/s]111it [01:12,  1.55it/s]112it [01:12,  1.55it/s]113it [01:13,  1.55it/s]114it [01:13,  1.54it/s]115it [01:14,  1.55it/s]116it [01:15,  1.54it/s]117it [01:15,  1.55it/s]118it [01:16,  1.55it/s]119it [01:17,  1.55it/s]120it [01:17,  1.55it/s]121it [01:18,  1.55it/s]122it [01:19,  1.55it/s]123it [01:19,  1.55it/s]124it [01:20,  1.55it/s]125it [01:21,  1.56it/s]126it [01:21,  1.55it/s]127it [01:22,  1.55it/s]128it [01:23,  1.54it/s]129it [01:23,  1.54it/s]130it [01:24,  1.54it/s]131it [01:24,  1.54it/s]132it [01:25,  1.54it/s]133it [01:26,  1.54it/s]134it [01:26,  1.54it/s]135it [01:27,  1.54it/s]136it [01:28,  1.54it/s]137it [01:28,  1.54it/s]138it [01:29,  1.54it/s]139it [01:30,  1.54it/s]140it [01:30,  1.54it/s]141it [01:31,  1.54it/s]142it [01:32,  1.54it/s]143it [01:32,  1.54it/s]144it [01:33,  1.55it/s]145it [01:34,  1.55it/s]146it [01:34,  1.55it/s]147it [01:35,  1.55it/s]148it [01:35,  1.55it/s]149it [01:36,  1.55it/s]150it [01:37,  1.55it/s]151it [01:37,  1.55it/s]152it [01:38,  1.55it/s]153it [01:39,  1.55it/s]154it [01:39,  1.55it/s]155it [01:40,  1.55it/s]156it [01:41,  1.55it/s]157it [01:41,  1.55it/s]158it [01:42,  1.55it/s]159it [01:43,  1.55it/s]160it [01:43,  1.54it/s]161it [01:44,  1.54it/s]162it [01:45,  1.54it/s]163it [01:45,  1.54it/s]164it [01:46,  1.54it/s]165it [01:46,  1.54it/s]166it [01:47,  1.55it/s]167it [01:48,  1.55it/s]168it [01:48,  1.55it/s]169it [01:49,  1.54it/s]170it [01:50,  1.54it/s]171it [01:50,  1.54it/s]172it [01:51,  1.54it/s]173it [01:52,  1.54it/s]174it [01:52,  1.54it/s]175it [01:53,  1.54it/s]176it [01:54,  1.54it/s]177it [01:54,  1.54it/s]178it [01:55,  1.55it/s]179it [01:56,  1.55it/s]180it [01:56,  1.55it/s]181it [01:57,  1.55it/s]182it [01:57,  1.55it/s]183it [01:58,  1.55it/s]184it [01:59,  1.54it/s]185it [01:59,  1.55it/s]186it [02:00,  1.55it/s]187it [02:01,  1.55it/s]188it [02:01,  1.56it/s]189it [02:02,  1.55it/s]190it [02:03,  1.55it/s]191it [02:03,  1.55it/s]192it [02:04,  1.55it/s]193it [02:05,  1.55it/s]194it [02:05,  1.54it/s]195it [02:06,  1.54it/s]196it [02:07,  1.54it/s]197it [02:07,  1.54it/s]198it [02:08,  1.54it/s]199it [02:08,  1.54it/s]200it [02:10,  1.29it/s]201it [02:10,  1.36it/s]202it [02:11,  1.42it/s]203it [02:11,  1.45it/s]204it [02:12,  1.47it/s]205it [02:13,  1.49it/s]206it [02:13,  1.51it/s]207it [02:14,  1.52it/s]208it [02:15,  1.52it/s]209it [02:15,  1.53it/s]210it [02:16,  1.53it/s]211it [02:17,  1.53it/s]212it [02:17,  1.54it/s]213it [02:18,  1.54it/s]214it [02:19,  1.55it/s]215it [02:19,  1.55it/s]216it [02:20,  1.55it/s]217it [02:21,  1.55it/s]218it [02:21,  1.55it/s]219it [02:22,  1.55it/s]220it [02:23,  1.55it/s]221it [02:23,  1.55it/s]222it [02:24,  1.55it/s]223it [02:24,  1.55it/s]224it [02:25,  1.55it/s]225it [02:26,  1.55it/s]226it [02:26,  1.55it/s]227it [02:27,  1.55it/s]228it [02:28,  1.56it/s]229it [02:28,  1.55it/s]230it [02:29,  1.55it/s]231it [02:30,  1.55it/s]232it [02:30,  1.54it/s]233it [02:31,  1.55it/s]234it [02:32,  1.55it/s]235it [02:32,  1.55it/s]236it [02:33,  1.55it/s]237it [02:33,  1.55it/s]238it [02:34,  1.55it/s]239it [02:35,  1.54it/s]240it [02:35,  1.54it/s]241it [02:36,  1.54it/s]242it [02:37,  1.54it/s]243it [02:37,  1.54it/s]244it [02:38,  1.54it/s]245it [02:39,  1.54it/s]246it [02:39,  1.54it/s]247it [02:40,  1.54it/s]248it [02:41,  1.55it/s]249it [02:41,  1.55it/s]250it [02:42,  1.55it/s]251it [02:43,  1.55it/s]252it [02:43,  1.55it/s]253it [02:44,  1.54it/s]254it [02:44,  1.55it/s]255it [02:45,  1.55it/s]256it [02:46,  1.55it/s]257it [02:46,  1.55it/s]258it [02:47,  1.55it/s]259it [02:48,  1.55it/s]260it [02:48,  1.55it/s]261it [02:49,  1.55it/s]262it [02:50,  1.55it/s]263it [02:50,  1.55it/s]264it [02:51,  1.55it/s]265it [02:52,  1.55it/s]266it [02:52,  1.54it/s]267it [02:53,  1.54it/s]268it [02:54,  1.54it/s]269it [02:54,  1.55it/s]270it [02:55,  1.55it/s]271it [02:55,  1.55it/s]272it [02:56,  1.55it/s]273it [02:57,  1.55it/s]274it [02:57,  1.55it/s]275it [02:58,  1.55it/s]276it [02:59,  1.54it/s]277it [02:59,  1.54it/s]278it [03:00,  1.54it/s]279it [03:01,  1.54it/s]280it [03:01,  1.54it/s]281it [03:02,  1.54it/s]282it [03:03,  1.54it/s]283it [03:03,  1.54it/s]284it [03:04,  1.54it/s]285it [03:05,  1.54it/s]286it [03:05,  1.54it/s]287it [03:06,  1.54it/s]288it [03:06,  1.54it/s]289it [03:07,  1.54it/s]290it [03:08,  1.55it/s]291it [03:08,  1.55it/s]292it [03:09,  1.55it/s]293it [03:10,  1.55it/s]294it [03:10,  1.55it/s]295it [03:11,  1.55it/s]296it [03:12,  1.55it/s]297it [03:12,  1.55it/s]298it [03:13,  1.55it/s]299it [03:14,  1.55it/s]300it [03:15,  1.30it/s]301it [03:15,  1.37it/s]302it [03:16,  1.42it/s]303it [03:17,  1.45it/s]304it [03:17,  1.48it/s]305it [03:18,  1.50it/s]306it [03:19,  1.52it/s]307it [03:19,  1.53it/s]308it [03:20,  1.53it/s]309it [03:20,  1.54it/s]310it [03:21,  1.55it/s]311it [03:22,  1.55it/s]312it [03:22,  1.56it/s]313it [03:23,  1.56it/s]314it [03:24,  1.55it/s]315it [03:24,  1.55it/s]316it [03:25,  1.55it/s]317it [03:26,  1.55it/s]318it [03:26,  1.55it/s]319it [03:27,  1.55it/s]320it [03:28,  1.55it/s]321it [03:28,  1.54it/s]322it [03:29,  1.55it/s]323it [03:29,  1.55it/s]324it [03:30,  1.55it/s]325it [03:31,  1.55it/s]326it [03:31,  1.56it/s]327it [03:32,  1.56it/s]328it [03:33,  1.56it/s]329it [03:33,  1.56it/s]330it [03:34,  1.56it/s]331it [03:35,  1.56it/s]332it [03:35,  1.55it/s]333it [03:36,  1.55it/s]334it [03:37,  1.55it/s]335it [03:37,  1.55it/s]336it [03:38,  1.55it/s]337it [03:38,  1.56it/s]338it [03:39,  1.55it/s]339it [03:40,  1.55it/s]340it [03:40,  1.55it/s]341it [03:41,  1.55it/s]342it [03:42,  1.55it/s]343it [03:42,  1.55it/s]344it [03:43,  1.55it/s]345it [03:44,  1.55it/s]346it [03:44,  1.56it/s]347it [03:45,  1.56it/s]348it [03:46,  1.56it/s]349it [03:46,  1.56it/s]350it [03:47,  1.55it/s]351it [03:47,  1.55it/s]352it [03:48,  1.55it/s]353it [03:49,  1.55it/s]354it [03:49,  1.55it/s]355it [03:50,  1.55it/s]356it [03:51,  1.55it/s]357it [03:51,  1.55it/s]358it [03:52,  1.55it/s]359it [03:53,  1.55it/s]360it [03:53,  1.56it/s]361it [03:54,  1.55it/s]362it [03:55,  1.55it/s]363it [03:55,  1.54it/s]364it [03:56,  1.54it/s]365it [03:57,  1.54it/s]366it [03:57,  1.55it/s]367it [03:58,  1.55it/s]368it [03:58,  1.55it/s]369it [03:59,  1.55it/s]370it [04:00,  1.55it/s]371it [04:00,  1.55it/s]372it [04:01,  1.55it/s]373it [04:02,  1.55it/s]374it [04:02,  1.54it/s]375it [04:03,  1.54it/s]376it [04:04,  1.55it/s]377it [04:04,  1.55it/s]378it [04:05,  1.56it/s]379it [04:06,  1.56it/s]380it [04:06,  1.56it/s]381it [04:07,  1.56it/s]382it [04:07,  1.55it/s]383it [04:08,  1.55it/s]384it [04:09,  1.55it/s]385it [04:09,  1.55it/s]386it [04:10,  1.55it/s]387it [04:11,  1.55it/s]388it [04:11,  1.55it/s]389it [04:12,  1.55it/s]390it [04:13,  1.55it/s]391it [04:13,  1.55it/s]392it [04:14,  1.55it/s]393it [04:15,  1.55it/s]394it [04:15,  1.56it/s]395it [04:16,  1.56it/s]396it [04:16,  1.56it/s]397it [04:17,  1.56it/s]398it [04:18,  1.56it/s]399it [04:18,  1.56it/s]400it [04:19,  1.30it/s]401it [04:20,  1.37it/s]402it [04:21,  1.41it/s]403it [04:21,  1.45it/s]404it [04:22,  1.48it/s]405it [04:23,  1.51it/s]406it [04:23,  1.52it/s]407it [04:24,  1.53it/s]408it [04:25,  1.54it/s]409it [04:25,  1.54it/s]410it [04:26,  1.55it/s]411it [04:27,  1.55it/s]412it [04:27,  1.55it/s]413it [04:28,  1.55it/s]414it [04:28,  1.55it/s]415it [04:29,  1.55it/s]416it [04:30,  1.56it/s]417it [04:30,  1.56it/s]418it [04:31,  1.56it/s]419it [04:32,  1.56it/s]420it [04:32,  1.56it/s]421it [04:33,  1.56it/s]422it [04:34,  1.56it/s]423it [04:34,  1.56it/s]424it [04:35,  1.56it/s]425it [04:36,  1.55it/s]426it [04:36,  1.55it/s]427it [04:37,  1.55it/s]428it [04:37,  1.56it/s]429it [04:38,  1.55it/s]430it [04:39,  1.56it/s]431it [04:39,  1.56it/s]432it [04:40,  1.56it/s]433it [04:41,  1.56it/s]434it [04:41,  1.56it/s]435it [04:42,  1.55it/s]436it [04:43,  1.55it/s]437it [04:43,  1.55it/s]438it [04:44,  1.55it/s]439it [04:45,  1.55it/s]440it [04:45,  1.56it/s]441it [04:46,  1.56it/s]442it [04:46,  1.56it/s]443it [04:47,  1.56it/s]444it [04:48,  1.56it/s]445it [04:48,  1.56it/s]446it [04:49,  1.56it/s]447it [04:50,  1.56it/s]448it [04:50,  1.56it/s]449it [04:51,  1.56it/s]450it [04:52,  1.56it/s]451it [04:52,  1.57it/s]452it [04:53,  1.56it/s]453it [04:54,  1.56it/s]454it [04:54,  1.56it/s]455it [04:55,  1.56it/s]456it [04:55,  1.56it/s]457it [04:56,  1.56it/s]458it [04:57,  1.57it/s]459it [04:57,  1.57it/s]460it [04:58,  1.57it/s]461it [04:59,  1.56it/s]462it [04:59,  1.55it/s]463it [05:00,  1.55it/s]464it [05:01,  1.55it/s]465it [05:01,  1.55it/s]466it [05:02,  1.55it/s]467it [05:03,  1.55it/s]468it [05:03,  1.56it/s]469it [05:04,  1.56it/s]470it [05:04,  1.56it/s]471it [05:05,  1.56it/s]472it [05:06,  1.57it/s]473it [05:06,  1.56it/s]474it [05:07,  1.56it/s]475it [05:08,  1.56it/s]476it [05:08,  1.56it/s]477it [05:09,  1.56it/s]478it [05:10,  1.56it/s]479it [05:10,  1.56it/s]480it [05:11,  1.56it/s]481it [05:11,  1.57it/s]482it [05:12,  1.57it/s]483it [05:13,  1.57it/s]484it [05:13,  1.57it/s]485it [05:14,  1.57it/s]486it [05:15,  1.56it/s]487it [05:15,  1.57it/s]488it [05:16,  1.56it/s]489it [05:17,  1.56it/s]490it [05:17,  1.56it/s]491it [05:18,  1.56it/s]492it [05:19,  1.56it/s]493it [05:19,  1.56it/s]494it [05:20,  1.56it/s]495it [05:20,  1.56it/s]496it [05:21,  1.56it/s]497it [05:22,  1.56it/s]498it [05:22,  1.56it/s]499it [05:23,  1.56it/s]500it [05:24,  1.30it/s]501it [05:25,  1.37it/s]502it [05:25,  1.41it/s]503it [05:26,  1.44it/s]504it [05:27,  1.47it/s]505it [05:27,  1.50it/s]506it [05:28,  1.51it/s]507it [05:29,  1.52it/s]508it [05:29,  1.53it/s]509it [05:30,  1.54it/s]510it [05:31,  1.54it/s]511it [05:31,  1.54it/s]512it [05:32,  1.54it/s]513it [05:33,  1.54it/s]514it [05:33,  1.54it/s]515it [05:34,  1.54it/s]516it [05:34,  1.55it/s]517it [05:35,  1.55it/s]518it [05:36,  1.55it/s]519it [05:36,  1.55it/s]520it [05:37,  1.56it/s]521it [05:38,  1.55it/s]522it [05:38,  1.55it/s]523it [05:39,  1.55it/s]524it [05:40,  1.55it/s]525it [05:40,  1.55it/s]526it [05:41,  1.55it/s]527it [05:42,  1.55it/s]528it [05:42,  1.55it/s]529it [05:43,  1.54it/s]530it [05:43,  1.55it/s]531it [05:44,  1.55it/s]532it [05:45,  1.55it/s]533it [05:45,  1.55it/s]534it [05:46,  1.56it/s]535it [05:47,  1.55it/s]536it [05:47,  1.55it/s]537it [05:48,  1.56it/s]538it [05:49,  1.55it/s]539it [05:49,  1.56it/s]540it [05:50,  1.55it/s]541it [05:51,  1.55it/s]542it [05:51,  1.55it/s]543it [05:52,  1.56it/s]544it [05:52,  1.56it/s]545it [05:53,  1.55it/s]546it [05:54,  1.55it/s]547it [05:54,  1.55it/s]548it [05:55,  1.55it/s]549it [05:56,  1.55it/s]550it [05:56,  1.55it/s]551it [05:57,  1.55it/s]552it [05:58,  1.55it/s]553it [05:58,  1.55it/s]554it [05:59,  1.56it/s]555it [06:00,  1.55it/s]556it [06:00,  1.55it/s]557it [06:01,  1.55it/s]558it [06:02,  1.55it/s]559it [06:02,  1.55it/s]560it [06:03,  1.55it/s]561it [06:03,  1.55it/s]562it [06:04,  1.55it/s]563it [06:05,  1.55it/s]564it [06:05,  1.55it/s]565it [06:06,  1.54it/s]566it [06:07,  1.55it/s]567it [06:07,  1.55it/s]568it [06:08,  1.54it/s]569it [06:09,  1.55it/s]570it [06:09,  1.55it/s]571it [06:10,  1.55it/s]572it [06:11,  1.55it/s]573it [06:11,  1.55it/s]574it [06:12,  1.55it/s]575it [06:12,  1.55it/s]576it [06:13,  1.55it/s]577it [06:14,  1.55it/s]578it [06:14,  1.55it/s]579it [06:15,  1.56it/s]580it [06:16,  1.55it/s]581it [06:16,  1.56it/s]582it [06:17,  1.55it/s]583it [06:18,  1.55it/s]584it [06:18,  1.54it/s]585it [06:19,  1.54it/s]586it [06:20,  1.54it/s]587it [06:20,  1.55it/s]588it [06:21,  1.55it/s]589it [06:22,  1.55it/s]590it [06:22,  1.54it/s]591it [06:23,  1.54it/s]592it [06:23,  1.54it/s]593it [06:24,  1.54it/s]594it [06:25,  1.54it/s]595it [06:25,  1.54it/s]596it [06:26,  1.54it/s]597it [06:27,  1.55it/s]598it [06:27,  1.54it/s]599it [06:28,  1.55it/s]600it [06:29,  1.32it/s]601it [06:30,  1.38it/s]602it [06:30,  1.43it/s]603it [06:31,  1.47it/s]604it [06:32,  1.49it/s]605it [06:32,  1.51it/s]606it [06:33,  1.53it/s]607it [06:34,  1.53it/s]608it [06:34,  1.54it/s]609it [06:35,  1.54it/s]610it [06:35,  1.54it/s]611it [06:36,  1.54it/s]612it [06:37,  1.54it/s]613it [06:37,  1.55it/s]614it [06:38,  1.54it/s]615it [06:39,  1.55it/s]616it [06:39,  1.55it/s]617it [06:40,  1.55it/s]618it [06:41,  1.55it/s]619it [06:41,  1.55it/s]620it [06:42,  1.55it/s]621it [06:43,  1.54it/s]622it [06:43,  1.54it/s]623it [06:44,  1.55it/s]624it [06:45,  1.55it/s]625it [06:45,  1.55it/s]626it [06:46,  1.55it/s]627it [06:46,  1.55it/s]628it [06:47,  1.55it/s]629it [06:48,  1.55it/s]630it [06:48,  1.55it/s]631it [06:49,  1.55it/s]632it [06:50,  1.55it/s]633it [06:50,  1.55it/s]634it [06:51,  1.54it/s]635it [06:52,  1.54it/s]636it [06:52,  1.55it/s]637it [06:53,  1.55it/s]638it [06:54,  1.55it/s]639it [06:54,  1.55it/s]640it [06:55,  1.55it/s]641it [06:56,  1.55it/s]642it [06:56,  1.55it/s]643it [06:57,  1.54it/s]644it [06:57,  1.54it/s]645it [06:58,  1.55it/s]646it [06:59,  1.55it/s]647it [06:59,  1.55it/s]648it [07:00,  1.55it/s]649it [07:01,  1.55it/s]650it [07:01,  1.55it/s]651it [07:02,  1.55it/s]652it [07:03,  1.55it/s]653it [07:03,  1.56it/s]654it [07:04,  1.56it/s]655it [07:05,  1.56it/s]656it [07:05,  1.55it/s]657it [07:06,  1.55it/s]658it [07:06,  1.55it/s]659it [07:07,  1.55it/s]660it [07:08,  1.55it/s]661it [07:08,  1.55it/s]662it [07:09,  1.55it/s]663it [07:10,  1.55it/s]664it [07:10,  1.55it/s]665it [07:11,  1.55it/s]666it [07:12,  1.55it/s]667it [07:12,  1.55it/s]668it [07:13,  1.55it/s]669it [07:14,  1.54it/s]670it [07:14,  1.54it/s]671it [07:15,  1.55it/s]672it [07:16,  1.55it/s]673it [07:16,  1.55it/s]674it [07:17,  1.55it/s]675it [07:17,  1.55it/s]676it [07:18,  1.56it/s]677it [07:19,  1.55it/s]678it [07:19,  1.56it/s]679it [07:20,  1.55it/s]680it [07:21,  1.55it/s]681it [07:21,  1.55it/s]682it [07:22,  1.55it/s]683it [07:23,  1.55it/s]684it [07:23,  1.55it/s]685it [07:24,  1.55it/s]686it [07:25,  1.55it/s]687it [07:25,  1.55it/s]688it [07:26,  1.55it/s]689it [07:26,  1.55it/s]690it [07:27,  1.55it/s]691it [07:28,  1.55it/s]692it [07:28,  1.54it/s]693it [07:29,  1.55it/s]694it [07:30,  1.55it/s]695it [07:30,  1.55it/s]696it [07:31,  1.55it/s]697it [07:32,  1.55it/s]698it [07:32,  1.54it/s]699it [07:33,  1.54it/s]700it [07:34,  1.30it/s]701it [07:35,  1.37it/s]702it [07:35,  1.42it/s]703it [07:36,  1.45it/s]704it [07:37,  1.48it/s]705it [07:37,  1.51it/s]706it [07:38,  1.52it/s]707it [07:38,  1.53it/s]708it [07:39,  1.54it/s]709it [07:40,  1.54it/s]710it [07:40,  1.54it/s]711it [07:41,  1.54it/s]712it [07:42,  1.54it/s]713it [07:42,  1.54it/s]714it [07:43,  1.54it/s]715it [07:44,  1.54it/s]716it [07:44,  1.54it/s]717it [07:45,  1.54it/s]718it [07:46,  1.54it/s]719it [07:46,  1.54it/s]720it [07:47,  1.54it/s]721it [07:48,  1.54it/s]722it [07:48,  1.54it/s]723it [07:49,  1.55it/s]724it [07:50,  1.55it/s]725it [07:50,  1.55it/s]726it [07:51,  1.54it/s]727it [07:51,  1.54it/s]728it [07:52,  1.54it/s]729it [07:53,  1.54it/s]730it [07:53,  1.54it/s]731it [07:54,  1.54it/s]732it [07:55,  1.54it/s]733it [07:55,  1.54it/s]734it [07:56,  1.54it/s]735it [07:57,  1.54it/s]736it [07:57,  1.54it/s]737it [07:58,  1.54it/s]738it [07:59,  1.54it/s]739it [07:59,  1.54it/s]740it [08:00,  1.54it/s]741it [08:01,  1.54it/s]742it [08:01,  1.55it/s]743it [08:02,  1.55it/s]744it [08:02,  1.55it/s]745it [08:03,  1.55it/s]746it [08:04,  1.56it/s]747it [08:04,  1.57it/s]748it [08:05,  1.57it/s]749it [08:06,  1.56it/s]750it [08:06,  1.56it/s]751it [08:07,  1.55it/s]752it [08:08,  1.55it/s]753it [08:08,  1.54it/s]754it [08:09,  1.54it/s]755it [08:10,  1.54it/s]756it [08:10,  1.55it/s]757it [08:11,  1.55it/s]758it [08:11,  1.55it/s]759it [08:12,  1.54it/s]760it [08:13,  1.55it/s]761it [08:13,  1.55it/s]762it [08:14,  1.55it/s]763it [08:15,  1.56it/s]764it [08:15,  1.56it/s]765it [08:16,  1.56it/s]766it [08:17,  1.56it/s]767it [08:17,  1.56it/s]768it [08:18,  1.55it/s]769it [08:19,  1.55it/s]770it [08:19,  1.56it/s]771it [08:20,  1.56it/s]772it [08:20,  1.56it/s]773it [08:21,  1.55it/s]774it [08:22,  1.55it/s]775it [08:22,  1.55it/s]776it [08:23,  1.55it/s]777it [08:24,  1.56it/s]778it [08:24,  1.56it/s]779it [08:25,  1.55it/s]780it [08:26,  1.55it/s]781it [08:26,  1.55it/s]782it [08:27,  1.55it/s]783it [08:28,  1.55it/s]784it [08:28,  1.55it/s]785it [08:29,  1.55it/s]786it [08:30,  1.55it/s]787it [08:30,  1.55it/s]788it [08:31,  1.55it/s]789it [08:31,  1.54it/s]790it [08:32,  1.54it/s]791it [08:33,  1.54it/s]792it [08:33,  1.54it/s]793it [08:34,  1.55it/s]794it [08:35,  1.55it/s]795it [08:35,  1.55it/s]796it [08:36,  1.56it/s]797it [08:37,  1.56it/s]798it [08:37,  1.56it/s]799it [08:38,  1.55it/s]800it [08:39,  1.29it/s]801it [08:40,  1.36it/s]802it [08:40,  1.40it/s]803it [08:41,  1.44it/s]804it [08:42,  1.47it/s]805it [08:42,  1.49it/s]806it [08:43,  1.51it/s]807it [08:44,  1.52it/s]808it [08:44,  1.53it/s]809it [08:45,  1.53it/s]810it [08:45,  1.54it/s]811it [08:46,  1.54it/s]812it [08:47,  1.54it/s]813it [08:47,  1.55it/s]814it [08:48,  1.55it/s]815it [08:49,  1.53it/s]816it [08:49,  1.53it/s]817it [08:50,  1.54it/s]818it [08:51,  1.54it/s]819it [08:51,  1.54it/s]820it [08:52,  1.54it/s]821it [08:53,  1.54it/s]822it [08:53,  1.54it/s]823it [08:54,  1.54it/s]824it [08:55,  1.55it/s]825it [08:55,  1.55it/s]826it [08:56,  1.55it/s]827it [08:56,  1.55it/s]828it [08:57,  1.55it/s]829it [08:58,  1.55it/s]830it [08:58,  1.55it/s]831it [08:59,  1.55it/s]832it [09:00,  1.55it/s]833it [09:00,  1.55it/s]834it [09:01,  1.55it/s]835it [09:02,  1.55it/s]836it [09:02,  1.55it/s]837it [09:03,  1.54it/s]838it [09:04,  1.54it/s]839it [09:04,  1.54it/s]840it [09:05,  1.54it/s]841it [09:06,  1.54it/s]842it [09:06,  1.55it/s]843it [09:07,  1.56it/s]844it [09:07,  1.56it/s]845it [09:08,  1.56it/s]846it [09:09,  1.55it/s]847it [09:09,  1.55it/s]848it [09:10,  1.55it/s]849it [09:11,  1.55it/s]850it [09:11,  1.55it/s]851it [09:12,  1.54it/s]852it [09:13,  1.54it/s]853it [09:13,  1.55it/s]854it [09:14,  1.55it/s]855it [09:15,  1.55it/s]856it [09:15,  1.54it/s]857it [09:16,  1.55it/s]858it [09:17,  1.55it/s]859it [09:17,  1.55it/s]860it [09:18,  1.55it/s]861it [09:18,  1.55it/s]862it [09:19,  1.55it/s]863it [09:20,  1.55it/s]864it [09:20,  1.55it/s]865it [09:21,  1.54it/s]866it [09:22,  1.55it/s]867it [09:22,  1.55it/s]868it [09:23,  1.55it/s]869it [09:24,  1.55it/s]870it [09:24,  1.55it/s]871it [09:25,  1.55it/s]872it [09:26,  1.55it/s]873it [09:26,  1.55it/s]874it [09:27,  1.54it/s]875it [09:27,  1.55it/s]876it [09:28,  1.55it/s]877it [09:29,  1.54it/s]878it [09:29,  1.55it/s]879it [09:30,  1.55it/s]880it [09:31,  1.55it/s]881it [09:31,  1.55it/s]882it [09:32,  1.55it/s]883it [09:33,  1.55it/s]884it [09:33,  1.55it/s]885it [09:34,  1.55it/s]886it [09:35,  1.55it/s]887it [09:35,  1.55it/s]888it [09:36,  1.55it/s]889it [09:36,  1.55it/s]890it [09:37,  1.55it/s]891it [09:38,  1.55it/s]892it [09:38,  1.55it/s]893it [09:39,  1.54it/s]894it [09:40,  1.54it/s]895it [09:40,  1.55it/s]896it [09:41,  1.54it/s]897it [09:42,  1.54it/s]898it [09:42,  1.54it/s]899it [09:43,  1.54it/s]900it [09:44,  1.29it/s]901it [09:45,  1.36it/s]902it [09:45,  1.41it/s]903it [09:46,  1.45it/s]904it [09:47,  1.48it/s]905it [09:47,  1.50it/s]906it [09:48,  1.51it/s]907it [09:49,  1.52it/s]908it [09:49,  1.53it/s]909it [09:50,  1.53it/s]910it [09:51,  1.54it/s]911it [09:51,  1.54it/s]912it [09:52,  1.55it/s]913it [09:52,  1.55it/s]914it [09:53,  1.55it/s]915it [09:54,  1.55it/s]916it [09:54,  1.55it/s]917it [09:55,  1.55it/s]918it [09:56,  1.55it/s]919it [09:56,  1.55it/s]920it [09:57,  1.55it/s]921it [09:58,  1.55it/s]922it [09:58,  1.56it/s]923it [09:59,  1.56it/s]924it [10:00,  1.55it/s]925it [10:00,  1.55it/s]926it [10:01,  1.55it/s]927it [10:01,  1.55it/s]928it [10:02,  1.55it/s]929it [10:03,  1.55it/s]930it [10:03,  1.55it/s]931it [10:04,  1.55it/s]932it [10:05,  1.55it/s]933it [10:05,  1.55it/s]934it [10:06,  1.55it/s]935it [10:07,  1.55it/s]936it [10:07,  1.55it/s]937it [10:08,  1.55it/s]938it [10:09,  1.55it/s]939it [10:09,  1.54it/s]940it [10:10,  1.54it/s]941it [10:11,  1.54it/s]942it [10:11,  1.55it/s]943it [10:12,  1.55it/s]944it [10:12,  1.55it/s]945it [10:13,  1.55it/s]946it [10:14,  1.55it/s]947it [10:14,  1.55it/s]948it [10:15,  1.55it/s]949it [10:16,  1.55it/s]950it [10:16,  1.55it/s]951it [10:17,  1.55it/s]952it [10:18,  1.55it/s]953it [10:18,  1.55it/s]954it [10:19,  1.55it/s]955it [10:20,  1.55it/s]956it [10:20,  1.55it/s]957it [10:21,  1.56it/s]958it [10:21,  1.56it/s]959it [10:22,  1.55it/s]960it [10:23,  1.55it/s]961it [10:23,  1.55it/s]962it [10:24,  1.55it/s]963it [10:25,  1.54it/s]964it [10:25,  1.55it/s]965it [10:26,  1.56it/s]966it [10:27,  1.56it/s]967it [10:27,  1.55it/s]968it [10:28,  1.55it/s]969it [10:29,  1.55it/s]970it [10:29,  1.54it/s]971it [10:30,  1.54it/s]972it [10:31,  1.55it/s]973it [10:31,  1.55it/s]974it [10:32,  1.54it/s]975it [10:32,  1.54it/s]976it [10:33,  1.54it/s]977it [10:34,  1.55it/s]978it [10:34,  1.55it/s]979it [10:35,  1.55it/s]980it [10:36,  1.55it/s]981it [10:36,  1.55it/s]982it [10:37,  1.55it/s]983it [10:38,  1.55it/s]984it [10:38,  1.55it/s]985it [10:39,  1.55it/s]986it [10:40,  1.55it/s]987it [10:40,  1.56it/s]988it [10:41,  1.56it/s]989it [10:41,  1.56it/s]990it [10:42,  1.55it/s]991it [10:43,  1.55it/s]992it [10:43,  1.55it/s]993it [10:44,  1.55it/s]994it [10:45,  1.55it/s]995it [10:45,  1.55it/s]996it [10:46,  1.55it/s]997it [10:47,  1.55it/s]998it [10:47,  1.55it/s]999it [10:48,  1.54it/s]1000it [10:49,  1.28it/s]1001it [10:50,  1.35it/s]1002it [10:50,  1.40it/s]1003it [10:51,  1.45it/s]1004it [10:52,  1.47it/s]1005it [10:52,  1.50it/s]1006it [10:53,  1.52it/s]1007it [10:54,  1.53it/s]1008it [10:54,  1.54it/s]1009it [10:55,  1.54it/s]1010it [10:55,  1.54it/s]1011it [10:56,  1.54it/s]1012it [10:57,  1.54it/s]1013it [10:57,  1.54it/s]1014it [10:58,  1.54it/s]1015it [10:59,  1.54it/s]1016it [10:59,  1.55it/s]1017it [11:00,  1.55it/s]1018it [11:01,  1.55it/s]1019it [11:01,  1.56it/s]1020it [11:02,  1.56it/s]1021it [11:03,  1.55it/s]1022it [11:03,  1.55it/s]1023it [11:04,  1.56it/s]1024it [11:04,  1.55it/s]1025it [11:05,  1.55it/s]1026it [11:06,  1.55it/s]1027it [11:06,  1.55it/s]1028it [11:07,  1.55it/s]1029it [11:08,  1.55it/s]1030it [11:08,  1.55it/s]1031it [11:09,  1.55it/s]1032it [11:10,  1.55it/s]1033it [11:10,  1.55it/s]1034it [11:11,  1.55it/s]1035it [11:12,  1.55it/s]1036it [11:12,  1.55it/s]1037it [11:13,  1.55it/s]1038it [11:14,  1.55it/s]1039it [11:14,  1.55it/s]1040it [11:15,  1.55it/s]1041it [11:15,  1.55it/s]1042it [11:16,  1.55it/s]1043it [11:17,  1.55it/s]1044it [11:17,  1.56it/s]1045it [11:18,  1.56it/s]1046it [11:19,  1.55it/s]1047it [11:19,  1.55it/s]1048it [11:20,  1.55it/s]1049it [11:21,  1.55it/s]1050it [11:21,  1.54it/s]1051it [11:22,  1.55it/s]1052it [11:23,  1.55it/s]1053it [11:23,  1.55it/s]1054it [11:24,  1.55it/s]1055it [11:25,  1.55it/s]1056it [11:25,  1.55it/s]1057it [11:26,  1.55it/s]1058it [11:26,  1.55it/s]1059it [11:27,  1.55it/s]1060it [11:28,  1.54it/s]1061it [11:28,  1.55it/s]1062it [11:29,  1.55it/s]1063it [11:30,  1.55it/s]1064it [11:30,  1.55it/s]1065it [11:31,  1.55it/s]1066it [11:32,  1.55it/s]1067it [11:32,  1.55it/s]1068it [11:33,  1.54it/s]1069it [11:34,  1.55it/s]1070it [11:34,  1.54it/s]1071it [11:35,  1.54it/s]1072it [11:35,  1.54it/s]1073it [11:36,  1.54it/s]1074it [11:37,  1.54it/s]1075it [11:37,  1.55it/s]1076it [11:38,  1.55it/s]1077it [11:39,  1.55it/s]1078it [11:39,  1.55it/s]1079it [11:40,  1.55it/s]1080it [11:41,  1.55it/s]1081it [11:41,  1.55it/s]1082it [11:42,  1.55it/s]1083it [11:43,  1.55it/s]1084it [11:43,  1.55it/s]1085it [11:44,  1.56it/s]1086it [11:45,  1.55it/s]1087it [11:45,  1.55it/s]1088it [11:46,  1.55it/s]1089it [11:46,  1.55it/s]1090it [11:47,  1.55it/s]1091it [11:48,  1.55it/s]1092it [11:48,  1.55it/s]1093it [11:49,  1.55it/s]1094it [11:50,  1.55it/s]1095it [11:50,  1.55it/s]1096it [11:51,  1.55it/s]1097it [11:52,  1.55it/s]1098it [11:52,  1.55it/s]1099it [11:53,  1.55it/s]1100it [11:54,  1.31it/s]1101it [11:55,  1.37it/s]1102it [11:55,  1.42it/s]1103it [11:56,  1.45it/s]1104it [11:57,  1.48it/s]1105it [11:57,  1.50it/s]1106it [11:58,  1.52it/s]1107it [11:58,  1.53it/s]1108it [11:59,  1.54it/s]1109it [12:00,  1.54it/s]1110it [12:00,  1.54it/s]1111it [12:01,  1.54it/s]1112it [12:02,  1.55it/s]1113it [12:02,  1.55it/s]1114it [12:03,  1.55it/s]1115it [12:04,  1.55it/s]1116it [12:04,  1.54it/s]1117it [12:05,  1.54it/s]1118it [12:06,  1.54it/s]1119it [12:06,  1.54it/s]1120it [12:07,  1.54it/s]1121it [12:08,  1.55it/s]1122it [12:08,  1.55it/s]1123it [12:09,  1.55it/s]1124it [12:09,  1.55it/s]1125it [12:10,  1.55it/s]1126it [12:11,  1.55it/s]1127it [12:11,  1.55it/s]1128it [12:12,  1.55it/s]1129it [12:13,  1.55it/s]1130it [12:13,  1.55it/s]1131it [12:14,  1.55it/s]1132it [12:15,  1.55it/s]1133it [12:15,  1.55it/s]1134it [12:16,  1.55it/s]1135it [12:17,  1.55it/s]1136it [12:17,  1.54it/s]1137it [12:18,  1.54it/s]1138it [12:19,  1.51it/s]1139it [12:19,  1.52it/s]1140it [12:20,  1.52it/s]1141it [12:21,  1.53it/s]1142it [12:21,  1.53it/s]1143it [12:22,  1.53it/s]1144it [12:22,  1.53it/s]1145it [12:23,  1.53it/s]1146it [12:24,  1.53it/s]1147it [12:24,  1.53it/s]1148it [12:25,  1.53it/s]1149it [12:26,  1.54it/s]1150it [12:26,  1.54it/s]1151it [12:27,  1.54it/s]1152it [12:28,  1.54it/s]1153it [12:28,  1.55it/s]1154it [12:29,  1.55it/s]1155it [12:30,  1.55it/s]1156it [12:30,  1.55it/s]1157it [12:31,  1.55it/s]1158it [12:32,  1.55it/s]1159it [12:32,  1.55it/s]1160it [12:33,  1.54it/s]1161it [12:33,  1.54it/s]1162it [12:34,  1.55it/s]1163it [12:35,  1.55it/s]1164it [12:35,  1.55it/s]1165it [12:36,  1.55it/s]1166it [12:37,  1.55it/s]1167it [12:37,  1.55it/s]1168it [12:38,  1.55it/s]1169it [12:39,  1.55it/s]1170it [12:39,  1.55it/s]1171it [12:40,  1.55it/s]1172it [12:41,  1.55it/s]1173it [12:41,  1.54it/s]1174it [12:42,  1.55it/s]1175it [12:43,  1.52it/s]1176it [12:43,  1.53it/s]1177it [12:44,  1.54it/s]1178it [12:44,  1.54it/s]1179it [12:45,  1.54it/s]1180it [12:46,  1.54it/s]1181it [12:46,  1.54it/s]1182it [12:47,  1.54it/s]1183it [12:48,  1.54it/s]1184it [12:48,  1.54it/s]1185it [12:49,  1.54it/s]1186it [12:50,  1.55it/s]1187it [12:50,  1.55it/s]1188it [12:51,  1.55it/s]1189it [12:52,  1.55it/s]1190it [12:52,  1.56it/s]1191it [12:53,  1.55it/s]1192it [12:54,  1.55it/s]1193it [12:54,  1.55it/s]1194it [12:55,  1.55it/s]1195it [12:55,  1.54it/s]1196it [12:56,  1.54it/s]1197it [12:57,  1.55it/s]1198it [12:57,  1.55it/s]1199it [12:58,  1.55it/s]1200it [12:59,  1.28it/s]1201it [13:00,  1.35it/s]1202it [13:00,  1.40it/s]1203it [13:01,  1.44it/s]1204it [13:02,  1.47it/s]1205it [13:02,  1.50it/s]1206it [13:03,  1.52it/s]1207it [13:04,  1.53it/s]1208it [13:04,  1.54it/s]1209it [13:05,  1.54it/s]1210it [13:06,  1.55it/s]1211it [13:06,  1.55it/s]1212it [13:07,  1.55it/s]1213it [13:08,  1.55it/s]1214it [13:08,  1.55it/s]1215it [13:09,  1.55it/s]1216it [13:09,  1.55it/s]1217it [13:10,  1.55it/s]1218it [13:11,  1.55it/s]1219it [13:11,  1.55it/s]1220it [13:12,  1.55it/s]1221it [13:13,  1.56it/s]1222it [13:13,  1.56it/s]1223it [13:14,  1.56it/s]1224it [13:15,  1.55it/s]1225it [13:15,  1.55it/s]1226it [13:16,  1.55it/s]1227it [13:17,  1.55it/s]1228it [13:17,  1.55it/s]1229it [13:18,  1.55it/s]1230it [13:18,  1.55it/s]1231it [13:19,  1.55it/s]1232it [13:20,  1.55it/s]1233it [13:20,  1.55it/s]1234it [13:21,  1.55it/s]1235it [13:22,  1.55it/s]1236it [13:22,  1.55it/s]1237it [13:23,  1.55it/s]1238it [13:24,  1.55it/s]1239it [13:24,  1.55it/s]1240it [13:25,  1.56it/s]1241it [13:26,  1.55it/s]1242it [13:26,  1.55it/s]1243it [13:27,  1.55it/s]1244it [13:27,  1.56it/s]1245it [13:28,  1.55it/s]1246it [13:29,  1.55it/s]1247it [13:29,  1.55it/s]1248it [13:30,  1.53it/s]1249it [13:31,  1.54it/s]1250it [13:31,  1.54it/s]1251it [13:32,  1.55it/s]1252it [13:33,  1.55it/s]1253it [13:33,  1.55it/s]1254it [13:34,  1.55it/s]1255it [13:35,  1.54it/s]1256it [13:35,  1.54it/s]1257it [13:36,  1.55it/s]1258it [13:37,  1.55it/s]1259it [13:37,  1.56it/s]1260it [13:38,  1.56it/s]1261it [13:38,  1.56it/s]1262it [13:39,  1.56it/s]1263it [13:40,  1.55it/s]1264it [13:40,  1.56it/s]1265it [13:41,  1.55it/s]1266it [13:42,  1.55it/s]1267it [13:42,  1.55it/s]1268it [13:43,  1.55it/s]1269it [13:44,  1.55it/s]1270it [13:44,  1.55it/s]1271it [13:45,  1.55it/s]1272it [13:46,  1.55it/s]1273it [13:46,  1.55it/s]1274it [13:47,  1.54it/s]1275it [13:47,  1.55it/s]1276it [13:48,  1.55it/s]1277it [13:49,  1.55it/s]1278it [13:49,  1.55it/s]1279it [13:50,  1.55it/s]1280it [13:51,  1.54it/s]1281it [13:51,  1.55it/s]1282it [13:52,  1.55it/s]1283it [13:53,  1.56it/s]1284it [13:53,  1.55it/s]1285it [13:54,  1.56it/s]1286it [13:55,  1.55it/s]1287it [13:55,  1.55it/s]1288it [13:56,  1.55it/s]1289it [13:57,  1.54it/s]1290it [13:57,  1.54it/s]1291it [13:58,  1.54it/s]1292it [13:58,  1.54it/s]1293it [13:59,  1.54it/s]1294it [14:00,  1.54it/s]1295it [14:00,  1.55it/s]1296it [14:01,  1.55it/s]1297it [14:02,  1.55it/s]1298it [14:02,  1.55it/s]1299it [14:03,  1.55it/s]1300it [14:04,  1.30it/s]1301it [14:05,  1.36it/s]1302it [14:05,  1.41it/s]1303it [14:06,  1.45it/s]1304it [14:07,  1.48it/s]1305it [14:07,  1.50it/s]1306it [14:08,  1.52it/s]1307it [14:09,  1.53it/s]1308it [14:09,  1.52it/s]1309it [14:10,  1.52it/s]1310it [14:11,  1.53it/s]1311it [14:11,  1.52it/s]1312it [14:12,  1.51it/s]1313it [14:13,  1.50it/s]1314it [14:13,  1.47it/s]1315it [14:14,  1.49it/s]1316it [14:15,  1.51it/s]1317it [14:15,  1.52it/s]1318it [14:16,  1.53it/s]1319it [14:17,  1.53it/s]1320it [14:17,  1.54it/s]1321it [14:18,  1.54it/s]1322it [14:18,  1.54it/s]1323it [14:19,  1.55it/s]1324it [14:20,  1.55it/s]1325it [14:20,  1.55it/s]1326it [14:21,  1.55it/s]1327it [14:22,  1.55it/s]1328it [14:22,  1.55it/s]1329it [14:23,  1.55it/s]1330it [14:24,  1.54it/s]1331it [14:24,  1.55it/s]1332it [14:25,  1.55it/s]1333it [14:26,  1.55it/s]1334it [14:26,  1.55it/s]1335it [14:27,  1.56it/s]1336it [14:27,  1.56it/s]1337it [14:28,  1.56it/s]1338it [14:29,  1.55it/s]1339it [14:29,  1.56it/s]1340it [14:30,  1.56it/s]1341it [14:31,  1.55it/s]1342it [14:31,  1.55it/s]1343it [14:32,  1.55it/s]1344it [14:33,  1.55it/s]1345it [14:33,  1.55it/s]1346it [14:34,  1.55it/s]1347it [14:35,  1.55it/s]1348it [14:35,  1.55it/s]1349it [14:36,  1.54it/s]1350it [14:37,  1.54it/s]1351it [14:37,  1.55it/s]1352it [14:38,  1.55it/s]1353it [14:38,  1.55it/s]1354it [14:39,  1.55it/s]1355it [14:40,  1.55it/s]1356it [14:40,  1.55it/s]1357it [14:41,  1.55it/s]1358it [14:42,  1.55it/s]1359it [14:42,  1.55it/s]1360it [14:43,  1.54it/s]1361it [14:44,  1.54it/s]1362it [14:44,  1.55it/s]1363it [14:45,  1.55it/s]1364it [14:46,  1.55it/s]1365it [14:46,  1.55it/s]1366it [14:47,  1.55it/s]1367it [14:47,  1.55it/s]1368it [14:48,  1.56it/s]1369it [14:49,  1.55it/s]1370it [14:49,  1.55it/s]1371it [14:50,  1.55it/s]1372it [14:51,  1.54it/s]1373it [14:51,  1.54it/s]1374it [14:52,  1.54it/s]1375it [14:53,  1.54it/s]1376it [14:53,  1.54it/s]1377it [14:54,  1.54it/s]1378it [14:55,  1.55it/s]1379it [14:55,  1.54it/s]1380it [14:56,  1.54it/s]1381it [14:57,  1.54it/s]1382it [14:57,  1.54it/s]1383it [14:58,  1.54it/s]1384it [14:58,  1.54it/s]1385it [14:59,  1.55it/s]1386it [15:00,  1.55it/s]1387it [15:00,  1.54it/s]1388it [15:01,  1.54it/s]1389it [15:02,  1.54it/s]1390it [15:02,  1.55it/s]1391it [15:03,  1.53it/s]1392it [15:04,  1.53it/s]1393it [15:04,  1.54it/s]1394it [15:05,  1.54it/s]1395it [15:06,  1.54it/s]1396it [15:06,  1.54it/s]1397it [15:07,  1.55it/s]1398it [15:08,  1.54it/s]1399it [15:08,  1.54it/s]1400it [15:09,  1.29it/s]1401it [15:10,  1.36it/s]1402it [15:11,  1.37it/s]1403it [15:11,  1.42it/s]1404it [15:12,  1.46it/s]1405it [15:13,  1.49it/s]1406it [15:13,  1.50it/s]1407it [15:14,  1.51it/s]1408it [15:15,  1.53it/s]1409it [15:15,  1.53it/s]1410it [15:16,  1.54it/s]1411it [15:16,  1.54it/s]1412it [15:17,  1.55it/s]1413it [15:18,  1.55it/s]1414it [15:18,  1.54it/s]1415it [15:19,  1.55it/s]1416it [15:20,  1.55it/s]1417it [15:20,  1.55it/s]1418it [15:21,  1.55it/s]1419it [15:22,  1.55it/s]1420it [15:22,  1.55it/s]1421it [15:23,  1.55it/s]1422it [15:24,  1.55it/s]1423it [15:24,  1.55it/s]1424it [15:25,  1.55it/s]1425it [15:25,  1.55it/s]1426it [15:26,  1.54it/s]1427it [15:27,  1.55it/s]1428it [15:27,  1.55it/s]1429it [15:28,  1.54it/s]1430it [15:29,  1.54it/s]1431it [15:29,  1.55it/s]1432it [15:30,  1.54it/s]1433it [15:31,  1.54it/s]1434it [15:31,  1.55it/s]1435it [15:32,  1.52it/s]1436it [15:33,  1.52it/s]1437it [15:33,  1.53it/s]1438it [15:34,  1.52it/s]1439it [15:35,  1.53it/s]1440it [15:35,  1.53it/s]1441it [15:36,  1.53it/s]1442it [15:37,  1.54it/s]1443it [15:37,  1.54it/s]1444it [15:38,  1.55it/s]1445it [15:38,  1.55it/s]1446it [15:39,  1.55it/s]1447it [15:40,  1.52it/s]1448it [15:40,  1.54it/s]1449it [15:41,  1.55it/s]1450it [15:42,  1.55it/s]1451it [15:42,  1.52it/s]1452it [15:43,  1.53it/s]1453it [15:44,  1.54it/s]1454it [15:44,  1.54it/s]1455it [15:45,  1.55it/s]1456it [15:46,  1.55it/s]1457it [15:46,  1.55it/s]1458it [15:47,  1.55it/s]1459it [15:48,  1.55it/s]1460it [15:48,  1.56it/s]1461it [15:49,  1.56it/s]1462it [15:49,  1.55it/s]1463it [15:50,  1.55it/s]1464it [15:51,  1.55it/s]1465it [15:51,  1.54it/s]1466it [15:52,  1.54it/s]1467it [15:53,  1.53it/s]1468it [15:53,  1.54it/s]1469it [15:54,  1.54it/s]1470it [15:55,  1.55it/s]1471it [15:55,  1.55it/s]1472it [15:56,  1.55it/s]1473it [15:57,  1.55it/s]1474it [15:57,  1.54it/s]1475it [15:58,  1.54it/s]1476it [15:59,  1.54it/s]1477it [15:59,  1.55it/s]1478it [16:00,  1.55it/s]1479it [16:00,  1.56it/s]1480it [16:01,  1.56it/s]1481it [16:02,  1.56it/s]1482it [16:02,  1.55it/s]1483it [16:03,  1.55it/s]1484it [16:04,  1.55it/s]1485it [16:04,  1.55it/s]1486it [16:05,  1.55it/s]1487it [16:06,  1.55it/s]1488it [16:06,  1.55it/s]1489it [16:07,  1.55it/s]1490it [16:08,  1.55it/s]1491it [16:08,  1.55it/s]1492it [16:09,  1.55it/s]1493it [16:10,  1.55it/s]1494it [16:10,  1.56it/s]1495it [16:11,  1.56it/s]1496it [16:11,  1.55it/s]1497it [16:12,  1.55it/s]1498it [16:13,  1.55it/s]1499it [16:13,  1.55it/s]1500it [16:14,  1.30it/s]1501it [16:15,  1.37it/s]1502it [16:16,  1.42it/s]1503it [16:16,  1.45it/s]1504it [16:17,  1.48it/s]1505it [16:18,  1.50it/s]1506it [16:18,  1.52it/s]1507it [16:19,  1.52it/s]1508it [16:20,  1.53it/s]1509it [16:20,  1.53it/s]1510it [16:21,  1.54it/s]1511it [16:22,  1.54it/s]1512it [16:22,  1.54it/s]1513it [16:23,  1.54it/s]1514it [16:23,  1.55it/s]1515it [16:24,  1.55it/s]1516it [16:25,  1.54it/s]1517it [16:25,  1.55it/s]1518it [16:26,  1.55it/s]1519it [16:27,  1.55it/s]1520it [16:27,  1.53it/s]1521it [16:28,  1.54it/s]1522it [16:29,  1.53it/s]1523it [16:29,  1.54it/s]1524it [16:30,  1.54it/s]1525it [16:31,  1.55it/s]1526it [16:31,  1.54it/s]1527it [16:32,  1.55it/s]1528it [16:33,  1.55it/s]1529it [16:33,  1.55it/s]1530it [16:34,  1.55it/s]1531it [16:35,  1.54it/s]1532it [16:35,  1.54it/s]1533it [16:36,  1.54it/s]1534it [16:36,  1.54it/s]1535it [16:37,  1.55it/s]1536it [16:38,  1.55it/s]1537it [16:38,  1.55it/s]1538it [16:39,  1.55it/s]1539it [16:40,  1.55it/s]1540it [16:40,  1.55it/s]1541it [16:41,  1.55it/s]1542it [16:42,  1.55it/s]1543it [16:42,  1.55it/s]1544it [16:43,  1.55it/s]1545it [16:44,  1.54it/s]1546it [16:44,  1.55it/s]1547it [16:45,  1.55it/s]1548it [16:45,  1.55it/s]1549it [16:46,  1.55it/s]1550it [16:47,  1.55it/s]1551it [16:47,  1.55it/s]1552it [16:48,  1.55it/s]1553it [16:49,  1.55it/s]1554it [16:49,  1.55it/s]1555it [16:50,  1.54it/s]1556it [16:51,  1.54it/s]1557it [16:51,  1.55it/s]1558it [16:52,  1.55it/s]1559it [16:53,  1.55it/s]1560it [16:53,  1.56it/s]1561it [16:54,  1.55it/s]1562it [16:55,  1.55it/s]1563it [16:55,  1.56it/s]1564it [16:56,  1.55it/s]1565it [16:56,  1.55it/s]1566it [16:57,  1.56it/s]1567it [16:58,  1.56it/s]1568it [16:58,  1.56it/s]1569it [16:59,  1.56it/s]1570it [17:00,  1.56it/s]1571it [17:00,  1.55it/s]1572it [17:01,  1.55it/s]1573it [17:02,  1.56it/s]1574it [17:02,  1.55it/s]1575it [17:03,  1.55it/s]1576it [17:04,  1.55it/s]1577it [17:04,  1.55it/s]1578it [17:05,  1.55it/s]1579it [17:05,  1.55it/s]1580it [17:06,  1.55it/s]1581it [17:07,  1.55it/s]1582it [17:07,  1.54it/s]1583it [17:08,  1.54it/s]1584it [17:09,  1.55it/s]1585it [17:09,  1.56it/s]1586it [17:10,  1.56it/s]1587it [17:11,  1.56it/s]1588it [17:11,  1.55it/s]1589it [17:12,  1.56it/s]1590it [17:13,  1.56it/s]1591it [17:13,  1.55it/s]1592it [17:14,  1.55it/s]1593it [17:14,  1.55it/s]1594it [17:15,  1.55it/s]1595it [17:16,  1.55it/s]1596it [17:16,  1.55it/s]1597it [17:17,  1.56it/s]1598it [17:18,  1.55it/s]1599it [17:18,  1.55it/s]1600it [17:19,  1.32it/s]1601it [17:20,  1.38it/s]1602it [17:21,  1.43it/s]1603it [17:21,  1.46it/s]1604it [17:22,  1.49it/s]1605it [17:23,  1.51it/s]1606it [17:23,  1.52it/s]1607it [17:24,  1.53it/s]1608it [17:25,  1.54it/s]1609it [17:25,  1.54it/s]1610it [17:26,  1.54it/s]1611it [17:26,  1.54it/s]1612it [17:27,  1.54it/s]1613it [17:28,  1.54it/s]1614it [17:28,  1.54it/s]1615it [17:29,  1.54it/s]1616it [17:30,  1.54it/s]1617it [17:30,  1.54it/s]1618it [17:31,  1.55it/s]1619it [17:32,  1.55it/s]1620it [17:32,  1.55it/s]1621it [17:33,  1.55it/s]1622it [17:34,  1.55it/s]1623it [17:34,  1.54it/s]1624it [17:35,  1.54it/s]1625it [17:36,  1.54it/s]1626it [17:36,  1.54it/s]1627it [17:37,  1.54it/s]1628it [17:37,  1.54it/s]1629it [17:38,  1.55it/s]1630it [17:39,  1.55it/s]1631it [17:39,  1.54it/s]1632it [17:40,  1.55it/s]1633it [17:41,  1.55it/s]1634it [17:41,  1.55it/s]1635it [17:42,  1.55it/s]1636it [17:43,  1.55it/s]1637it [17:43,  1.55it/s]1638it [17:44,  1.55it/s]1639it [17:45,  1.55it/s]1640it [17:45,  1.54it/s]1641it [17:46,  1.54it/s]1642it [17:47,  1.55it/s]1643it [17:47,  1.55it/s]1644it [17:48,  1.55it/s]1645it [17:48,  1.55it/s]1646it [17:49,  1.55it/s]1647it [17:50,  1.55it/s]1648it [17:50,  1.55it/s]1649it [17:51,  1.55it/s]1650it [17:52,  1.55it/s]1651it [17:52,  1.55it/s]1652it [17:53,  1.56it/s]1653it [17:54,  1.56it/s]1654it [17:54,  1.56it/s]1655it [17:55,  1.56it/s]1656it [17:56,  1.56it/s]1657it [17:56,  1.56it/s]1658it [17:57,  1.56it/s]1659it [17:57,  1.56it/s]1660it [17:58,  1.56it/s]1661it [17:59,  1.56it/s]1662it [17:59,  1.56it/s]1663it [18:00,  1.56it/s]1664it [18:01,  1.57it/s]1665it [18:01,  1.57it/s]1666it [18:02,  1.57it/s]1667it [18:03,  1.57it/s]1668it [18:03,  1.57it/s]1669it [18:04,  1.57it/s]1670it [18:04,  1.57it/s]1671it [18:05,  1.57it/s]1672it [18:06,  1.57it/s]1673it [18:06,  1.56it/s]1674it [18:07,  1.56it/s]1675it [18:08,  1.55it/s]1676it [18:08,  1.55it/s]1677it [18:09,  1.55it/s]1678it [18:10,  1.55it/s]1679it [18:10,  1.55it/s]1680it [18:11,  1.54it/s]1681it [18:12,  1.54it/s]1682it [18:12,  1.55it/s]1683it [18:13,  1.55it/s]1684it [18:13,  1.55it/s]1685it [18:14,  1.55it/s]1686it [18:15,  1.55it/s]1687it [18:15,  1.56it/s]1688it [18:16,  1.56it/s]1689it [18:17,  1.56it/s]1690it [18:17,  1.56it/s]1691it [18:18,  1.56it/s]1692it [18:19,  1.55it/s]1693it [18:19,  1.55it/s]1694it [18:20,  1.55it/s]1695it [18:21,  1.55it/s]1696it [18:21,  1.55it/s]1697it [18:22,  1.55it/s]1698it [18:22,  1.55it/s]1699it [18:23,  1.56it/s]1700it [18:24,  1.31it/s]1701it [18:25,  1.38it/s]1702it [18:25,  1.43it/s]1703it [18:26,  1.46it/s]1704it [18:27,  1.49it/s]1705it [18:27,  1.51it/s]1706it [18:28,  1.51it/s]1707it [18:29,  1.52it/s]1708it [18:29,  1.52it/s]1709it [18:30,  1.53it/s]1710it [18:31,  1.53it/s]1711it [18:31,  1.54it/s]1712it [18:32,  1.54it/s]1713it [18:33,  1.54it/s]1714it [18:33,  1.54it/s]1715it [18:34,  1.55it/s]1716it [18:35,  1.55it/s]1717it [18:35,  1.54it/s]1718it [18:36,  1.55it/s]1719it [18:36,  1.55it/s]1720it [18:37,  1.55it/s]1721it [18:38,  1.55it/s]1722it [18:38,  1.55it/s]1723it [18:39,  1.55it/s]1724it [18:40,  1.55it/s]1725it [18:40,  1.55it/s]1726it [18:41,  1.56it/s]1727it [18:42,  1.55it/s]1728it [18:42,  1.55it/s]1729it [18:43,  1.55it/s]1730it [18:44,  1.55it/s]1731it [18:44,  1.55it/s]1732it [18:45,  1.54it/s]1733it [18:45,  1.55it/s]1734it [18:46,  1.55it/s]1735it [18:47,  1.54it/s]1736it [18:47,  1.54it/s]1737it [18:48,  1.54it/s]1738it [18:49,  1.54it/s]1739it [18:49,  1.55it/s]1740it [18:50,  1.55it/s]1741it [18:51,  1.56it/s]1742it [18:51,  1.56it/s]1743it [18:52,  1.56it/s]1744it [18:53,  1.55it/s]1745it [18:53,  1.54it/s]1746it [18:54,  1.54it/s]1747it [18:55,  1.54it/s]1748it [18:55,  1.54it/s]1749it [18:56,  1.54it/s]1750it [18:56,  1.55it/s]1751it [18:57,  1.54it/s]1752it [18:58,  1.54it/s]1753it [18:58,  1.54it/s]1754it [18:59,  1.54it/s]1755it [19:00,  1.54it/s]1756it [19:00,  1.54it/s]1757it [19:01,  1.54it/s]1758it [19:02,  1.54it/s]1759it [19:02,  1.54it/s]1760it [19:03,  1.53it/s]1761it [19:04,  1.53it/s]1762it [19:04,  1.54it/s]1763it [19:05,  1.54it/s]1764it [19:06,  1.53it/s]1765it [19:06,  1.53it/s]1766it [19:07,  1.54it/s]1767it [19:08,  1.54it/s]1768it [19:08,  1.54it/s]1769it [19:09,  1.54it/s]1770it [19:09,  1.54it/s]1771it [19:10,  1.54it/s]1772it [19:11,  1.54it/s]1773it [19:11,  1.54it/s]1774it [19:12,  1.54it/s]1775it [19:13,  1.54it/s]1776it [19:13,  1.54it/s]1777it [19:14,  1.54it/s]1778it [19:15,  1.54it/s]1779it [19:15,  1.54it/s]1780it [19:16,  1.54it/s]1781it [19:17,  1.54it/s]1782it [19:17,  1.54it/s]1783it [19:18,  1.54it/s]1784it [19:19,  1.54it/s]1785it [19:19,  1.54it/s]1786it [19:20,  1.54it/s]1787it [19:21,  1.54it/s]1788it [19:21,  1.54it/s]1789it [19:22,  1.54it/s]1790it [19:22,  1.54it/s]1791it [19:23,  1.54it/s]1792it [19:24,  1.54it/s]1793it [19:24,  1.54it/s]1794it [19:25,  1.54it/s]1795it [19:26,  1.54it/s]1796it [19:26,  1.55it/s]1797it [19:27,  1.55it/s]1798it [19:28,  1.55it/s]1799it [19:28,  1.55it/s]1800it [19:29,  1.29it/s]1801it [19:30,  1.37it/s]1802it [19:31,  1.42it/s]1803it [19:31,  1.46it/s]1804it [19:32,  1.48it/s]1805it [19:33,  1.50it/s]1806it [19:33,  1.52it/s]1807it [19:34,  1.53it/s]1808it [19:35,  1.53it/s]1809it [19:35,  1.54it/s]1810it [19:36,  1.54it/s]1811it [19:36,  1.54it/s]1812it [19:37,  1.55it/s]1813it [19:38,  1.54it/s]1814it [19:38,  1.54it/s]1815it [19:39,  1.55it/s]1816it [19:40,  1.55it/s]1817it [19:40,  1.55it/s]1818it [19:41,  1.55it/s]1819it [19:42,  1.55it/s]1820it [19:42,  1.55it/s]1821it [19:43,  1.55it/s]1822it [19:44,  1.55it/s]1823it [19:44,  1.55it/s]1824it [19:45,  1.55it/s]1825it [19:45,  1.55it/s]1826it [19:46,  1.55it/s]1827it [19:47,  1.55it/s]1828it [19:47,  1.55it/s]1829it [19:48,  1.55it/s]1830it [19:49,  1.55it/s]1831it [19:49,  1.55it/s]1832it [19:50,  1.55it/s]1833it [19:51,  1.55it/s]1834it [19:51,  1.56it/s]1835it [19:52,  1.56it/s]1836it [19:53,  1.57it/s]1837it [19:53,  1.56it/s]1838it [19:54,  1.56it/s]1839it [19:54,  1.56it/s]1840it [19:55,  1.55it/s]1841it [19:56,  1.55it/s]1842it [19:56,  1.54it/s]1843it [19:57,  1.54it/s]1844it [19:58,  1.54it/s]1845it [19:58,  1.54it/s]1846it [19:59,  1.54it/s]1847it [20:00,  1.54it/s]1848it [20:00,  1.55it/s]1849it [20:01,  1.55it/s]1850it [20:02,  1.55it/s]1851it [20:02,  1.55it/s]1852it [20:03,  1.55it/s]1853it [20:04,  1.55it/s]1854it [20:04,  1.55it/s]1855it [20:05,  1.55it/s]1856it [20:05,  1.55it/s]1857it [20:06,  1.55it/s]1858it [20:07,  1.55it/s]1859it [20:07,  1.55it/s]1860it [20:08,  1.55it/s]1861it [20:09,  1.55it/s]1862it [20:09,  1.54it/s]1863it [20:10,  1.54it/s]1864it [20:11,  1.54it/s]1865it [20:11,  1.54it/s]1866it [20:12,  1.54it/s]1867it [20:13,  1.54it/s]1868it [20:13,  1.54it/s]1869it [20:14,  1.55it/s]1870it [20:15,  1.55it/s]1871it [20:15,  1.55it/s]1872it [20:16,  1.55it/s]1873it [20:16,  1.55it/s]1874it [20:17,  1.55it/s]1875it [20:18,  1.55it/s]1876it [20:18,  1.55it/s]1877it [20:19,  1.55it/s]1878it [20:20,  1.55it/s]1879it [20:20,  1.55it/s]1880it [20:21,  1.54it/s]1881it [20:22,  1.55it/s]1882it [20:22,  1.54it/s]1883it [20:23,  1.54it/s]1884it [20:24,  1.55it/s]1885it [20:24,  1.55it/s]1886it [20:25,  1.56it/s]1887it [20:25,  1.57it/s]1888it [20:26,  1.57it/s]1889it [20:27,  1.56it/s]1890it [20:27,  1.56it/s]1891it [20:28,  1.56it/s]1892it [20:29,  1.56it/s]1893it [20:29,  1.56it/s]1894it [20:30,  1.56it/s]1895it [20:31,  1.56it/s]1896it [20:31,  1.55it/s]1897it [20:32,  1.55it/s]1898it [20:33,  1.55it/s]1899it [20:33,  1.55it/s]1900it [20:34,  1.30it/s]1901it [20:35,  1.37it/s]1902it [20:36,  1.42it/s]1903it [20:36,  1.46it/s]1904it [20:37,  1.48it/s]1905it [20:37,  1.50it/s]1906it [20:38,  1.52it/s]1907it [20:39,  1.53it/s]1908it [20:39,  1.54it/s]1909it [20:40,  1.54it/s]1910it [20:41,  1.55it/s]1911it [20:41,  1.55it/s]1912it [20:42,  1.56it/s]1913it [20:43,  1.56it/s]1914it [20:43,  1.56it/s]1915it [20:44,  1.56it/s]1916it [20:45,  1.56it/s]1917it [20:45,  1.56it/s]1918it [20:46,  1.56it/s]1919it [20:46,  1.56it/s]1920it [20:47,  1.56it/s]1921it [20:48,  1.56it/s]1922it [20:48,  1.56it/s]1923it [20:49,  1.56it/s]1924it [20:50,  1.56it/s]1925it [20:50,  1.56it/s]1926it [20:51,  1.56it/s]1927it [20:52,  1.55it/s]1928it [20:52,  1.56it/s]1929it [20:53,  1.55it/s]1930it [20:54,  1.55it/s]1931it [20:54,  1.56it/s]1932it [20:55,  1.56it/s]1933it [20:55,  1.55it/s]1934it [20:56,  1.55it/s]1935it [20:57,  1.55it/s]1936it [20:57,  1.55it/s]1937it [20:58,  1.56it/s]1938it [20:59,  1.55it/s]1939it [20:59,  1.55it/s]1940it [21:00,  1.55it/s]1941it [21:01,  1.55it/s]1942it [21:01,  1.54it/s]1943it [21:02,  1.55it/s]1944it [21:03,  1.55it/s]1945it [21:03,  1.55it/s]1946it [21:04,  1.55it/s]1947it [21:04,  1.55it/s]1948it [21:05,  1.55it/s]1949it [21:06,  1.55it/s]1950it [21:06,  1.55it/s]1951it [21:07,  1.55it/s]1952it [21:08,  1.55it/s]1953it [21:08,  1.55it/s]1954it [21:09,  1.55it/s]1955it [21:10,  1.55it/s]1956it [21:10,  1.55it/s]1957it [21:11,  1.56it/s]1958it [21:12,  1.56it/s]1959it [21:12,  1.55it/s]1960it [21:13,  1.55it/s]1961it [21:14,  1.56it/s]1962it [21:14,  1.55it/s]1963it [21:15,  1.55it/s]1964it [21:15,  1.55it/s]1965it [21:16,  1.55it/s]1966it [21:17,  1.55it/s]1967it [21:17,  1.56it/s]1968it [21:18,  1.56it/s]1969it [21:19,  1.56it/s]1970it [21:19,  1.56it/s]1971it [21:20,  1.56it/s]1972it [21:21,  1.56it/s]1973it [21:21,  1.55it/s]1974it [21:22,  1.55it/s]1975it [21:23,  1.55it/s]1976it [21:23,  1.55it/s]1977it [21:24,  1.55it/s]1978it [21:24,  1.55it/s]1979it [21:25,  1.55it/s]1980it [21:26,  1.55it/s]1981it [21:26,  1.55it/s]1982it [21:27,  1.55it/s]1983it [21:28,  1.55it/s]1984it [21:28,  1.55it/s]1985it [21:29,  1.55it/s]1986it [21:30,  1.52it/s]1987it [21:30,  1.51it/s]1988it [21:31,  1.51it/s]1989it [21:32,  1.52it/s]1990it [21:32,  1.53it/s]1991it [21:33,  1.53it/s]1992it [21:34,  1.53it/s]1993it [21:34,  1.54it/s]1994it [21:35,  1.54it/s]1995it [21:36,  1.54it/s]1996it [21:36,  1.54it/s]1997it [21:37,  1.55it/s]1998it [21:37,  1.55it/s]1999it [21:38,  1.55it/s]2000it [21:39,  1.28it/s]2001it [21:40,  1.36it/s]2002it [21:40,  1.41it/s]2003it [21:41,  1.45it/s]2004it [21:42,  1.48it/s]2005it [21:42,  1.50it/s]2006it [21:43,  1.51it/s]2007it [21:44,  1.53it/s]2008it [21:44,  1.54it/s]2009it [21:45,  1.54it/s]2010it [21:46,  1.54it/s]2011it [21:46,  1.54it/s]2012it [21:47,  1.55it/s]2013it [21:48,  1.55it/s]2014it [21:48,  1.55it/s]2015it [21:49,  1.55it/s]2016it [21:49,  1.56it/s]2017it [21:50,  1.56it/s]2018it [21:51,  1.55it/s]2019it [21:51,  1.56it/s]2020it [21:52,  1.55it/s]2021it [21:53,  1.55it/s]2022it [21:53,  1.55it/s]2023it [21:54,  1.55it/s]2024it [21:55,  1.55it/s]2025it [21:55,  1.55it/s]2026it [21:56,  1.55it/s]2027it [21:57,  1.55it/s]2028it [21:57,  1.56it/s]2029it [21:58,  1.56it/s]2030it [21:58,  1.56it/s]2031it [21:59,  1.56it/s]2032it [22:00,  1.56it/s]2033it [22:00,  1.55it/s]2034it [22:01,  1.54it/s]2035it [22:02,  1.54it/s]2036it [22:02,  1.54it/s]2037it [22:03,  1.54it/s]2038it [22:04,  1.54it/s]2039it [22:04,  1.55it/s]2040it [22:05,  1.55it/s]2041it [22:06,  1.55it/s]2042it [22:06,  1.55it/s]2043it [22:07,  1.54it/s]2044it [22:08,  1.55it/s]2045it [22:08,  1.54it/s]2046it [22:09,  1.54it/s]2047it [22:10,  1.54it/s]2048it [22:10,  1.54it/s]2049it [22:11,  1.54it/s]2050it [22:11,  1.53it/s]2051it [22:12,  1.49it/s]2052it [22:13,  1.50it/s]2053it [22:13,  1.51it/s]2054it [22:14,  1.52it/s]2055it [22:15,  1.53it/s]2056it [22:15,  1.54it/s]2057it [22:16,  1.54it/s]2058it [22:17,  1.54it/s]2059it [22:17,  1.54it/s]2060it [22:18,  1.54it/s]2061it [22:19,  1.55it/s]2062it [22:19,  1.55it/s]2063it [22:20,  1.55it/s]2064it [22:21,  1.55it/s]2065it [22:21,  1.55it/s]2066it [22:22,  1.55it/s]2067it [22:23,  1.55it/s]2068it [22:23,  1.55it/s]2069it [22:24,  1.55it/s]2070it [22:24,  1.55it/s]2071it [22:25,  1.55it/s]2072it [22:26,  1.55it/s]2073it [22:26,  1.54it/s]2074it [22:27,  1.54it/s]2075it [22:28,  1.54it/s]2076it [22:28,  1.54it/s]2077it [22:29,  1.54it/s]2078it [22:30,  1.55it/s]2079it [22:30,  1.55it/s]2080it [22:31,  1.55it/s]2081it [22:32,  1.56it/s]2082it [22:32,  1.56it/s]2083it [22:33,  1.56it/s]2084it [22:33,  1.56it/s]2085it [22:34,  1.55it/s]2086it [22:35,  1.55it/s]2087it [22:35,  1.55it/s]2088it [22:36,  1.56it/s]2089it [22:37,  1.55it/s]2090it [22:37,  1.55it/s]2091it [22:38,  1.55it/s]2092it [22:39,  1.54it/s]2093it [22:39,  1.54it/s]2094it [22:40,  1.54it/s]2095it [22:41,  1.55it/s]2096it [22:41,  1.54it/s]2097it [22:42,  1.55it/s]2098it [22:43,  1.55it/s]2099it [22:43,  1.55it/s]2100it [22:44,  1.32it/s]2101it [22:45,  1.38it/s]2102it [22:46,  1.43it/s]2103it [22:46,  1.46it/s]2104it [22:47,  1.48it/s]2105it [22:47,  1.49it/s]2106it [22:48,  1.51it/s]2107it [22:49,  1.52it/s]2108it [22:49,  1.53it/s]2109it [22:50,  1.53it/s]2110it [22:51,  1.53it/s]2111it [22:51,  1.54it/s]2112it [22:52,  1.53it/s]2113it [22:53,  1.53it/s]2114it [22:53,  1.54it/s]2115it [22:54,  1.54it/s]2116it [22:55,  1.54it/s]2117it [22:55,  1.54it/s]2118it [22:56,  1.54it/s]2119it [22:57,  1.54it/s]2120it [22:57,  1.54it/s]2121it [22:58,  1.55it/s]2122it [22:58,  1.55it/s]2123it [22:59,  1.55it/s]2124it [23:00,  1.55it/s]2125it [23:00,  1.55it/s]2126it [23:01,  1.56it/s]2127it [23:02,  1.56it/s]2128it [23:02,  1.56it/s]2129it [23:03,  1.57it/s]2130it [23:04,  1.57it/s]2131it [23:04,  1.57it/s]2132it [23:05,  1.57it/s]2133it [23:06,  1.56it/s]2134it [23:06,  1.55it/s]2135it [23:07,  1.55it/s]2136it [23:07,  1.55it/s]2137it [23:08,  1.54it/s]2138it [23:09,  1.55it/s]2139it [23:09,  1.55it/s]2140it [23:10,  1.55it/s]2141it [23:11,  1.55it/s]2142it [23:11,  1.54it/s]2143it [23:12,  1.54it/s]2144it [23:13,  1.55it/s]2145it [23:13,  1.54it/s]2146it [23:14,  1.54it/s]2147it [23:15,  1.54it/s]2148it [23:15,  1.53it/s]2149it [23:16,  1.53it/s]2150it [23:17,  1.49it/s]2151it [23:17,  1.49it/s]2152it [23:18,  1.51it/s]2153it [23:19,  1.52it/s]2154it [23:19,  1.53it/s]2155it [23:20,  1.54it/s]2156it [23:20,  1.55it/s]2157it [23:21,  1.55it/s]2158it [23:22,  1.55it/s]2159it [23:22,  1.55it/s]2160it [23:23,  1.54it/s]2161it [23:24,  1.54it/s]2162it [23:24,  1.54it/s]2163it [23:25,  1.54it/s]2164it [23:26,  1.54it/s]2165it [23:26,  1.54it/s]2166it [23:27,  1.54it/s]2167it [23:28,  1.55it/s]2168it [23:28,  1.54it/s]2169it [23:29,  1.54it/s]2170it [23:30,  1.54it/s]2171it [23:30,  1.53it/s]2172it [23:31,  1.53it/s]2173it [23:32,  1.54it/s]2174it [23:32,  1.54it/s]2175it [23:33,  1.54it/s]2176it [23:33,  1.54it/s]2177it [23:34,  1.54it/s]2178it [23:35,  1.54it/s]2179it [23:35,  1.54it/s]2180it [23:36,  1.53it/s]2181it [23:37,  1.53it/s]2182it [23:37,  1.54it/s]2183it [23:38,  1.53it/s]2184it [23:39,  1.54it/s]2185it [23:39,  1.54it/s]2186it [23:40,  1.54it/s]2187it [23:41,  1.54it/s]2188it [23:41,  1.54it/s]2189it [23:42,  1.55it/s]2190it [23:43,  1.55it/s]2191it [23:43,  1.55it/s]2192it [23:44,  1.55it/s]2193it [23:44,  1.55it/s]2194it [23:45,  1.55it/s]2195it [23:46,  1.55it/s]2196it [23:46,  1.55it/s]2197it [23:47,  1.55it/s]2198it [23:48,  1.55it/s]2199it [23:48,  1.55it/s]2200it [23:49,  1.29it/s]2201it [23:50,  1.33it/s]2202it [23:51,  1.39it/s]2203it [23:51,  1.44it/s]2204it [23:52,  1.47it/s]2205it [23:53,  1.50it/s]2206it [23:53,  1.52it/s]2207it [23:54,  1.53it/s]2208it [23:55,  1.54it/s]2209it [23:55,  1.54it/s]2210it [23:56,  1.55it/s]2211it [23:57,  1.55it/s]2212it [23:57,  1.55it/s]2213it [23:58,  1.55it/s]2214it [23:58,  1.56it/s]2215it [23:59,  1.56it/s]2216it [24:00,  1.56it/s]2217it [24:00,  1.56it/s]2218it [24:01,  1.56it/s]2219it [24:02,  1.56it/s]2220it [24:02,  1.56it/s]2221it [24:03,  1.56it/s]2222it [24:04,  1.56it/s]2223it [24:04,  1.55it/s]2224it [24:05,  1.55it/s]2225it [24:06,  1.56it/s]2226it [24:06,  1.56it/s]2227it [24:07,  1.56it/s]2228it [24:07,  1.56it/s]2229it [24:08,  1.57it/s]2230it [24:09,  1.56it/s]2231it [24:09,  1.56it/s]2232it [24:10,  1.56it/s]2233it [24:11,  1.56it/s]2234it [24:11,  1.56it/s]2235it [24:12,  1.56it/s]2236it [24:13,  1.56it/s]2237it [24:13,  1.56it/s]2238it [24:14,  1.56it/s]2239it [24:14,  1.56it/s]2240it [24:15,  1.56it/s]2241it [24:16,  1.56it/s]2242it [24:16,  1.56it/s]2243it [24:17,  1.56it/s]2244it [24:18,  1.56it/s]2245it [24:18,  1.56it/s]2246it [24:19,  1.56it/s]2247it [24:20,  1.56it/s]2248it [24:20,  1.56it/s]2249it [24:21,  1.55it/s]2250it [24:22,  1.56it/s]2251it [24:22,  1.56it/s]2252it [24:23,  1.56it/s]2253it [24:23,  1.56it/s]2254it [24:24,  1.56it/s]2255it [24:25,  1.56it/s]2256it [24:25,  1.56it/s]2257it [24:26,  1.56it/s]2258it [24:27,  1.56it/s]2259it [24:27,  1.56it/s]2260it [24:28,  1.56it/s]2261it [24:29,  1.56it/s]2262it [24:29,  1.56it/s]2263it [24:30,  1.57it/s]2264it [24:31,  1.56it/s]2265it [24:31,  1.56it/s]2266it [24:32,  1.56it/s]2267it [24:32,  1.55it/s]2268it [24:33,  1.55it/s]2269it [24:34,  1.55it/s]2270it [24:34,  1.56it/s]2271it [24:35,  1.56it/s]2272it [24:36,  1.56it/s]2273it [24:36,  1.56it/s]2274it [24:37,  1.56it/s]2275it [24:38,  1.56it/s]2276it [24:38,  1.55it/s]2277it [24:39,  1.54it/s]2278it [24:40,  1.54it/s]2279it [24:40,  1.55it/s]2280it [24:41,  1.56it/s]2281it [24:41,  1.56it/s]2282it [24:42,  1.56it/s]2283it [24:43,  1.56it/s]2284it [24:43,  1.56it/s]2285it [24:44,  1.56it/s]2286it [24:45,  1.56it/s]2287it [24:45,  1.56it/s]2288it [24:46,  1.56it/s]2289it [24:47,  1.56it/s]2290it [24:47,  1.56it/s]2291it [24:48,  1.56it/s]2292it [24:48,  1.56it/s]2293it [24:49,  1.55it/s]2294it [24:50,  1.55it/s]2295it [24:50,  1.55it/s]2296it [24:51,  1.55it/s]2297it [24:52,  1.55it/s]2298it [24:52,  1.55it/s]2299it [24:53,  1.55it/s]2300it [24:54,  1.31it/s]2301it [24:55,  1.38it/s]2302it [24:55,  1.43it/s]2023-03-02 15:52:53.561978: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 15:52:53.648925: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 15:52:54.024002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 15:52:54.024036: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 15:52:54.024040: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/checkpoint_latest.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/checkpoint_latest.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
total_steps = 0
0.11055755615234375 Go allocated
0it [00:00, ?it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
1it [00:03,  3.54s/it]2it [00:04,  1.74s/it]3it [00:04,  1.17s/it]4it [00:05,  1.10it/s]5it [00:05,  1.30it/s]6it [00:06,  1.47it/s]7it [00:06,  1.60it/s]8it [00:07,  1.70it/s]9it [00:07,  1.77it/s]10it [00:08,  1.74it/s]11it [00:08,  1.70it/s]12it [00:09,  1.65it/s]13it [00:10,  1.63it/s]14it [00:10,  1.61it/s]15it [00:11,  1.61it/s]16it [00:11,  1.60it/s]17it [00:12,  1.60it/s]18it [00:13,  1.59it/s]19it [00:13,  1.58it/s]20it [00:14,  1.58it/s]21it [00:15,  1.58it/s]22it [00:15,  1.58it/s]23it [00:16,  1.58it/s]24it [00:17,  1.58it/s]25it [00:17,  1.58it/s]26it [00:18,  1.58it/s]27it [00:18,  1.58it/s]28it [00:19,  1.58it/s]29it [00:20,  1.58it/s]30it [00:20,  1.58it/s]31it [00:21,  1.58it/s]32it [00:22,  1.58it/s]33it [00:22,  1.58it/s]34it [00:23,  1.58it/s]35it [00:23,  1.58it/s]36it [00:24,  1.57it/s]37it [00:25,  1.57it/s]38it [00:25,  1.57it/s]39it [00:26,  1.57it/s]40it [00:27,  1.56it/s]41it [00:27,  1.56it/s]42it [00:28,  1.57it/s]43it [00:29,  1.57it/s]44it [00:29,  1.57it/s]45it [00:30,  1.57it/s]46it [00:31,  1.57it/s]47it [00:31,  1.57it/s]48it [00:32,  1.56it/s]49it [00:32,  1.56it/s]50it [00:33,  1.56it/s]51it [00:34,  1.56it/s]52it [00:34,  1.57it/s]53it [00:35,  1.57it/s]54it [00:36,  1.57it/s]55it [00:36,  1.57it/s]56it [00:37,  1.57it/s]57it [00:38,  1.57it/s]58it [00:38,  1.57it/s]59it [00:39,  1.57it/s]60it [00:39,  1.57it/s]61it [00:40,  1.57it/s]62it [00:41,  1.56it/s]63it [00:41,  1.56it/s]64it [00:42,  1.56it/s]65it [00:43,  1.55it/s]66it [00:43,  1.55it/s]67it [00:44,  1.56it/s]68it [00:45,  1.55it/s]69it [00:45,  1.55it/s]70it [00:46,  1.56it/s]71it [00:47,  1.56it/s]72it [00:47,  1.56it/s]73it [00:48,  1.56it/s]74it [00:48,  1.56it/s]75it [00:49,  1.56it/s]76it [00:50,  1.56it/s]77it [00:50,  1.55it/s]78it [00:51,  1.55it/s]79it [00:52,  1.56it/s]80it [00:52,  1.56it/s]81it [00:53,  1.56it/s]82it [00:54,  1.57it/s]83it [00:54,  1.57it/s]84it [00:55,  1.57it/s]85it [00:56,  1.56it/s]86it [00:56,  1.56it/s]87it [00:57,  1.56it/s]88it [00:57,  1.56it/s]89it [00:58,  1.56it/s]90it [00:59,  1.55it/s]91it [00:59,  1.55it/s]92it [01:00,  1.55it/s]93it [01:01,  1.55it/s]94it [01:01,  1.56it/s]95it [01:02,  1.56it/s]96it [01:03,  1.56it/s]97it [01:03,  1.57it/s]98it [01:04,  1.57it/s]99it [01:04,  1.57it/s]100it [01:06,  1.31it/s]Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/step_005900.pth
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 210, in main
    checkpoint = torch.load(args.resume, map_location=loc)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/serialization.py", line 771, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/serialization.py", line 270, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/serialization.py", line 251, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'checkpoints_stereo/step_005900.pth'
2023-03-02 15:54:40.763112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 15:54:40.849985: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 15:54:41.229691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 15:54:41.229728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 15:54:41.229731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='none', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'none'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/step_005900.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
=> Start training...
total_steps = 0
0.054798126220703125 Go allocated
0it [00:00, ?it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
1it [00:03,  3.95s/it]2it [00:04,  1.94s/it]3it [00:05,  1.31s/it]4it [00:05,  1.03s/it]5it [00:06,  1.14it/s]6it [00:06,  1.27it/s]7it [00:07,  1.38it/s]8it [00:08,  1.46it/s]9it [00:08,  1.51it/s]10it [00:09,  1.55it/s]11it [00:09,  1.58it/s]12it [00:10,  1.58it/s]13it [00:11,  1.58it/s]14it [00:11,  1.57it/s]15it [00:12,  1.57it/s]16it [00:13,  1.58it/s]17it [00:13,  1.57it/s]18it [00:14,  1.57it/s]19it [00:14,  1.57it/s]20it [00:15,  1.57it/s]21it [00:16,  1.57it/s]22it [00:16,  1.57it/s]23it [00:17,  1.57it/s]24it [00:18,  1.57it/s]25it [00:18,  1.56it/s]26it [00:19,  1.56it/s]27it [00:20,  1.57it/s]28it [00:20,  1.57it/s]29it [00:21,  1.57it/s]30it [00:21,  1.57it/s]31it [00:22,  1.56it/s]32it [00:23,  1.56it/s]33it [00:23,  1.54it/s]34it [00:24,  1.54it/s]35it [00:25,  1.54it/s]36it [00:25,  1.54it/s]37it [00:26,  1.55it/s]38it [00:27,  1.55it/s]39it [00:27,  1.56it/s]40it [00:28,  1.56it/s]41it [00:29,  1.56it/s]42it [00:29,  1.56it/s]43it [00:30,  1.54it/s]44it [00:31,  1.55it/s]45it [00:31,  1.56it/s]46it [00:32,  1.56it/s]47it [00:32,  1.55it/s]48it [00:33,  1.56it/s]49it [00:34,  1.56it/s]50it [00:34,  1.56it/s]Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'pytorch'
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 157, in main
    init_dist(args.launcher, **dist_params)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/utils/dist_utils.py", line 16, in init_dist
    _init_dist_pytorch(backend, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/utils/dist_utils.py", line 27, in _init_dist_pytorch
    rank = int(os.environ['RANK'])
  File "/usr/lib/python3.9/os.py", line 679, in __getitem__
    raise KeyError(key) from None
KeyError: 'RANK'
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=1024, img_width=1536, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'pytorch'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/step_005900.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 16:02:59.308818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 16:02:59.397143: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 16:02:59.792698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:02:59.792733: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:02:59.792736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
total_steps = 0
0.08244705200195312 Go allocated
0it [00:00, ?it/s]0it [00:02, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 182, in forward
    feature0, feature1 = self.transformer(feature0, feature1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 278, in forward
    concat0 = layer(concat0, concat1,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 183, in forward
    source = self.self_attn(source, source,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/transformer.py", line 110, in forward
    message = single_head_split_window_attention(query, key, value,
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/attention.py", line 85, in single_head_split_window_attention
    scores = torch.matmul(q.view(b_new, -1, c), k.view(b_new, -1, c).permute(0, 2, 1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.12 GiB (GPU 0; 15.75 GiB total capacity; 13.90 GiB already allocated; 11.12 MiB free; 14.23 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 391200) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-02_16:03:17
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 391200)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'pytorch'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/step_005900.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 16:03:50.560479: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 16:03:50.646885: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 16:03:51.039976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:03:51.040016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:03:51.040021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
total_steps = 0
0.08244705200195312 Go allocated
0it [00:00, ?it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
1it [00:03,  3.35s/it]2it [00:03,  1.66s/it]3it [00:04,  1.12s/it]4it [00:04,  1.14it/s]5it [00:05,  1.36it/s]6it [00:05,  1.52it/s]7it [00:06,  1.66it/s]8it [00:06,  1.75it/s]9it [00:07,  1.83it/s]10it [00:07,  1.88it/s]11it [00:08,  1.91it/s]12it [00:08,  1.94it/s]13it [00:09,  1.96it/s]14it [00:09,  1.97it/s]15it [00:10,  1.99it/s]16it [00:10,  1.99it/s]17it [00:11,  2.00it/s]18it [00:11,  2.00it/s]19it [00:12,  2.00it/s]20it [00:12,  2.00it/s]21it [00:13,  1.94it/s]22it [00:13,  1.85it/s]23it [00:14,  1.79it/s]24it [00:15,  1.74it/s]25it [00:15,  1.71it/s]26it [00:16,  1.70it/s]27it [00:16,  1.69it/s]28it [00:17,  1.67it/s]29it [00:18,  1.67it/s]30it [00:18,  1.67it/s]31it [00:19,  1.66it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=477, img_width=579, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'pytorch'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/step_005900.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 16:04:46.728510: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 16:04:46.814378: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 16:04:47.208024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:04:47.208059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:04:47.208063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
total_steps = 0
0.08244705200195312 Go allocated
0it [00:00, ?it/s]0it [00:01, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 177, in forward
    feature0, feature1 = feature_add_position(feature0, feature1, attn_splits, self.feature_channels)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py", line 115, in feature_add_position
    feature0_splits = split_feature(feature0, num_splits=attn_splits)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py", line 50, in split_feature
    assert h % num_splits == 0 and w % num_splits == 0
AssertionError
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 394776) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-02_16:04:59
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 394776)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=240, img_width=480, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'pytorch'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/step_005900.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 16:05:52.569242: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 16:05:52.656227: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 16:05:53.056210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:05:53.056245: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:05:53.056249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
total_steps = 0
0.08244705200195312 Go allocated
0it [00:00, ?it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
0it [00:01, ?it/s]
Traceback (most recent call last):
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 614, in <module>
    main(args)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/main_stereo.py", line 408, in main
    pred_disps = model(left, right,
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/unimatch.py", line 177, in forward
    feature0, feature1 = feature_add_position(feature0, feature1, attn_splits, self.feature_channels)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py", line 115, in feature_add_position
    feature0_splits = split_feature(feature0, num_splits=attn_splits)
  File "/home/godeta/PycharmProjects/LYNRED/Stereo_matching/NeuralNetwork/UniMatch/unimatch/utils.py", line 50, in split_feature
    assert h % num_splits == 0 and w % num_splits == 0
AssertionError
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 396744) of binary: /usr/bin/python3.9
Traceback (most recent call last):
  File "/usr/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 195, in <module>
    main()
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 191, in main
    launch(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py", line 176, in launch
    run(args)
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 246, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main_stereo.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-03-02_16:06:05
  host      : laptop-493
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 396744)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=100, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'pytorch'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/step_005900.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 16:07:04.253092: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 16:07:04.341330: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 16:07:04.742184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:07:04.742219: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 16:07:04.742222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
total_steps = 0
0.08244705200195312 Go allocated
0it [00:00, ?it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
1it [00:03,  3.38s/it]2it [00:03,  1.67s/it]3it [00:04,  1.13s/it]4it [00:04,  1.14it/s]5it [00:05,  1.35it/s]6it [00:05,  1.52it/s]7it [00:06,  1.66it/s]8it [00:06,  1.76it/s]9it [00:07,  1.82it/s]10it [00:07,  1.87it/s]11it [00:08,  1.91it/s]12it [00:08,  1.94it/s]13it [00:09,  1.96it/s]14it [00:09,  1.97it/s]15it [00:10,  1.98it/s]16it [00:10,  1.99it/s]17it [00:11,  2.00it/s]18it [00:11,  2.00it/s]19it [00:12,  1.99it/s]20it [00:12,  2.00it/s]21it [00:13,  1.94it/s]22it [00:13,  1.85it/s]23it [00:14,  1.79it/s]24it [00:15,  1.74it/s]25it [00:15,  1.72it/s]26it [00:16,  1.70it/s]27it [00:16,  1.68it/s]28it [00:17,  1.67it/s]29it [00:18,  1.67it/s]30it [00:18,  1.67it/s]31it [00:19,  1.66it/s]32it [00:20,  1.66it/s]33it [00:20,  1.66it/s]34it [00:21,  1.65it/s]35it [00:21,  1.65it/s]36it [00:22,  1.65it/s]37it [00:23,  1.65it/s]38it [00:23,  1.65it/s]39it [00:24,  1.65it/s]40it [00:24,  1.65it/s]41it [00:25,  1.65it/s]42it [00:26,  1.66it/s]43it [00:26,  1.66it/s]44it [00:27,  1.65it/s]45it [00:27,  1.66it/s]46it [00:28,  1.65it/s]47it [00:29,  1.65it/s]48it [00:29,  1.65it/s]49it [00:30,  1.65it/s]50it [00:30,  1.65it/s]51it [00:31,  1.65it/s]52it [00:32,  1.65it/s]53it [00:32,  1.65it/s]54it [00:33,  1.65it/s]55it [00:33,  1.65it/s]56it [00:34,  1.64it/s]57it [00:35,  1.64it/s]58it [00:35,  1.64it/s]59it [00:36,  1.64it/s]60it [00:36,  1.64it/s]61it [00:37,  1.64it/s]62it [00:38,  1.64it/s]63it [00:38,  1.64it/s]64it [00:39,  1.64it/s]65it [00:40,  1.64it/s]66it [00:40,  1.65it/s]67it [00:41,  1.65it/s]68it [00:41,  1.64it/s]69it [00:42,  1.64it/s]70it [00:43,  1.65it/s]71it [00:43,  1.64it/s]72it [00:44,  1.65it/s]73it [00:44,  1.65it/s]74it [00:45,  1.64it/s]75it [00:46,  1.64it/s]76it [00:46,  1.64it/s]77it [00:47,  1.64it/s]78it [00:47,  1.64it/s]79it [00:48,  1.64it/s]80it [00:49,  1.64it/s]81it [00:49,  1.64it/s]82it [00:50,  1.64it/s]83it [00:51,  1.64it/s]84it [00:51,  1.63it/s]85it [00:52,  1.64it/s]86it [00:52,  1.64it/s]87it [00:53,  1.64it/s]88it [00:54,  1.64it/s]89it [00:54,  1.63it/s]90it [00:55,  1.63it/s]91it [00:55,  1.64it/s]92it [00:56,  1.64it/s]93it [00:57,  1.63it/s]94it [00:57,  1.63it/s]95it [00:58,  1.63it/s]96it [00:58,  1.63it/s]97it [00:59,  1.63it/s]98it [01:00,  1.63it/s]99it [01:00,  1.63it/s]step: 000100 	 epe: 5.251
Save checkpoint at step: 100
100it [01:01,  1.36it/s]101it [01:02,  1.43it/s]102it [01:03,  1.49it/s]103it [01:03,  1.53it/s]104it [01:04,  1.56it/s]105it [01:04,  1.58it/s]106it [01:05,  1.60it/s]107it [01:06,  1.61it/s]108it [01:06,  1.62it/s]109it [01:07,  1.63it/s]110it [01:07,  1.62it/s]111it [01:08,  1.63it/s]112it [01:09,  1.63it/s]113it [01:09,  1.63it/s]114it [01:10,  1.63it/s]115it [01:11,  1.63it/s]116it [01:11,  1.63it/s]117it [01:12,  1.64it/s]118it [01:12,  1.63it/s]119it [01:13,  1.64it/s]120it [01:14,  1.64it/s]121it [01:14,  1.64it/s]122it [01:15,  1.64it/s]123it [01:15,  1.64it/s]124it [01:16,  1.65it/s]125it [01:17,  1.65it/s]126it [01:17,  1.65it/s]127it [01:18,  1.64it/s]128it [01:18,  1.64it/s]129it [01:19,  1.63it/s]130it [01:20,  1.63it/s]131it [01:20,  1.62it/s]132it [01:21,  1.63it/s]133it [01:21,  1.63it/s]134it [01:22,  1.63it/s]135it [01:23,  1.63it/s]136it [01:23,  1.63it/s]137it [01:24,  1.63it/s]138it [01:25,  1.63it/s]139it [01:25,  1.63it/s]140it [01:26,  1.63it/s]141it [01:26,  1.63it/s]142it [01:27,  1.63it/s]143it [01:28,  1.63it/s]144it [01:28,  1.63it/s]145it [01:29,  1.63it/s]146it [01:29,  1.63it/s]147it [01:30,  1.63it/s]148it [01:31,  1.62it/s]149it [01:31,  1.62it/s]150it [01:32,  1.62it/s]151it [01:33,  1.62it/s]152it [01:33,  1.62it/s]153it [01:34,  1.62it/s]154it [01:34,  1.62it/s]155it [01:35,  1.63it/s]156it [01:36,  1.63it/s]157it [01:36,  1.63it/s]158it [01:37,  1.63it/s]159it [01:37,  1.63it/s]160it [01:38,  1.63it/s]161it [01:39,  1.63it/s]162it [01:39,  1.63it/s]163it [01:40,  1.63it/s]164it [01:41,  1.63it/s]165it [01:41,  1.63it/s]166it [01:42,  1.63it/s]167it [01:42,  1.63it/s]168it [01:43,  1.63it/s]169it [01:44,  1.63it/s]170it [01:44,  1.63it/s]171it [01:45,  1.63it/s]172it [01:45,  1.63it/s]173it [01:46,  1.63it/s]174it [01:47,  1.64it/s]175it [01:47,  1.63it/s]176it [01:48,  1.63it/s]177it [01:49,  1.64it/s]178it [01:49,  1.63it/s]179it [01:50,  1.64it/s]180it [01:50,  1.64it/s]181it [01:51,  1.64it/s]182it [01:52,  1.64it/s]183it [01:52,  1.63it/s]184it [01:53,  1.63it/s]185it [01:53,  1.63it/s]186it [01:54,  1.63it/s]187it [01:55,  1.63it/s]188it [01:55,  1.63it/s]189it [01:56,  1.63it/s]190it [01:56,  1.63it/s]191it [01:57,  1.63it/s]192it [01:58,  1.63it/s]193it [01:58,  1.63it/s]194it [01:59,  1.62it/s]195it [02:00,  1.62it/s]196it [02:00,  1.62it/s]197it [02:01,  1.62it/s]198it [02:01,  1.62it/s]199it [02:02,  1.62it/s]step: 000200 	 epe: 7.873
Save checkpoint at step: 200
200it [02:03,  1.34it/s]201it [02:04,  1.42it/s]202it [02:04,  1.48it/s]203it [02:05,  1.52it/s]204it [02:06,  1.55it/s]205it [02:06,  1.57it/s]206it [02:07,  1.59it/s]207it [02:07,  1.60it/s]208it [02:08,  1.60it/s]209it [02:09,  1.61it/s]210it [02:09,  1.61it/s]211it [02:10,  1.61it/s]212it [02:10,  1.61it/s]213it [02:11,  1.62it/s]214it [02:12,  1.62it/s]215it [02:12,  1.62it/s]216it [02:13,  1.62it/s]217it [02:14,  1.62it/s]218it [02:14,  1.62it/s]219it [02:15,  1.62it/s]220it [02:15,  1.62it/s]221it [02:16,  1.62it/s]222it [02:17,  1.62it/s]223it [02:17,  1.63it/s]224it [02:18,  1.63it/s]225it [02:18,  1.63it/s]226it [02:19,  1.63it/s]227it [02:20,  1.63it/s]228it [02:20,  1.62it/s]229it [02:21,  1.62it/s]230it [02:22,  1.62it/s]231it [02:22,  1.63it/s]232it [02:23,  1.63it/s]233it [02:23,  1.63it/s]234it [02:24,  1.62it/s]235it [02:25,  1.62it/s]236it [02:25,  1.62it/s]237it [02:26,  1.62it/s]238it [02:26,  1.62it/s]239it [02:27,  1.62it/s]240it [02:28,  1.62it/s]241it [02:28,  1.62it/s]242it [02:29,  1.62it/s]243it [02:30,  1.62it/s]244it [02:30,  1.62it/s]245it [02:31,  1.62it/s]246it [02:31,  1.62it/s]247it [02:32,  1.62it/s]248it [02:33,  1.62it/s]249it [02:33,  1.62it/s]250it [02:34,  1.63it/s]251it [02:34,  1.62it/s]252it [02:35,  1.62it/s]253it [02:36,  1.62it/s]254it [02:36,  1.63it/s]255it [02:37,  1.62it/s]256it [02:38,  1.62it/s]257it [02:38,  1.63it/s]258it [02:39,  1.63it/s]259it [02:39,  1.62it/s]260it [02:40,  1.62it/s]261it [02:41,  1.62it/s]262it [02:41,  1.62it/s]263it [02:42,  1.62it/s]264it [02:43,  1.62it/s]265it [02:43,  1.63it/s]266it [02:44,  1.63it/s]267it [02:44,  1.63it/s]268it [02:45,  1.63it/s]269it [02:46,  1.63it/s]270it [02:46,  1.62it/s]271it [02:47,  1.62it/s]272it [02:47,  1.62it/s]273it [02:48,  1.62it/s]274it [02:49,  1.61it/s]275it [02:49,  1.62it/s]276it [02:50,  1.61it/s]277it [02:51,  1.62it/s]278it [02:51,  1.62it/s]279it [02:52,  1.62it/s]280it [02:52,  1.62it/s]281it [02:53,  1.61it/s]282it [02:54,  1.62it/s]283it [02:54,  1.62it/s]284it [02:55,  1.62it/s]285it [02:55,  1.62it/s]286it [02:56,  1.63it/s]287it [02:57,  1.63it/s]288it [02:57,  1.63it/s]289it [02:58,  1.63it/s]290it [02:59,  1.63it/s]291it [02:59,  1.63it/s]292it [03:00,  1.62it/s]293it [03:00,  1.62it/s]294it [03:01,  1.62it/s]295it [03:02,  1.62it/s]296it [03:02,  1.62it/s]297it [03:03,  1.62it/s]298it [03:03,  1.62it/s]299it [03:04,  1.63it/s]step: 000300 	 epe: 4.094
Save checkpoint at step: 300
300it [03:05,  1.36it/s]301it [03:06,  1.43it/s]302it [03:06,  1.48it/s]303it [03:07,  1.52it/s]304it [03:08,  1.55it/s]305it [03:08,  1.57it/s]306it [03:09,  1.59it/s]307it [03:09,  1.60it/s]308it [03:10,  1.61it/s]309it [03:11,  1.62it/s]310it [03:11,  1.62it/s]311it [03:12,  1.62it/s]312it [03:12,  1.63it/s]313it [03:13,  1.63it/s]314it [03:14,  1.62it/s]315it [03:14,  1.63it/s]316it [03:15,  1.62it/s]317it [03:16,  1.62it/s]318it [03:16,  1.63it/s]319it [03:17,  1.62it/s]320it [03:17,  1.62it/s]321it [03:18,  1.62it/s]322it [03:19,  1.62it/s]323it [03:19,  1.62it/s]324it [03:20,  1.62it/s]325it [03:20,  1.63it/s]326it [03:21,  1.63it/s]327it [03:22,  1.62it/s]328it [03:22,  1.62it/s]329it [03:23,  1.62it/s]330it [03:24,  1.62it/s]331it [03:24,  1.63it/s]332it [03:25,  1.62it/s]333it [03:25,  1.62it/s]334it [03:26,  1.62it/s]335it [03:27,  1.62it/s]336it [03:27,  1.61it/s]337it [03:28,  1.62it/s]338it [03:29,  1.62it/s]339it [03:29,  1.62it/s]340it [03:30,  1.63it/s]341it [03:30,  1.63it/s]342it [03:31,  1.63it/s]343it [03:32,  1.63it/s]344it [03:32,  1.63it/s]345it [03:33,  1.62it/s]346it [03:33,  1.62it/s]347it [03:34,  1.62it/s]348it [03:35,  1.62it/s]349it [03:35,  1.62it/s]350it [03:36,  1.62it/s]351it [03:37,  1.62it/s]352it [03:37,  1.62it/s]353it [03:38,  1.62it/s]354it [03:38,  1.62it/s]355it [03:39,  1.62it/s]356it [03:40,  1.62it/s]357it [03:40,  1.62it/s]358it [03:41,  1.62it/s]359it [03:41,  1.62it/s]360it [03:42,  1.62it/s]361it [03:43,  1.63it/s]362it [03:43,  1.62it/s]363it [03:44,  1.62it/s]364it [03:45,  1.62it/s]365it [03:45,  1.63it/s]366it [03:46,  1.63it/s]367it [03:46,  1.63it/s]368it [03:47,  1.63it/s]369it [03:48,  1.63it/s]370it [03:48,  1.63it/s]371it [03:49,  1.62it/s]372it [03:49,  1.62it/s]373it [03:50,  1.62it/s]374it [03:51,  1.63it/s]375it [03:51,  1.63it/s]376it [03:52,  1.62it/s]377it [03:53,  1.62it/s]378it [03:53,  1.62it/s]379it [03:54,  1.62it/s]380it [03:54,  1.62it/s]381it [03:55,  1.62it/s]382it [03:56,  1.62it/s]383it [03:56,  1.62it/s]384it [03:57,  1.62it/s]385it [03:57,  1.62it/s]386it [03:58,  1.63it/s]387it [03:59,  1.63it/s]388it [03:59,  1.63it/s]389it [04:00,  1.63it/s]390it [04:01,  1.62it/s]391it [04:01,  1.62it/s]392it [04:02,  1.62it/s]393it [04:02,  1.62it/s]394it [04:03,  1.62it/s]395it [04:04,  1.62it/s]396it [04:04,  1.62it/s]397it [04:05,  1.61it/s]398it [04:05,  1.61it/s]399it [04:06,  1.62it/s]step: 000400 	 epe: 3.742
Save checkpoint at step: 400
400it [04:07,  1.34it/s]401it [04:08,  1.41it/s]402it [04:08,  1.47it/s]403it [04:09,  1.51it/s]404it [04:10,  1.54it/s]405it [04:10,  1.57it/s]406it [04:11,  1.59it/s]407it [04:11,  1.60it/s]408it [04:12,  1.61it/s]409it [04:13,  1.61it/s]410it [04:13,  1.62it/s]411it [04:14,  1.62it/s]412it [04:15,  1.62it/s]413it [04:15,  1.62it/s]414it [04:16,  1.62it/s]415it [04:16,  1.62it/s]416it [04:17,  1.62it/s]417it [04:18,  1.62it/s]418it [04:18,  1.61it/s]419it [04:19,  1.62it/s]420it [04:19,  1.62it/s]421it [04:20,  1.62it/s]422it [04:21,  1.61it/s]423it [04:21,  1.61it/s]424it [04:22,  1.62it/s]425it [04:23,  1.62it/s]426it [04:23,  1.62it/s]427it [04:24,  1.62it/s]428it [04:24,  1.62it/s]429it [04:25,  1.62it/s]430it [04:26,  1.62it/s]431it [04:26,  1.63it/s]432it [04:27,  1.63it/s]433it [04:27,  1.63it/s]434it [04:28,  1.62it/s]435it [04:29,  1.62it/s]436it [04:29,  1.62it/s]437it [04:30,  1.63it/s]438it [04:31,  1.63it/s]439it [04:31,  1.63it/s]440it [04:32,  1.63it/s]441it [04:32,  1.62it/s]442it [04:33,  1.62it/s]443it [04:34,  1.62it/s]444it [04:34,  1.62it/s]445it [04:35,  1.63it/s]446it [04:35,  1.63it/s]447it [04:36,  1.63it/s]448it [04:37,  1.63it/s]449it [04:37,  1.63it/s]450it [04:38,  1.63it/s]451it [04:39,  1.63it/s]452it [04:39,  1.63it/s]453it [04:40,  1.63it/s]454it [04:40,  1.63it/s]455it [04:41,  1.62it/s]456it [04:42,  1.62it/s]457it [04:42,  1.62it/s]458it [04:43,  1.62it/s]459it [04:43,  1.62it/s]460it [04:44,  1.62it/s]461it [04:45,  1.62it/s]462it [04:45,  1.62it/s]463it [04:46,  1.63it/s]464it [04:47,  1.62it/s]465it [04:47,  1.62it/s]466it [04:48,  1.62it/s]467it [04:48,  1.62it/s]468it [04:49,  1.62it/s]469it [04:50,  1.62it/s]470it [04:50,  1.62it/s]471it [04:51,  1.62it/s]472it [04:52,  1.62it/s]473it [04:52,  1.63it/s]474it [04:53,  1.63it/s]475it [04:53,  1.62it/s]476it [04:54,  1.62it/s]477it [04:55,  1.62it/s]478it [04:55,  1.62it/s]479it [04:56,  1.63it/s]480it [04:56,  1.63it/s]481it [04:57,  1.62it/s]482it [04:58,  1.62it/s]483it [04:58,  1.62it/s]484it [04:59,  1.61it/s]485it [05:00,  1.61it/s]486it [05:00,  1.62it/s]487it [05:01,  1.62it/s]488it [05:01,  1.62it/s]489it [05:02,  1.62it/s]490it [05:03,  1.62it/s]491it [05:03,  1.62it/s]492it [05:04,  1.62it/s]493it [05:04,  1.63it/s]494it [05:05,  1.63it/s]495it [05:06,  1.62it/s]496it [05:06,  1.62it/s]497it [05:07,  1.62it/s]498it [05:08,  1.62it/s]499it [05:08,  1.62it/s]step: 000500 	 epe: 1.938
Save checkpoint at step: 500
500it [05:09,  1.34it/s]501it [05:10,  1.41it/s]502it [05:10,  1.47it/s]503it [05:11,  1.51it/s]504it [05:12,  1.54it/s]505it [05:12,  1.57it/s]506it [05:13,  1.59it/s]507it [05:14,  1.60it/s]508it [05:14,  1.61it/s]509it [05:15,  1.62it/s]510it [05:15,  1.63it/s]511it [05:16,  1.62it/s]512it [05:17,  1.62it/s]513it [05:17,  1.63it/s]514it [05:18,  1.63it/s]515it [05:18,  1.63it/s]516it [05:19,  1.63it/s]517it [05:20,  1.62it/s]518it [05:20,  1.62it/s]519it [05:21,  1.62it/s]520it [05:22,  1.63it/s]521it [05:22,  1.62it/s]522it [05:23,  1.62it/s]523it [05:23,  1.63it/s]524it [05:24,  1.63it/s]525it [05:25,  1.63it/s]526it [05:25,  1.63it/s]527it [05:26,  1.63it/s]528it [05:26,  1.63it/s]529it [05:27,  1.63it/s]530it [05:28,  1.63it/s]531it [05:28,  1.63it/s]532it [05:29,  1.63it/s]533it [05:29,  1.63it/s]534it [05:30,  1.63it/s]535it [05:31,  1.63it/s]536it [05:31,  1.63it/s]537it [05:32,  1.63it/s]538it [05:33,  1.62it/s]539it [05:33,  1.63it/s]540it [05:34,  1.63it/s]541it [05:34,  1.62it/s]542it [05:35,  1.62it/s]543it [05:36,  1.62it/s]544it [05:36,  1.62it/s]545it [05:37,  1.62it/s]546it [05:37,  1.63it/s]547it [05:38,  1.63it/s]548it [05:39,  1.63it/s]549it [05:39,  1.63it/s]550it [05:40,  1.63it/s]551it [05:41,  1.63it/s]552it [05:41,  1.63it/s]553it [05:42,  1.63it/s]554it [05:42,  1.63it/s]555it [05:43,  1.63it/s]556it [05:44,  1.62it/s]557it [05:44,  1.62it/s]558it [05:45,  1.63it/s]559it [05:45,  1.63it/s]560it [05:46,  1.63it/s]561it [05:47,  1.62it/s]562it [05:47,  1.62it/s]563it [05:48,  1.62it/s]564it [05:49,  1.62it/s]565it [05:49,  1.62it/s]566it [05:50,  1.62it/s]567it [05:50,  1.63it/s]568it [05:51,  1.63it/s]569it [05:52,  1.63it/s]570it [05:52,  1.63it/s]571it [05:53,  1.63it/s]572it [05:53,  1.63it/s]573it [05:54,  1.63it/s]574it [05:55,  1.63it/s]575it [05:55,  1.63it/s]576it [05:56,  1.64it/s]577it [05:57,  1.64it/s]578it [05:57,  1.64it/s]579it [05:58,  1.63it/s]580it [05:58,  1.63it/s]581it [05:59,  1.63it/s]582it [06:00,  1.62it/s]583it [06:00,  1.62it/s]584it [06:01,  1.62it/s]585it [06:01,  1.62it/s]586it [06:02,  1.62it/s]587it [06:03,  1.62it/s]588it [06:03,  1.62it/s]589it [06:04,  1.63it/s]590it [06:05,  1.63it/s]591it [06:05,  1.63it/s]592it [06:06,  1.63it/s]593it [06:06,  1.63it/s]594it [06:07,  1.63it/s]595it [06:08,  1.63it/s]596it [06:08,  1.63it/s]597it [06:09,  1.63it/s]598it [06:09,  1.63it/s]599it [06:10,  1.63it/s]step: 000600 	 epe: 5.957
Save checkpoint at step: 600
600it [06:11,  1.36it/s]601it [06:12,  1.43it/s]602it [06:12,  1.47it/s]603it [06:13,  1.52it/s]604it [06:14,  1.54it/s]605it [06:14,  1.57it/s]606it [06:15,  1.58it/s]607it [06:15,  1.59it/s]608it [06:16,  1.60it/s]609it [06:17,  1.61it/s]610it [06:17,  1.62it/s]611it [06:18,  1.61it/s]612it [06:18,  1.62it/s]613it [06:19,  1.62it/s]614it [06:20,  1.62it/s]615it [06:20,  1.62it/s]616it [06:21,  1.62it/s]617it [06:22,  1.62it/s]618it [06:22,  1.62it/s]619it [06:23,  1.62it/s]620it [06:23,  1.62it/s]621it [06:24,  1.62it/s]622it [06:25,  1.62it/s]623it [06:25,  1.63it/s]624it [06:26,  1.63it/s]625it [06:27,  1.63it/s]626it [06:27,  1.62it/s]627it [06:28,  1.62it/s]628it [06:28,  1.62it/s]629it [06:29,  1.62it/s]630it [06:30,  1.62it/s]631it [06:30,  1.63it/s]632it [06:31,  1.62it/s]633it [06:31,  1.62it/s]634it [06:32,  1.62it/s]635it [06:33,  1.62it/s]636it [06:33,  1.62it/s]637it [06:34,  1.62it/s]638it [06:35,  1.63it/s]639it [06:35,  1.62it/s]640it [06:36,  1.62it/s]641it [06:36,  1.63it/s]642it [06:37,  1.62it/s]643it [06:38,  1.62it/s]644it [06:38,  1.62it/s]645it [06:39,  1.62it/s]646it [06:39,  1.62it/s]647it [06:40,  1.62it/s]648it [06:41,  1.62it/s]649it [06:41,  1.62it/s]650it [06:42,  1.61it/s]651it [06:43,  1.61it/s]652it [06:43,  1.61it/s]653it [06:44,  1.61it/s]654it [06:44,  1.62it/s]655it [06:45,  1.62it/s]656it [06:46,  1.62it/s]657it [06:46,  1.62it/s]658it [06:47,  1.63it/s]659it [06:47,  1.62it/s]660it [06:48,  1.63it/s]661it [06:49,  1.63it/s]662it [06:49,  1.63it/s]663it [06:50,  1.63it/s]664it [06:51,  1.63it/s]665it [06:51,  1.62it/s]666it [06:52,  1.62it/s]667it [06:52,  1.62it/s]668it [06:53,  1.63it/s]669it [06:54,  1.62it/s]670it [06:54,  1.63it/s]671it [06:55,  1.63it/s]672it [06:55,  1.63it/s]673it [06:56,  1.63it/s]674it [06:57,  1.63it/s]675it [06:57,  1.63it/s]676it [06:58,  1.63it/s]677it [06:59,  1.63it/s]678it [06:59,  1.63it/s]679it [07:00,  1.63it/s]680it [07:00,  1.63it/s]681it [07:01,  1.62it/s]682it [07:02,  1.63it/s]683it [07:02,  1.62it/s]684it [07:03,  1.62it/s]685it [07:03,  1.62it/s]686it [07:04,  1.62it/s]687it [07:05,  1.62it/s]688it [07:05,  1.62it/s]689it [07:06,  1.62it/s]690it [07:07,  1.62it/s]691it [07:07,  1.62it/s]692it [07:08,  1.62it/s]693it [07:08,  1.62it/s]694it [07:09,  1.62it/s]695it [07:10,  1.62it/s]696it [07:10,  1.62it/s]697it [07:11,  1.62it/s]698it [07:11,  1.63it/s]699it [07:12,  1.62it/s]step: 000700 	 epe: 3.496
Save checkpoint at step: 700
700it [07:13,  1.35it/s]701it [07:14,  1.43it/s]702it [07:14,  1.48it/s]703it [07:15,  1.53it/s]704it [07:16,  1.55it/s]705it [07:16,  1.57it/s]706it [07:17,  1.59it/s]707it [07:17,  1.61it/s]708it [07:18,  1.61it/s]709it [07:19,  1.62it/s]710it [07:19,  1.62it/s]711it [07:20,  1.62it/s]712it [07:21,  1.62it/s]713it [07:21,  1.62it/s]714it [07:22,  1.62it/s]715it [07:22,  1.62it/s]716it [07:23,  1.63it/s]717it [07:24,  1.63it/s]718it [07:24,  1.62it/s]719it [07:25,  1.62it/s]720it [07:25,  1.63it/s]721it [07:26,  1.63it/s]722it [07:27,  1.62it/s]723it [07:27,  1.62it/s]724it [07:28,  1.62it/s]725it [07:29,  1.61it/s]726it [07:29,  1.61it/s]727it [07:30,  1.62it/s]728it [07:30,  1.62it/s]729it [07:31,  1.62it/s]730it [07:32,  1.62it/s]731it [07:32,  1.62it/s]732it [07:33,  1.62it/s]733it [07:33,  1.62it/s]734it [07:34,  1.63it/s]735it [07:35,  1.62it/s]736it [07:35,  1.62it/s]737it [07:36,  1.62it/s]738it [07:37,  1.63it/s]739it [07:37,  1.63it/s]740it [07:38,  1.62it/s]741it [07:38,  1.63it/s]742it [07:39,  1.62it/s]743it [07:40,  1.63it/s]744it [07:40,  1.63it/s]745it [07:41,  1.63it/s]746it [07:41,  1.63it/s]747it [07:42,  1.63it/s]748it [07:43,  1.63it/s]749it [07:43,  1.63it/s]750it [07:44,  1.63it/s]751it [07:45,  1.63it/s]752it [07:45,  1.62it/s]753it [07:46,  1.62it/s]754it [07:46,  1.63it/s]755it [07:47,  1.62it/s]756it [07:48,  1.62it/s]757it [07:48,  1.63it/s]758it [07:49,  1.63it/s]759it [07:49,  1.62it/s]760it [07:50,  1.63it/s]761it [07:51,  1.62it/s]762it [07:51,  1.62it/s]763it [07:52,  1.62it/s]764it [07:53,  1.62it/s]765it [07:53,  1.62it/s]766it [07:54,  1.62it/s]767it [07:54,  1.62it/s]768it [07:55,  1.63it/s]769it [07:56,  1.63it/s]770it [07:56,  1.63it/s]771it [07:57,  1.63it/s]772it [07:57,  1.63it/s]773it [07:58,  1.63it/s]774it [07:59,  1.63it/s]775it [07:59,  1.63it/s]776it [08:00,  1.63it/s]777it [08:00,  1.63it/s]778it [08:01,  1.63it/s]779it [08:02,  1.63it/s]780it [08:02,  1.63it/s]781it [08:03,  1.63it/s]782it [08:04,  1.63it/s]783it [08:04,  1.63it/s]784it [08:05,  1.62it/s]785it [08:05,  1.62it/s]786it [08:06,  1.62it/s]787it [08:07,  1.62it/s]788it [08:07,  1.62it/s]789it [08:08,  1.62it/s]790it [08:08,  1.63it/s]791it [08:09,  1.63it/s]792it [08:10,  1.63it/s]793it [08:10,  1.63it/s]794it [08:11,  1.63it/s]795it [08:12,  1.62it/s]796it [08:12,  1.63it/s]797it [08:13,  1.62it/s]798it [08:13,  1.62it/s]799it [08:14,  1.63it/s]step: 000800 	 epe: 9.369
Save checkpoint at step: 800
800it [08:15,  1.34it/s]801it [08:16,  1.41it/s]802it [08:16,  1.47it/s]803it [08:17,  1.51it/s]804it [08:18,  1.54it/s]805it [08:18,  1.57it/s]806it [08:19,  1.58it/s]807it [08:19,  1.59it/s]808it [08:20,  1.60it/s]809it [08:21,  1.60it/s]810it [08:21,  1.61it/s]811it [08:22,  1.62it/s]812it [08:22,  1.62it/s]813it [08:23,  1.62it/s]814it [08:24,  1.62it/s]815it [08:24,  1.62it/s]816it [08:25,  1.62it/s]817it [08:26,  1.61it/s]818it [08:26,  1.62it/s]819it [08:27,  1.61it/s]820it [08:27,  1.61it/s]821it [08:28,  1.62it/s]822it [08:29,  1.62it/s]823it [08:29,  1.62it/s]824it [08:30,  1.62it/s]825it [08:31,  1.62it/s]826it [08:31,  1.62it/s]827it [08:32,  1.63it/s]828it [08:32,  1.63it/s]829it [08:33,  1.63it/s]830it [08:34,  1.62it/s]831it [08:34,  1.63it/s]832it [08:35,  1.63it/s]833it [08:35,  1.63it/s]834it [08:36,  1.62it/s]835it [08:37,  1.63it/s]836it [08:37,  1.63it/s]837it [08:38,  1.63it/s]838it [08:39,  1.63it/s]839it [08:39,  1.63it/s]840it [08:40,  1.62it/s]841it [08:40,  1.63it/s]842it [08:41,  1.62it/s]843it [08:42,  1.62it/s]844it [08:42,  1.62it/s]845it [08:43,  1.62it/s]846it [08:43,  1.62it/s]847it [08:44,  1.62it/s]848it [08:45,  1.63it/s]849it [08:45,  1.62it/s]850it [08:46,  1.62it/s]851it [08:47,  1.63it/s]852it [08:47,  1.62it/s]853it [08:48,  1.62it/s]854it [08:48,  1.62it/s]855it [08:49,  1.62it/s]856it [08:50,  1.62it/s]857it [08:50,  1.62it/s]858it [08:51,  1.62it/s]859it [08:51,  1.62it/s]860it [08:52,  1.62it/s]861it [08:53,  1.63it/s]862it [08:53,  1.62it/s]863it [08:54,  1.62it/s]864it [08:55,  1.62it/s]865it [08:55,  1.62it/s]866it [08:56,  1.62it/s]867it [08:56,  1.62it/s]868it [08:57,  1.62it/s]869it [08:58,  1.62it/s]870it [08:58,  1.62it/s]871it [08:59,  1.63it/s]872it [08:59,  1.63it/s]873it [09:00,  1.62it/s]874it [09:01,  1.63it/s]875it [09:01,  1.62it/s]876it [09:02,  1.62it/s]877it [09:03,  1.62it/s]878it [09:03,  1.62it/s]879it [09:04,  1.62it/s]880it [09:04,  1.62it/s]881it [09:05,  1.62it/s]882it [09:06,  1.62it/s]883it [09:06,  1.62it/s]884it [09:07,  1.62it/s]885it [09:07,  1.63it/s]886it [09:08,  1.62it/s]887it [09:09,  1.62it/s]888it [09:09,  1.62it/s]889it [09:10,  1.62it/s]890it [09:11,  1.62it/s]891it [09:11,  1.62it/s]892it [09:12,  1.62it/s]893it [09:12,  1.62it/s]894it [09:13,  1.63it/s]895it [09:14,  1.62it/s]896it [09:14,  1.62it/s]897it [09:15,  1.62it/s]898it [09:15,  1.62it/s]899it [09:16,  1.62it/s]step: 000900 	 epe: 6.273
Save checkpoint at step: 900
900it [09:17,  1.34it/s]901it [09:18,  1.42it/s]902it [09:18,  1.48it/s]903it [09:19,  1.52it/s]904it [09:20,  1.55it/s]905it [09:20,  1.58it/s]906it [09:21,  1.60it/s]907it [09:21,  1.61it/s]908it [09:22,  1.61it/s]909it [09:23,  1.62it/s]910it [09:23,  1.63it/s]911it [09:24,  1.63it/s]912it [09:25,  1.63it/s]913it [09:25,  1.63it/s]914it [09:26,  1.63it/s]915it [09:26,  1.63it/s]916it [09:27,  1.62it/s]917it [09:28,  1.63it/s]918it [09:28,  1.62it/s]919it [09:29,  1.62it/s]920it [09:29,  1.63it/s]921it [09:30,  1.62it/s]922it [09:31,  1.62it/s]923it [09:31,  1.62it/s]924it [09:32,  1.62it/s]925it [09:33,  1.62it/s]926it [09:33,  1.62it/s]927it [09:34,  1.62it/s]928it [09:34,  1.62it/s]929it [09:35,  1.62it/s]930it [09:36,  1.62it/s]931it [09:36,  1.62it/s]932it [09:37,  1.62it/s]933it [09:37,  1.62it/s]934it [09:38,  1.62it/s]935it [09:39,  1.62it/s]936it [09:39,  1.62it/s]937it [09:40,  1.62it/s]938it [09:41,  1.62it/s]939it [09:41,  1.62it/s]940it [09:42,  1.62it/s]941it [09:42,  1.62it/s]942it [09:43,  1.62it/s]943it [09:44,  1.62it/s]944it [09:44,  1.63it/s]945it [09:45,  1.63it/s]946it [09:45,  1.62it/s]947it [09:46,  1.62it/s]948it [09:47,  1.62it/s]949it [09:47,  1.63it/s]950it [09:48,  1.63it/s]951it [09:49,  1.63it/s]952it [09:49,  1.63it/s]953it [09:50,  1.63it/s]954it [09:50,  1.63it/s]955it [09:51,  1.63it/s]956it [09:52,  1.63it/s]957it [09:52,  1.63it/s]958it [09:53,  1.62it/s]959it [09:53,  1.62it/s]960it [09:54,  1.62it/s]961it [09:55,  1.62it/s]962it [09:55,  1.61it/s]963it [09:56,  1.62it/s]964it [09:57,  1.62it/s]965it [09:57,  1.62it/s]966it [09:58,  1.63it/s]967it [09:58,  1.62it/s]968it [09:59,  1.62it/s]969it [10:00,  1.62it/s]970it [10:00,  1.62it/s]971it [10:01,  1.62it/s]972it [10:01,  1.62it/s]973it [10:02,  1.62it/s]974it [10:03,  1.62it/s]975it [10:03,  1.61it/s]976it [10:04,  1.62it/s]977it [10:05,  1.61it/s]978it [10:05,  1.62it/s]979it [10:06,  1.62it/s]980it [10:06,  1.62it/s]981it [10:07,  1.62it/s]982it [10:08,  1.62it/s]983it [10:08,  1.62it/s]984it [10:09,  1.62it/s]985it [10:10,  1.62it/s]986it [10:10,  1.62it/s]987it [10:11,  1.62it/s]988it [10:11,  1.62it/s]989it [10:12,  1.62it/s]990it [10:13,  1.62it/s]991it [10:13,  1.63it/s]992it [10:14,  1.63it/s]993it [10:14,  1.63it/s]994it [10:15,  1.63it/s]995it [10:16,  1.63it/s]996it [10:16,  1.63it/s]997it [10:17,  1.63it/s]998it [10:17,  1.63it/s]999it [10:18,  1.63it/s]step: 001000 	 epe: 3.126
Save checkpoint at step: 1000
1000it [10:19,  1.35it/s]1001it [10:20,  1.43it/s]1002it [10:20,  1.48it/s]1003it [10:21,  1.52it/s]1004it [10:22,  1.56it/s]1005it [10:22,  1.57it/s]1006it [10:23,  1.59it/s]1007it [10:23,  1.60it/s]1008it [10:24,  1.61it/s]1009it [10:25,  1.61it/s]1010it [10:25,  1.62it/s]1011it [10:26,  1.62it/s]1012it [10:27,  1.62it/s]1013it [10:27,  1.62it/s]1014it [10:28,  1.62it/s]1015it [10:28,  1.62it/s]1016it [10:29,  1.62it/s]1017it [10:30,  1.62it/s]1018it [10:30,  1.62it/s]1019it [10:31,  1.62it/s]1020it [10:31,  1.62it/s]1021it [10:32,  1.63it/s]1022it [10:33,  1.63it/s]1023it [10:33,  1.63it/s]1024it [10:34,  1.63it/s]1025it [10:35,  1.63it/s]1026it [10:35,  1.63it/s]1027it [10:36,  1.63it/s]1028it [10:36,  1.63it/s]1029it [10:37,  1.63it/s]1030it [10:38,  1.62it/s]1031it [10:38,  1.63it/s]1032it [10:39,  1.63it/s]1033it [10:39,  1.62it/s]1034it [10:40,  1.62it/s]1035it [10:41,  1.62it/s]1036it [10:41,  1.63it/s]1037it [10:42,  1.63it/s]1038it [10:42,  1.63it/s]1039it [10:43,  1.63it/s]1040it [10:44,  1.63it/s]1041it [10:44,  1.63it/s]1042it [10:45,  1.62it/s]1043it [10:46,  1.62it/s]1044it [10:46,  1.61it/s]1045it [10:47,  1.62it/s]1046it [10:47,  1.62it/s]1047it [10:48,  1.62it/s]1048it [10:49,  1.62it/s]1049it [10:49,  1.62it/s]1050it [10:50,  1.62it/s]1051it [10:51,  1.62it/s]1052it [10:51,  1.63it/s]1053it [10:52,  1.62it/s]1054it [10:52,  1.62it/s]1055it [10:53,  1.62it/s]1056it [10:54,  1.63it/s]1057it [10:54,  1.63it/s]1058it [10:55,  1.63it/s]1059it [10:55,  1.63it/s]1060it [10:56,  1.63it/s]1061it [10:57,  1.62it/s]1062it [10:57,  1.62it/s]1063it [10:58,  1.62it/s]1064it [10:59,  1.62it/s]1065it [10:59,  1.63it/s]1066it [11:00,  1.61it/s]1067it [11:00,  1.60it/s]1068it [11:01,  1.61it/s]1069it [11:02,  1.62it/s]1070it [11:02,  1.61it/s]1071it [11:03,  1.61it/s]1072it [11:03,  1.62it/s]1073it [11:04,  1.62it/s]1074it [11:05,  1.62it/s]1075it [11:05,  1.58it/s]1076it [11:06,  1.59it/s]1077it [11:07,  1.60it/s]1078it [11:07,  1.60it/s]1079it [11:08,  1.60it/s]1080it [11:08,  1.60it/s]1081it [11:09,  1.61it/s]1082it [11:10,  1.61it/s]1083it [11:10,  1.62it/s]1084it [11:11,  1.63it/s]1085it [11:12,  1.62it/s]1086it [11:12,  1.62it/s]1087it [11:13,  1.62it/s]1088it [11:13,  1.62it/s]1089it [11:14,  1.62it/s]1090it [11:15,  1.62it/s]1091it [11:15,  1.62it/s]1092it [11:16,  1.57it/s]1093it [11:17,  1.58it/s]1094it [11:17,  1.60it/s]1095it [11:18,  1.60it/s]1096it [11:18,  1.57it/s]1097it [11:19,  1.54it/s]1098it [11:20,  1.56it/s]1099it [11:20,  1.58it/s]step: 001100 	 epe: 2.836
Save checkpoint at step: 1100
1100it [11:21,  1.33it/s]1101it [11:22,  1.41it/s]1102it [11:23,  1.45it/s]1103it [11:23,  1.49it/s]1104it [11:24,  1.53it/s]1105it [11:25,  1.55it/s]1106it [11:25,  1.57it/s]1107it [11:26,  1.54it/s]1108it [11:27,  1.52it/s]1109it [11:27,  1.55it/s]1110it [11:28,  1.57it/s]1111it [11:28,  1.58it/s]1112it [11:29,  1.59it/s]1113it [11:30,  1.60it/s]1114it [11:30,  1.61it/s]1115it [11:31,  1.61it/s]1116it [11:31,  1.62it/s]1117it [11:32,  1.62it/s]1118it [11:33,  1.62it/s]1119it [11:33,  1.61it/s]1120it [11:34,  1.62it/s]1121it [11:35,  1.61it/s]1122it [11:35,  1.62it/s]1123it [11:36,  1.62it/s]1124it [11:36,  1.61it/s]1125it [11:37,  1.62it/s]1126it [11:38,  1.62it/s]1127it [11:38,  1.61it/s]1128it [11:39,  1.61it/s]1129it [11:40,  1.58it/s]1130it [11:40,  1.58it/s]1131it [11:41,  1.59it/s]1132it [11:41,  1.60it/s]1133it [11:42,  1.60it/s]1134it [11:43,  1.60it/s]1135it [11:43,  1.61it/s]1136it [11:44,  1.61it/s]1137it [11:44,  1.61it/s]1138it [11:45,  1.61it/s]1139it [11:46,  1.60it/s]1140it [11:46,  1.60it/s]1141it [11:47,  1.61it/s]1142it [11:48,  1.61it/s]1143it [11:48,  1.57it/s]1144it [11:49,  1.58it/s]1145it [11:50,  1.59it/s]1146it [11:50,  1.60it/s]1147it [11:51,  1.60it/s]1148it [11:51,  1.56it/s]1149it [11:52,  1.57it/s]1150it [11:53,  1.58it/s]1151it [11:53,  1.59it/s]1152it [11:54,  1.60it/s]1153it [11:55,  1.60it/s]1154it [11:55,  1.61it/s]1155it [11:56,  1.61it/s]1156it [11:56,  1.61it/s]1157it [11:57,  1.61it/s]1158it [11:58,  1.58it/s]1159it [11:58,  1.59it/s]1160it [11:59,  1.60it/s]1161it [12:00,  1.61it/s]1162it [12:00,  1.59it/s]1163it [12:01,  1.60it/s]1164it [12:01,  1.60it/s]1165it [12:02,  1.60it/s]1166it [12:03,  1.61it/s]1167it [12:03,  1.61it/s]1168it [12:04,  1.61it/s]1169it [12:05,  1.61it/s]1170it [12:05,  1.62it/s]1171it [12:06,  1.58it/s]1172it [12:06,  1.59it/s]1173it [12:07,  1.60it/s]1174it [12:08,  1.60it/s]1175it [12:08,  1.61it/s]1176it [12:09,  1.61it/s]1177it [12:10,  1.61it/s]1178it [12:10,  1.61it/s]1179it [12:11,  1.62it/s]1180it [12:11,  1.62it/s]1181it [12:12,  1.62it/s]1182it [12:13,  1.62it/s]1183it [12:13,  1.62it/s]1184it [12:14,  1.61it/s]1185it [12:14,  1.61it/s]1186it [12:15,  1.62it/s]1187it [12:16,  1.62it/s]1188it [12:16,  1.61it/s]1189it [12:17,  1.62it/s]1190it [12:18,  1.62it/s]1191it [12:18,  1.62it/s]1192it [12:19,  1.62it/s]1193it [12:19,  1.62it/s]1194it [12:20,  1.62it/s]1195it [12:21,  1.62it/s]1196it [12:21,  1.62it/s]1197it [12:22,  1.62it/s]1198it [12:23,  1.56it/s]1199it [12:23,  1.58it/s]step: 001200 	 epe: 7.999
Save checkpoint at step: 1200
1200it [12:24,  1.31it/s]1201it [12:25,  1.39it/s]1202it [12:25,  1.45it/s]1203it [12:26,  1.50it/s]1204it [12:27,  1.53it/s]1205it [12:27,  1.56it/s]1206it [12:28,  1.58it/s]1207it [12:29,  1.59it/s]1208it [12:29,  1.60it/s]1209it [12:30,  1.60it/s]1210it [12:30,  1.61it/s]1211it [12:31,  1.61it/s]1212it [12:32,  1.61it/s]1213it [12:32,  1.60it/s]1214it [12:33,  1.61it/s]1215it [12:34,  1.61it/s]1216it [12:34,  1.61it/s]1217it [12:35,  1.61it/s]1218it [12:35,  1.61it/s]1219it [12:36,  1.58it/s]1220it [12:37,  1.59it/s]1221it [12:37,  1.60it/s]1222it [12:38,  1.60it/s]1223it [12:39,  1.59it/s]1224it [12:39,  1.60it/s]1225it [12:40,  1.60it/s]1226it [12:40,  1.59it/s]1227it [12:41,  1.61it/s]1228it [12:42,  1.61it/s]1229it [12:42,  1.61it/s]1230it [12:43,  1.61it/s]1231it [12:44,  1.61it/s]1232it [12:44,  1.61it/s]1233it [12:45,  1.61it/s]1234it [12:45,  1.61it/s]1235it [12:46,  1.62it/s]1236it [12:47,  1.61it/s]1237it [12:47,  1.61it/s]1238it [12:48,  1.61it/s]1239it [12:48,  1.61it/s]1240it [12:49,  1.61it/s]1241it [12:50,  1.61it/s]1242it [12:50,  1.61it/s]1243it [12:51,  1.61it/s]1244it [12:52,  1.61it/s]1245it [12:52,  1.61it/s]1246it [12:53,  1.62it/s]1247it [12:53,  1.61it/s]1248it [12:54,  1.61it/s]1249it [12:55,  1.62it/s]1250it [12:55,  1.62it/s]1251it [12:56,  1.62it/s]1252it [12:57,  1.63it/s]1253it [12:57,  1.62it/s]1254it [12:58,  1.62it/s]1255it [12:58,  1.62it/s]1256it [12:59,  1.62it/s]1257it [13:00,  1.59it/s]1258it [13:00,  1.60it/s]1259it [13:01,  1.61it/s]1260it [13:01,  1.61it/s]1261it [13:02,  1.62it/s]1262it [13:03,  1.62it/s]1263it [13:03,  1.62it/s]1264it [13:04,  1.57it/s]1265it [13:05,  1.58it/s]1266it [13:05,  1.60it/s]1267it [13:06,  1.60it/s]1268it [13:06,  1.61it/s]1269it [13:07,  1.61it/s]1270it [13:08,  1.60it/s]1271it [13:08,  1.61it/s]1272it [13:09,  1.61it/s]1273it [13:10,  1.61it/s]1274it [13:10,  1.62it/s]1275it [13:11,  1.61it/s]1276it [13:11,  1.61it/s]1277it [13:12,  1.62it/s]1278it [13:13,  1.57it/s]1279it [13:13,  1.59it/s]1280it [13:14,  1.60it/s]1281it [13:15,  1.61it/s]1282it [13:15,  1.60it/s]1283it [13:16,  1.61it/s]1284it [13:16,  1.61it/s]1285it [13:17,  1.61it/s]1286it [13:18,  1.62it/s]1287it [13:18,  1.62it/s]1288it [13:19,  1.61it/s]1289it [13:20,  1.62it/s]1290it [13:20,  1.61it/s]1291it [13:21,  1.62it/s]1292it [13:21,  1.62it/s]1293it [13:22,  1.63it/s]1294it [13:23,  1.63it/s]1295it [13:23,  1.62it/s]1296it [13:24,  1.63it/s]1297it [13:24,  1.63it/s]1298it [13:25,  1.62it/s]1299it [13:26,  1.63it/s]step: 001300 	 epe: 2.020
Save checkpoint at step: 1300
1300it [13:27,  1.32it/s]1301it [13:27,  1.40it/s]1302it [13:28,  1.46it/s]1303it [13:29,  1.51it/s]1304it [13:29,  1.54it/s]1305it [13:30,  1.56it/s]1306it [13:30,  1.58it/s]1307it [13:31,  1.59it/s]1308it [13:32,  1.60it/s]1309it [13:32,  1.60it/s]1310it [13:33,  1.57it/s]1311it [13:34,  1.58it/s]1312it [13:34,  1.60it/s]1313it [13:35,  1.61it/s]1314it [13:35,  1.61it/s]1315it [13:36,  1.62it/s]1316it [13:37,  1.62it/s]1317it [13:37,  1.62it/s]1318it [13:38,  1.62it/s]1319it [13:39,  1.62it/s]1320it [13:39,  1.62it/s]1321it [13:40,  1.62it/s]1322it [13:40,  1.62it/s]1323it [13:41,  1.63it/s]1324it [13:42,  1.63it/s]1325it [13:42,  1.63it/s]1326it [13:43,  1.63it/s]1327it [13:43,  1.63it/s]1328it [13:44,  1.63it/s]1329it [13:45,  1.63it/s]1330it [13:45,  1.63it/s]1331it [13:46,  1.63it/s]1332it [13:47,  1.62it/s]1333it [13:47,  1.62it/s]1334it [13:48,  1.62it/s]1335it [13:48,  1.62it/s]1336it [13:49,  1.62it/s]1337it [13:50,  1.62it/s]1338it [13:50,  1.62it/s]1339it [13:51,  1.62it/s]1340it [13:51,  1.62it/s]1341it [13:52,  1.62it/s]1342it [13:53,  1.62it/s]1343it [13:53,  1.63it/s]1344it [13:54,  1.63it/s]1345it [13:55,  1.62it/s]1346it [13:55,  1.63it/s]1347it [13:56,  1.63it/s]1348it [13:56,  1.63it/s]1349it [13:57,  1.62it/s]1350it [13:58,  1.62it/s]1351it [13:58,  1.62it/s]1352it [13:59,  1.62it/s]1353it [13:59,  1.62it/s]1354it [14:00,  1.63it/s]1355it [14:01,  1.63it/s]1356it [14:01,  1.63it/s]1357it [14:02,  1.63it/s]1358it [14:03,  1.63it/s]1359it [14:03,  1.63it/s]1360it [14:04,  1.62it/s]1361it [14:04,  1.62it/s]1362it [14:05,  1.63it/s]1363it [14:06,  1.63it/s]1364it [14:06,  1.63it/s]1365it [14:07,  1.63it/s]1366it [14:07,  1.63it/s]1367it [14:08,  1.62it/s]1368it [14:09,  1.62it/s]1369it [14:09,  1.62it/s]1370it [14:10,  1.62it/s]1371it [14:11,  1.63it/s]1372it [14:11,  1.62it/s]1373it [14:12,  1.63it/s]1374it [14:12,  1.63it/s]1375it [14:13,  1.63it/s]1376it [14:14,  1.63it/s]1377it [14:14,  1.63it/s]1378it [14:15,  1.63it/s]1379it [14:15,  1.63it/s]1380it [14:16,  1.63it/s]1381it [14:17,  1.63it/s]1382it [14:17,  1.63it/s]1383it [14:18,  1.63it/s]1384it [14:19,  1.63it/s]1385it [14:19,  1.64it/s]1386it [14:20,  1.63it/s]1387it [14:20,  1.63it/s]1388it [14:21,  1.63it/s]1389it [14:22,  1.63it/s]1390it [14:22,  1.63it/s]1391it [14:23,  1.63it/s]1392it [14:23,  1.63it/s]1393it [14:24,  1.63it/s]1394it [14:25,  1.63it/s]1395it [14:25,  1.62it/s]1396it [14:26,  1.59it/s]1397it [14:27,  1.60it/s]1398it [14:27,  1.61it/s]1399it [14:28,  1.61it/s]step: 001400 	 epe: 7.390
Save checkpoint at step: 1400
1400it [14:29,  1.33it/s]1401it [14:30,  1.36it/s]1402it [14:30,  1.44it/s]1403it [14:31,  1.49it/s]1404it [14:31,  1.53it/s]1405it [14:32,  1.56it/s]1406it [14:33,  1.58it/s]1407it [14:33,  1.59it/s]1408it [14:34,  1.61it/s]1409it [14:34,  1.61it/s]1410it [14:35,  1.61it/s]1411it [14:36,  1.62it/s]1412it [14:36,  1.61it/s]1413it [14:37,  1.62it/s]1414it [14:38,  1.62it/s]1415it [14:38,  1.62it/s]1416it [14:39,  1.62it/s]1417it [14:39,  1.62it/s]1418it [14:40,  1.62it/s]1419it [14:41,  1.63it/s]1420it [14:41,  1.63it/s]1421it [14:42,  1.63it/s]1422it [14:42,  1.63it/s]1423it [14:43,  1.64it/s]1424it [14:44,  1.63it/s]1425it [14:44,  1.63it/s]1426it [14:45,  1.63it/s]1427it [14:45,  1.63it/s]1428it [14:46,  1.63it/s]1429it [14:47,  1.62it/s]1430it [14:47,  1.62it/s]1431it [14:48,  1.62it/s]1432it [14:49,  1.62it/s]1433it [14:49,  1.62it/s]1434it [14:50,  1.62it/s]1435it [14:50,  1.62it/s]1436it [14:51,  1.62it/s]1437it [14:52,  1.63it/s]1438it [14:52,  1.63it/s]1439it [14:53,  1.63it/s]1440it [14:53,  1.62it/s]1441it [14:54,  1.62it/s]1442it [14:55,  1.63it/s]1443it [14:55,  1.62it/s]1444it [14:56,  1.62it/s]1445it [14:57,  1.63it/s]1446it [14:57,  1.63it/s]1447it [14:58,  1.62it/s]1448it [14:58,  1.63it/s]1449it [14:59,  1.63it/s]1450it [15:00,  1.63it/s]1451it [15:00,  1.63it/s]1452it [15:01,  1.63it/s]1453it [15:01,  1.63it/s]1454it [15:02,  1.63it/s]1455it [15:03,  1.62it/s]1456it [15:03,  1.62it/s]1457it [15:04,  1.62it/s]1458it [15:05,  1.62it/s]1459it [15:05,  1.63it/s]1460it [15:06,  1.62it/s]1461it [15:06,  1.62it/s]1462it [15:07,  1.63it/s]1463it [15:08,  1.62it/s]1464it [15:08,  1.62it/s]1465it [15:09,  1.62it/s]1466it [15:09,  1.62it/s]1467it [15:10,  1.62it/s]1468it [15:11,  1.63it/s]1469it [15:11,  1.62it/s]1470it [15:12,  1.62it/s]1471it [15:13,  1.62it/s]1472it [15:13,  1.63it/s]1473it [15:14,  1.63it/s]1474it [15:14,  1.63it/s]1475it [15:15,  1.64it/s]1476it [15:16,  1.64it/s]1477it [15:16,  1.64it/s]1478it [15:17,  1.64it/s]1479it [15:17,  1.64it/s]1480it [15:18,  1.64it/s]1481it [15:19,  1.63it/s]1482it [15:19,  1.63it/s]1483it [15:20,  1.62it/s]1484it [15:21,  1.63it/s]1485it [15:21,  1.62it/s]1486it [15:22,  1.62it/s]1487it [15:22,  1.62it/s]1488it [15:23,  1.62it/s]1489it [15:24,  1.62it/s]1490it [15:24,  1.62it/s]1491it [15:25,  1.62it/s]1492it [15:25,  1.63it/s]1493it [15:26,  1.63it/s]1494it [15:27,  1.62it/s]1495it [15:27,  1.62it/s]1496it [15:28,  1.62it/s]1497it [15:29,  1.62it/s]1498it [15:29,  1.62it/s]1499it [15:30,  1.62it/s]step: 001500 	 epe: 2.780
Save checkpoint at step: 1500
1500it [15:31,  1.35it/s]1501it [15:31,  1.43it/s]1502it [15:32,  1.48it/s]1503it [15:33,  1.53it/s]1504it [15:33,  1.56it/s]1505it [15:34,  1.58it/s]1506it [15:34,  1.60it/s]1507it [15:35,  1.61it/s]1508it [15:36,  1.62it/s]1509it [15:36,  1.63it/s]1510it [15:37,  1.63it/s]1511it [15:38,  1.63it/s]1512it [15:38,  1.63it/s]1513it [15:39,  1.63it/s]1514it [15:39,  1.62it/s]1515it [15:40,  1.62it/s]1516it [15:41,  1.63it/s]1517it [15:41,  1.63it/s]1518it [15:42,  1.63it/s]1519it [15:42,  1.63it/s]1520it [15:43,  1.63it/s]1521it [15:44,  1.63it/s]1522it [15:44,  1.63it/s]1523it [15:45,  1.63it/s]1524it [15:46,  1.63it/s]1525it [15:46,  1.63it/s]1526it [15:47,  1.62it/s]1527it [15:47,  1.63it/s]1528it [15:48,  1.63it/s]1529it [15:49,  1.62it/s]1530it [15:49,  1.63it/s]1531it [15:50,  1.63it/s]1532it [15:50,  1.63it/s]1533it [15:51,  1.64it/s]1534it [15:52,  1.64it/s]1535it [15:52,  1.64it/s]1536it [15:53,  1.64it/s]1537it [15:53,  1.64it/s]1538it [15:54,  1.63it/s]1539it [15:55,  1.63it/s]1540it [15:55,  1.63it/s]1541it [15:56,  1.63it/s]1542it [15:57,  1.63it/s]1543it [15:57,  1.62it/s]1544it [15:58,  1.63it/s]1545it [15:58,  1.63it/s]1546it [15:59,  1.63it/s]1547it [16:00,  1.63it/s]1548it [16:00,  1.63it/s]1549it [16:01,  1.63it/s]1550it [16:01,  1.64it/s]1551it [16:02,  1.64it/s]1552it [16:03,  1.63it/s]1553it [16:03,  1.63it/s]1554it [16:04,  1.63it/s]1555it [16:04,  1.63it/s]1556it [16:05,  1.63it/s]1557it [16:06,  1.64it/s]1558it [16:06,  1.64it/s]1559it [16:07,  1.64it/s]1560it [16:08,  1.64it/s]1561it [16:08,  1.64it/s]1562it [16:09,  1.63it/s]1563it [16:09,  1.63it/s]1564it [16:10,  1.63it/s]1565it [16:11,  1.63it/s]1566it [16:11,  1.63it/s]1567it [16:12,  1.63it/s]1568it [16:12,  1.63it/s]1569it [16:13,  1.63it/s]1570it [16:14,  1.63it/s]1571it [16:14,  1.63it/s]1572it [16:15,  1.63it/s]1573it [16:16,  1.62it/s]1574it [16:16,  1.63it/s]1575it [16:17,  1.64it/s]1576it [16:17,  1.63it/s]1577it [16:18,  1.63it/s]1578it [16:19,  1.62it/s]1579it [16:19,  1.63it/s]1580it [16:20,  1.62it/s]1581it [16:20,  1.62it/s]1582it [16:21,  1.63it/s]1583it [16:22,  1.62it/s]1584it [16:22,  1.62it/s]1585it [16:23,  1.63it/s]1586it [16:24,  1.62it/s]1587it [16:24,  1.62it/s]1588it [16:25,  1.63it/s]1589it [16:25,  1.63it/s]1590it [16:26,  1.62it/s]1591it [16:27,  1.63it/s]1592it [16:27,  1.63it/s]1593it [16:28,  1.63it/s]1594it [16:28,  1.63it/s]1595it [16:29,  1.63it/s]1596it [16:30,  1.63it/s]1597it [16:30,  1.63it/s]1598it [16:31,  1.63it/s]1599it [16:32,  1.63it/s]step: 001600 	 epe: 4.175
Save checkpoint at step: 1600
1600it [16:33,  1.33it/s]1601it [16:33,  1.41it/s]1602it [16:34,  1.46it/s]1603it [16:34,  1.51it/s]1604it [16:35,  1.54it/s]1605it [16:36,  1.56it/s]1606it [16:36,  1.57it/s]1607it [16:37,  1.58it/s]1608it [16:38,  1.59it/s]1609it [16:38,  1.60it/s]1610it [16:39,  1.61it/s]1611it [16:39,  1.61it/s]1612it [16:40,  1.62it/s]1613it [16:41,  1.62it/s]1614it [16:41,  1.62it/s]1615it [16:42,  1.63it/s]1616it [16:42,  1.63it/s]1617it [16:43,  1.63it/s]1618it [16:44,  1.63it/s]1619it [16:44,  1.63it/s]1620it [16:45,  1.64it/s]1621it [16:46,  1.63it/s]1622it [16:46,  1.63it/s]1623it [16:47,  1.63it/s]1624it [16:47,  1.63it/s]1625it [16:48,  1.64it/s]1626it [16:49,  1.64it/s]1627it [16:49,  1.63it/s]1628it [16:50,  1.63it/s]1629it [16:50,  1.63it/s]1630it [16:51,  1.63it/s]1631it [16:52,  1.63it/s]1632it [16:52,  1.63it/s]1633it [16:53,  1.63it/s]1634it [16:53,  1.63it/s]1635it [16:54,  1.63it/s]1636it [16:55,  1.63it/s]1637it [16:55,  1.63it/s]1638it [16:56,  1.63it/s]1639it [16:57,  1.63it/s]1640it [16:57,  1.63it/s]1641it [16:58,  1.63it/s]1642it [16:58,  1.63it/s]1643it [16:59,  1.63it/s]1644it [17:00,  1.62it/s]1645it [17:00,  1.62it/s]1646it [17:01,  1.63it/s]1647it [17:01,  1.63it/s]1648it [17:02,  1.62it/s]1649it [17:03,  1.62it/s]1650it [17:03,  1.62it/s]1651it [17:04,  1.62it/s]1652it [17:05,  1.62it/s]1653it [17:05,  1.63it/s]1654it [17:06,  1.62it/s]1655it [17:06,  1.62it/s]1656it [17:07,  1.62it/s]1657it [17:08,  1.62it/s]1658it [17:08,  1.63it/s]1659it [17:09,  1.63it/s]1660it [17:09,  1.62it/s]1661it [17:10,  1.63it/s]1662it [17:11,  1.63it/s]1663it [17:11,  1.62it/s]1664it [17:12,  1.62it/s]1665it [17:13,  1.63it/s]1666it [17:13,  1.63it/s]1667it [17:14,  1.62it/s]1668it [17:14,  1.62it/s]1669it [17:15,  1.63it/s]1670it [17:16,  1.62it/s]1671it [17:16,  1.62it/s]1672it [17:17,  1.62it/s]1673it [17:17,  1.62it/s]1674it [17:18,  1.62it/s]1675it [17:19,  1.62it/s]1676it [17:19,  1.62it/s]1677it [17:20,  1.62it/s]1678it [17:21,  1.63it/s]1679it [17:21,  1.62it/s]1680it [17:22,  1.63it/s]1681it [17:22,  1.62it/s]1682it [17:23,  1.62it/s]1683it [17:24,  1.63it/s]1684it [17:24,  1.62it/s]1685it [17:25,  1.62it/s]1686it [17:26,  1.62it/s]1687it [17:26,  1.62it/s]1688it [17:27,  1.62it/s]1689it [17:27,  1.62it/s]1690it [17:28,  1.63it/s]1691it [17:29,  1.63it/s]1692it [17:29,  1.63it/s]1693it [17:30,  1.63it/s]1694it [17:30,  1.63it/s]1695it [17:31,  1.62it/s]1696it [17:32,  1.63it/s]1697it [17:32,  1.63it/s]1698it [17:33,  1.63it/s]1699it [17:33,  1.62it/s]step: 001700 	 epe: 5.207
Save checkpoint at step: 1700
1700it [17:35,  1.34it/s]1701it [17:35,  1.42it/s]1702it [17:36,  1.48it/s]1703it [17:36,  1.52it/s]1704it [17:37,  1.55it/s]1705it [17:38,  1.58it/s]1706it [17:38,  1.59it/s]1707it [17:39,  1.60it/s]1708it [17:39,  1.62it/s]1709it [17:40,  1.62it/s]1710it [17:41,  1.62it/s]1711it [17:41,  1.63it/s]1712it [17:42,  1.63it/s]1713it [17:42,  1.63it/s]1714it [17:43,  1.64it/s]1715it [17:44,  1.64it/s]1716it [17:44,  1.63it/s]1717it [17:45,  1.63it/s]1718it [17:46,  1.63it/s]1719it [17:46,  1.62it/s]1720it [17:47,  1.62it/s]1721it [17:47,  1.63it/s]1722it [17:48,  1.63it/s]1723it [17:49,  1.63it/s]1724it [17:49,  1.63it/s]1725it [17:50,  1.63it/s]1726it [17:50,  1.63it/s]1727it [17:51,  1.63it/s]1728it [17:52,  1.63it/s]1729it [17:52,  1.63it/s]1730it [17:53,  1.63it/s]1731it [17:54,  1.63it/s]1732it [17:54,  1.63it/s]1733it [17:55,  1.63it/s]1734it [17:55,  1.63it/s]1735it [17:56,  1.63it/s]1736it [17:57,  1.63it/s]1737it [17:57,  1.63it/s]1738it [17:58,  1.63it/s]1739it [17:58,  1.63it/s]1740it [17:59,  1.63it/s]1741it [18:00,  1.62it/s]1742it [18:00,  1.63it/s]1743it [18:01,  1.63it/s]1744it [18:02,  1.63it/s]1745it [18:02,  1.63it/s]1746it [18:03,  1.63it/s]1747it [18:03,  1.63it/s]1748it [18:04,  1.62it/s]1749it [18:05,  1.62it/s]1750it [18:05,  1.63it/s]1751it [18:06,  1.63it/s]1752it [18:06,  1.63it/s]1753it [18:07,  1.63it/s]1754it [18:08,  1.62it/s]1755it [18:08,  1.62it/s]1756it [18:09,  1.63it/s]1757it [18:09,  1.63it/s]1758it [18:10,  1.63it/s]1759it [18:11,  1.64it/s]1760it [18:11,  1.64it/s]1761it [18:12,  1.64it/s]1762it [18:13,  1.64it/s]1763it [18:13,  1.64it/s]1764it [18:14,  1.64it/s]1765it [18:14,  1.64it/s]1766it [18:15,  1.64it/s]1767it [18:16,  1.64it/s]1768it [18:16,  1.63it/s]1769it [18:17,  1.63it/s]1770it [18:17,  1.62it/s]1771it [18:18,  1.62it/s]1772it [18:19,  1.62it/s]1773it [18:19,  1.63it/s]1774it [18:20,  1.63it/s]1775it [18:21,  1.63it/s]1776it [18:21,  1.63it/s]1777it [18:22,  1.63it/s]1778it [18:22,  1.63it/s]1779it [18:23,  1.63it/s]1780it [18:24,  1.63it/s]1781it [18:24,  1.63it/s]1782it [18:25,  1.63it/s]1783it [18:25,  1.63it/s]1784it [18:26,  1.63it/s]1785it [18:27,  1.63it/s]1786it [18:27,  1.63it/s]1787it [18:28,  1.62it/s]1788it [18:29,  1.62it/s]1789it [18:29,  1.62it/s]1790it [18:30,  1.62it/s]1791it [18:30,  1.63it/s]1792it [18:31,  1.62it/s]1793it [18:32,  1.62it/s]1794it [18:32,  1.63it/s]1795it [18:33,  1.63it/s]1796it [18:33,  1.63it/s]1797it [18:34,  1.62it/s]1798it [18:35,  1.63it/s]1799it [18:35,  1.63it/s]step: 001800 	 epe: 3.811
Save checkpoint at step: 1800
1800it [18:36,  1.35it/s]1801it [18:37,  1.43it/s]1802it [18:38,  1.48it/s]1803it [18:38,  1.52it/s]1804it [18:39,  1.55it/s]1805it [18:39,  1.58it/s]1806it [18:40,  1.59it/s]1807it [18:41,  1.60it/s]1808it [18:41,  1.61it/s]1809it [18:42,  1.62it/s]1810it [18:42,  1.62it/s]1811it [18:43,  1.62it/s]1812it [18:44,  1.62it/s]1813it [18:44,  1.62it/s]1814it [18:45,  1.62it/s]1815it [18:46,  1.62it/s]1816it [18:46,  1.62it/s]1817it [18:47,  1.62it/s]1818it [18:47,  1.62it/s]1819it [18:48,  1.62it/s]1820it [18:49,  1.62it/s]1821it [18:49,  1.62it/s]1822it [18:50,  1.62it/s]1823it [18:50,  1.62it/s]1824it [18:51,  1.63it/s]1825it [18:52,  1.62it/s]1826it [18:52,  1.62it/s]1827it [18:53,  1.63it/s]1828it [18:54,  1.63it/s]1829it [18:54,  1.62it/s]1830it [18:55,  1.62it/s]1831it [18:55,  1.62it/s]1832it [18:56,  1.62it/s]1833it [18:57,  1.62it/s]1834it [18:57,  1.62it/s]1835it [18:58,  1.62it/s]1836it [18:58,  1.62it/s]1837it [18:59,  1.62it/s]1838it [19:00,  1.62it/s]1839it [19:00,  1.62it/s]1840it [19:01,  1.62it/s]1841it [19:02,  1.62it/s]1842it [19:02,  1.62it/s]1843it [19:03,  1.62it/s]1844it [19:03,  1.63it/s]1845it [19:04,  1.62it/s]1846it [19:05,  1.62it/s]1847it [19:05,  1.63it/s]1848it [19:06,  1.62it/s]1849it [19:06,  1.63it/s]1850it [19:07,  1.63it/s]1851it [19:08,  1.63it/s]1852it [19:08,  1.63it/s]1853it [19:09,  1.63it/s]1854it [19:10,  1.63it/s]1855it [19:10,  1.62it/s]1856it [19:11,  1.62it/s]1857it [19:11,  1.62it/s]1858it [19:12,  1.62it/s]1859it [19:13,  1.62it/s]1860it [19:13,  1.63it/s]1861it [19:14,  1.62it/s]1862it [19:14,  1.62it/s]1863it [19:15,  1.62it/s]1864it [19:16,  1.62it/s]1865it [19:16,  1.63it/s]1866it [19:17,  1.63it/s]1867it [19:18,  1.63it/s]1868it [19:18,  1.63it/s]1869it [19:19,  1.63it/s]1870it [19:19,  1.62it/s]1871it [19:20,  1.62it/s]1872it [19:21,  1.62it/s]1873it [19:21,  1.62it/s]1874it [19:22,  1.62it/s]1875it [19:22,  1.63it/s]1876it [19:23,  1.63it/s]1877it [19:24,  1.62it/s]1878it [19:24,  1.62it/s]1879it [19:25,  1.63it/s]1880it [19:26,  1.62it/s]1881it [19:26,  1.62it/s]1882it [19:27,  1.62it/s]1883it [19:27,  1.62it/s]1884it [19:28,  1.62it/s]1885it [19:29,  1.63it/s]1886it [19:29,  1.63it/s]1887it [19:30,  1.63it/s]1888it [19:30,  1.63it/s]1889it [19:31,  1.63it/s]1890it [19:32,  1.63it/s]1891it [19:32,  1.63it/s]1892it [19:33,  1.63it/s]1893it [19:34,  1.63it/s]1894it [19:34,  1.62it/s]1895it [19:35,  1.63it/s]1896it [19:35,  1.63it/s]1897it [19:36,  1.63it/s]1898it [19:37,  1.63it/s]1899it [19:37,  1.63it/s]step: 001900 	 epe: 3.314
Save checkpoint at step: 1900
1900it [19:38,  1.35it/s]1901it [19:39,  1.43it/s]1902it [19:40,  1.48it/s]1903it [19:40,  1.52it/s]1904it [19:41,  1.55it/s]1905it [19:41,  1.58it/s]1906it [19:42,  1.59it/s]1907it [19:43,  1.60it/s]1908it [19:43,  1.61it/s]1909it [19:44,  1.61it/s]1910it [19:44,  1.62it/s]1911it [19:45,  1.63it/s]1912it [19:46,  1.62it/s]1913it [19:46,  1.62it/s]1914it [19:47,  1.62it/s]1915it [19:47,  1.63it/s]1916it [19:48,  1.62it/s]1917it [19:49,  1.62it/s]1918it [19:49,  1.62it/s]1919it [19:50,  1.62it/s]1920it [19:51,  1.62it/s]1921it [19:51,  1.63it/s]1922it [19:52,  1.63it/s]1923it [19:52,  1.62it/s]1924it [19:53,  1.62it/s]1925it [19:54,  1.62it/s]1926it [19:54,  1.62it/s]1927it [19:55,  1.62it/s]1928it [19:56,  1.62it/s]1929it [19:56,  1.62it/s]1930it [19:57,  1.62it/s]1931it [19:57,  1.62it/s]1932it [19:58,  1.62it/s]1933it [19:59,  1.63it/s]1934it [19:59,  1.62it/s]1935it [20:00,  1.62it/s]1936it [20:00,  1.62it/s]1937it [20:01,  1.63it/s]1938it [20:02,  1.63it/s]1939it [20:02,  1.63it/s]1940it [20:03,  1.63it/s]1941it [20:03,  1.63it/s]1942it [20:04,  1.63it/s]1943it [20:05,  1.63it/s]1944it [20:05,  1.64it/s]1945it [20:06,  1.63it/s]1946it [20:07,  1.63it/s]1947it [20:07,  1.63it/s]1948it [20:08,  1.63it/s]1949it [20:08,  1.63it/s]1950it [20:09,  1.62it/s]1951it [20:10,  1.62it/s]1952it [20:10,  1.62it/s]1953it [20:11,  1.62it/s]1954it [20:11,  1.62it/s]1955it [20:12,  1.63it/s]1956it [20:13,  1.63it/s]1957it [20:13,  1.63it/s]1958it [20:14,  1.63it/s]1959it [20:15,  1.63it/s]1960it [20:15,  1.63it/s]1961it [20:16,  1.63it/s]1962it [20:16,  1.63it/s]1963it [20:17,  1.63it/s]1964it [20:18,  1.62it/s]1965it [20:18,  1.62it/s]1966it [20:19,  1.63it/s]1967it [20:19,  1.63it/s]1968it [20:20,  1.63it/s]1969it [20:21,  1.63it/s]1970it [20:21,  1.63it/s]1971it [20:22,  1.63it/s]1972it [20:23,  1.62it/s]1973it [20:23,  1.63it/s]1974it [20:24,  1.63it/s]1975it [20:24,  1.63it/s]1976it [20:25,  1.63it/s]1977it [20:26,  1.63it/s]1978it [20:26,  1.63it/s]1979it [20:27,  1.63it/s]1980it [20:27,  1.62it/s]1981it [20:28,  1.63it/s]1982it [20:29,  1.63it/s]1983it [20:29,  1.63it/s]1984it [20:30,  1.62it/s]1985it [20:31,  1.63it/s]1986it [20:31,  1.63it/s]1987it [20:32,  1.62it/s]1988it [20:32,  1.62it/s]1989it [20:33,  1.63it/s]1990it [20:34,  1.63it/s]1991it [20:34,  1.63it/s]1992it [20:35,  1.63it/s]1993it [20:35,  1.63it/s]1994it [20:36,  1.63it/s]1995it [20:37,  1.62it/s]1996it [20:37,  1.63it/s]1997it [20:38,  1.63it/s]1998it [20:39,  1.63it/s]1999it [20:39,  1.63it/s]step: 002000 	 epe: 4.408
Save checkpoint at step: 2000
2000it [20:40,  1.36it/s]2001it [20:41,  1.43it/s]2002it [20:41,  1.49it/s]2003it [20:42,  1.53it/s]2004it [20:43,  1.55it/s]2005it [20:43,  1.58it/s]2006it [20:44,  1.59it/s]2007it [20:44,  1.60it/s]2008it [20:45,  1.60it/s]2009it [20:46,  1.60it/s]2010it [20:46,  1.61it/s]2011it [20:47,  1.62it/s]2012it [20:48,  1.62it/s]2013it [20:48,  1.62it/s]2014it [20:49,  1.62it/s]2015it [20:49,  1.63it/s]2016it [20:50,  1.63it/s]2017it [20:51,  1.63it/s]2018it [20:51,  1.62it/s]2019it [20:52,  1.62it/s]2020it [20:52,  1.62it/s]2021it [20:53,  1.62it/s]2022it [20:54,  1.63it/s]2023it [20:54,  1.63it/s]2024it [20:55,  1.63it/s]2025it [20:56,  1.63it/s]2026it [20:56,  1.63it/s]2027it [20:57,  1.63it/s]2028it [20:57,  1.64it/s]2029it [20:58,  1.64it/s]2030it [20:59,  1.63it/s]2031it [20:59,  1.63it/s]2032it [21:00,  1.63it/s]2033it [21:00,  1.63it/s]2034it [21:01,  1.62it/s]2035it [21:02,  1.62it/s]2036it [21:02,  1.63it/s]2037it [21:03,  1.63it/s]2038it [21:04,  1.63it/s]2039it [21:04,  1.63it/s]2040it [21:05,  1.63it/s]2041it [21:05,  1.63it/s]2042it [21:06,  1.62it/s]2043it [21:07,  1.62it/s]2044it [21:07,  1.62it/s]2045it [21:08,  1.62it/s]2046it [21:08,  1.61it/s]2047it [21:09,  1.62it/s]2048it [21:10,  1.62it/s]2049it [21:10,  1.62it/s]2050it [21:11,  1.62it/s]2051it [21:12,  1.63it/s]2052it [21:12,  1.63it/s]2053it [21:13,  1.63it/s]2054it [21:13,  1.63it/s]2055it [21:14,  1.63it/s]2056it [21:15,  1.62it/s]2057it [21:15,  1.62it/s]2058it [21:16,  1.62it/s]2059it [21:16,  1.62it/s]2060it [21:17,  1.62it/s]2061it [21:18,  1.63it/s]2062it [21:18,  1.63it/s]2063it [21:19,  1.63it/s]2064it [21:20,  1.63it/s]2065it [21:20,  1.63it/s]2066it [21:21,  1.63it/s]2067it [21:21,  1.62it/s]2068it [21:22,  1.62it/s]2069it [21:23,  1.63it/s]2070it [21:23,  1.63it/s]2071it [21:24,  1.63it/s]2072it [21:24,  1.64it/s]2073it [21:25,  1.64it/s]2074it [21:26,  1.64it/s]2075it [21:26,  1.64it/s]2076it [21:27,  1.64it/s]2077it [21:27,  1.64it/s]2078it [21:28,  1.63it/s]2079it [21:29,  1.63it/s]2080it [21:29,  1.63it/s]2081it [21:30,  1.63it/s]2082it [21:31,  1.63it/s]2083it [21:31,  1.63it/s]2084it [21:32,  1.62it/s]2085it [21:32,  1.62it/s]2086it [21:33,  1.62it/s]2087it [21:34,  1.62it/s]2088it [21:34,  1.62it/s]2089it [21:35,  1.62it/s]2090it [21:35,  1.62it/s]2091it [21:36,  1.63it/s]2092it [21:37,  1.62it/s]2093it [21:37,  1.62it/s]2094it [21:38,  1.62it/s]2095it [21:39,  1.62it/s]2096it [21:39,  1.62it/s]2097it [21:40,  1.62it/s]2098it [21:40,  1.63it/s]2099it [21:41,  1.63it/s]step: 002100 	 epe: 6.588
Save checkpoint at step: 2100
2100it [21:42,  1.35it/s]2101it [21:43,  1.43it/s]2102it [21:43,  1.49it/s]2103it [21:44,  1.53it/s]2104it [21:44,  1.56it/s]2105it [21:45,  1.58it/s]2106it [21:46,  1.59it/s]2107it [21:46,  1.60it/s]2108it [21:47,  1.62it/s]2109it [21:48,  1.62it/s]2110it [21:48,  1.62it/s]2111it [21:49,  1.62it/s]2112it [21:49,  1.63it/s]2113it [21:50,  1.62it/s]2114it [21:51,  1.62it/s]2115it [21:51,  1.63it/s]2116it [21:52,  1.63it/s]2117it [21:52,  1.62it/s]2118it [21:53,  1.62it/s]2119it [21:54,  1.62it/s]2120it [21:54,  1.63it/s]2121it [21:55,  1.62it/s]2122it [21:56,  1.62it/s]2123it [21:56,  1.62it/s]2124it [21:57,  1.63it/s]2125it [21:57,  1.62it/s]2126it [21:58,  1.62it/s]2127it [21:59,  1.63it/s]2128it [21:59,  1.63it/s]2129it [22:00,  1.62it/s]2130it [22:00,  1.62it/s]2131it [22:01,  1.63it/s]2132it [22:02,  1.62it/s]2133it [22:02,  1.62it/s]2134it [22:03,  1.63it/s]2135it [22:04,  1.63it/s]2136it [22:04,  1.63it/s]2137it [22:05,  1.62it/s]2138it [22:05,  1.62it/s]2139it [22:06,  1.62it/s]2140it [22:07,  1.62it/s]2141it [22:07,  1.62it/s]2142it [22:08,  1.62it/s]2143it [22:08,  1.62it/s]2144it [22:09,  1.62it/s]2145it [22:10,  1.62it/s]2146it [22:10,  1.63it/s]2147it [22:11,  1.63it/s]2148it [22:12,  1.63it/s]2149it [22:12,  1.63it/s]2150it [22:13,  1.63it/s]2151it [22:13,  1.63it/s]2152it [22:14,  1.63it/s]2153it [22:15,  1.63it/s]2154it [22:15,  1.64it/s]2155it [22:16,  1.63it/s]2156it [22:16,  1.63it/s]2157it [22:17,  1.63it/s]2158it [22:18,  1.63it/s]2159it [22:18,  1.63it/s]2160it [22:19,  1.63it/s]2161it [22:20,  1.63it/s]2162it [22:20,  1.62it/s]2163it [22:21,  1.62it/s]2164it [22:21,  1.63it/s]2165it [22:22,  1.63it/s]2166it [22:23,  1.63it/s]2167it [22:23,  1.63it/s]2168it [22:24,  1.63it/s]2169it [22:24,  1.63it/s]2170it [22:25,  1.62it/s]2171it [22:26,  1.62it/s]2172it [22:26,  1.62it/s]2173it [22:27,  1.62it/s]2174it [22:28,  1.62it/s]2175it [22:28,  1.62it/s]2176it [22:29,  1.62it/s]2177it [22:29,  1.62it/s]2178it [22:30,  1.62it/s]2179it [22:31,  1.62it/s]2180it [22:31,  1.62it/s]2181it [22:32,  1.63it/s]2182it [22:32,  1.62it/s]2183it [22:33,  1.62it/s]2184it [22:34,  1.63it/s]2185it [22:34,  1.63it/s]2186it [22:35,  1.63it/s]2187it [22:36,  1.63it/s]2188it [22:36,  1.63it/s]2189it [22:37,  1.63it/s]2190it [22:37,  1.63it/s]2191it [22:38,  1.62it/s]2192it [22:39,  1.62it/s]2193it [22:39,  1.62it/s]2194it [22:40,  1.62it/s]2195it [22:40,  1.62it/s]2196it [22:41,  1.62it/s]2197it [22:42,  1.62it/s]2198it [22:42,  1.62it/s]2199it [22:43,  1.62it/s]step: 002200 	 epe: 10.966
Save checkpoint at step: 2200
2200it [22:44,  1.34it/s]2201it [22:45,  1.42it/s]2202it [22:45,  1.48it/s]2203it [22:46,  1.52it/s]2204it [22:46,  1.55it/s]2205it [22:47,  1.57it/s]2206it [22:48,  1.59it/s]2207it [22:48,  1.60it/s]2208it [22:49,  1.61it/s]2209it [22:50,  1.62it/s]2210it [22:50,  1.62it/s]2211it [22:51,  1.61it/s]2212it [22:51,  1.61it/s]2213it [22:52,  1.62it/s]2214it [22:53,  1.62it/s]2215it [22:53,  1.62it/s]2216it [22:54,  1.62it/s]2217it [22:54,  1.63it/s]2218it [22:55,  1.62it/s]2219it [22:56,  1.62it/s]2220it [22:56,  1.63it/s]2221it [22:57,  1.63it/s]2222it [22:58,  1.63it/s]2223it [22:58,  1.63it/s]2224it [22:59,  1.63it/s]2225it [22:59,  1.63it/s]2226it [23:00,  1.63it/s]2227it [23:01,  1.63it/s]2228it [23:01,  1.63it/s]2229it [23:02,  1.63it/s]2230it [23:02,  1.63it/s]2231it [23:03,  1.63it/s]2232it [23:04,  1.63it/s]2233it [23:04,  1.63it/s]2234it [23:05,  1.63it/s]2235it [23:05,  1.63it/s]2236it [23:06,  1.63it/s]2237it [23:07,  1.62it/s]2238it [23:07,  1.63it/s]2239it [23:08,  1.63it/s]2240it [23:09,  1.63it/s]2241it [23:09,  1.63it/s]2242it [23:10,  1.62it/s]2243it [23:10,  1.62it/s]2244it [23:11,  1.62it/s]2245it [23:12,  1.63it/s]2246it [23:12,  1.62it/s]2247it [23:13,  1.62it/s]2248it [23:13,  1.62it/s]2249it [23:14,  1.62it/s]2250it [23:15,  1.62it/s]2251it [23:15,  1.62it/s]2252it [23:16,  1.62it/s]2253it [23:17,  1.63it/s]2254it [23:17,  1.62it/s]2255it [23:18,  1.62it/s]2256it [23:18,  1.63it/s]2257it [23:19,  1.63it/s]2258it [23:20,  1.63it/s]2259it [23:20,  1.63it/s]2260it [23:21,  1.62it/s]2261it [23:21,  1.63it/s]2262it [23:22,  1.63it/s]2263it [23:23,  1.63it/s]2264it [23:23,  1.63it/s]2265it [23:24,  1.63it/s]2266it [23:25,  1.63it/s]2267it [23:25,  1.63it/s]2268it [23:26,  1.63it/s]2269it [23:26,  1.63it/s]2270it [23:27,  1.63it/s]2271it [23:28,  1.63it/s]2272it [23:28,  1.63it/s]2273it [23:29,  1.63it/s]2274it [23:29,  1.63it/s]2275it [23:30,  1.63it/s]2276it [23:31,  1.62it/s]2277it [23:31,  1.62it/s]2278it [23:32,  1.62it/s]2279it [23:33,  1.63it/s]2280it [23:33,  1.62it/s]2281it [23:34,  1.62it/s]2282it [23:34,  1.62it/s]2283it [23:35,  1.62it/s]2284it [23:36,  1.62it/s]2285it [23:36,  1.62it/s]2286it [23:37,  1.63it/s]2287it [23:37,  1.62it/s]2288it [23:38,  1.62it/s]2289it [23:39,  1.62it/s]2290it [23:39,  1.63it/s]2291it [23:40,  1.62it/s]2292it [23:41,  1.62it/s]2293it [23:41,  1.62it/s]2294it [23:42,  1.63it/s]2295it [23:42,  1.63it/s]2296it [23:43,  1.62it/s]2297it [23:44,  1.62it/s]2298it [23:44,  1.63it/s]2299it [23:45,  1.63it/s]step: 002300 	 epe: 5.876
Save checkpoint at step: 2300
2300it [23:46,  1.36it/s]2301it [23:46,  1.43it/s]2302it [23:47,  1.49it/s]2303it [23:48,  1.53it/s]2304it [23:48,  1.56it/s]2305it [23:49,  1.58it/s]2306it [23:50,  1.59it/s]2307it [23:50,  1.61it/s]2308it [23:51,  1.61it/s]2309it [23:51,  1.61it/s]2310it [23:52,  1.61it/s]2311it [23:53,  1.61it/s]2312it [23:53,  1.62it/s]2313it [23:54,  1.62it/s]2314it [23:54,  1.63it/s]2315it [23:55,  1.63it/s]2316it [23:56,  1.63it/s]2317it [23:56,  1.62it/s]2318it [23:57,  1.63it/s]2319it [23:58,  1.64it/s]2320it [23:58,  1.64it/s]2321it [23:59,  1.65it/s]2322it [23:59,  1.64it/s]2323it [24:00,  1.64it/s]2324it [24:01,  1.64it/s]2325it [24:01,  1.64it/s]2326it [24:02,  1.64it/s]2327it [24:02,  1.64it/s]2328it [24:03,  1.64it/s]2329it [24:04,  1.64it/s]2330it [24:04,  1.64it/s]2331it [24:05,  1.64it/s]2332it [24:05,  1.63it/s]2333it [24:06,  1.63it/s]2334it [24:07,  1.63it/s]2335it [24:07,  1.63it/s]2336it [24:08,  1.63it/s]2337it [24:09,  1.63it/s]2338it [24:09,  1.63it/s]2339it [24:10,  1.63it/s]2340it [24:10,  1.64it/s]2341it [24:11,  1.65it/s]2342it [24:12,  1.64it/s]2343it [24:12,  1.64it/s]2344it [24:13,  1.64it/s]2345it [24:13,  1.64it/s]2346it [24:14,  1.64it/s]2347it [24:15,  1.63it/s]2348it [24:15,  1.64it/s]2349it [24:16,  1.63it/s]2350it [24:16,  1.63it/s]2351it [24:17,  1.63it/s]2352it [24:18,  1.63it/s]2353it [24:18,  1.63it/s]2354it [24:19,  1.64it/s]2355it [24:20,  1.63it/s]2356it [24:20,  1.63it/s]2357it [24:21,  1.63it/s]2358it [24:21,  1.64it/s]2359it [24:22,  1.64it/s]2360it [24:23,  1.64it/s]2361it [24:23,  1.64it/s]2362it [24:24,  1.64it/s]2363it [24:24,  1.64it/s]2364it [24:25,  1.64it/s]2365it [24:26,  1.63it/s]2366it [24:26,  1.64it/s]2367it [24:27,  1.64it/s]2368it [24:27,  1.64it/s]2369it [24:28,  1.63it/s]2370it [24:29,  1.63it/s]2371it [24:29,  1.63it/s]2372it [24:30,  1.63it/s]2373it [24:31,  1.63it/s]2374it [24:31,  1.63it/s]2375it [24:32,  1.63it/s]2376it [24:32,  1.63it/s]2377it [24:33,  1.63it/s]2378it [24:34,  1.63it/s]2379it [24:34,  1.63it/s]2380it [24:35,  1.63it/s]2381it [24:35,  1.64it/s]2382it [24:36,  1.63it/s]2383it [24:37,  1.63it/s]2384it [24:37,  1.63it/s]2385it [24:38,  1.63it/s]2386it [24:39,  1.63it/s]2387it [24:39,  1.63it/s]2388it [24:40,  1.63it/s]2389it [24:40,  1.63it/s]2390it [24:41,  1.62it/s]2391it [24:42,  1.63it/s]2392it [24:42,  1.63it/s]2393it [24:43,  1.63it/s]2394it [24:43,  1.63it/s]2395it [24:44,  1.63it/s]2396it [24:45,  1.63it/s]2397it [24:45,  1.63it/s]2398it [24:46,  1.64it/s]2399it [24:46,  1.64it/s]step: 002400 	 epe: 2.503
Save checkpoint at step: 2400
2400it [24:47,  1.37it/s]2401it [24:48,  1.45it/s]2402it [24:49,  1.49it/s]2403it [24:49,  1.53it/s]2404it [24:50,  1.57it/s]2405it [24:51,  1.60it/s]2406it [24:51,  1.61it/s]2407it [24:52,  1.62it/s]2408it [24:52,  1.63it/s]2409it [24:53,  1.63it/s]2410it [24:54,  1.63it/s]2411it [24:54,  1.63it/s]2412it [24:55,  1.63it/s]2413it [24:55,  1.63it/s]2414it [24:56,  1.64it/s]2415it [24:57,  1.64it/s]2416it [24:57,  1.65it/s]2417it [24:58,  1.65it/s]2418it [24:58,  1.65it/s]2419it [24:59,  1.65it/s]2420it [25:00,  1.65it/s]2421it [25:00,  1.64it/s]2422it [25:01,  1.65it/s]2423it [25:01,  1.64it/s]2424it [25:02,  1.64it/s]2425it [25:03,  1.64it/s]2426it [25:03,  1.64it/s]2427it [25:04,  1.64it/s]2428it [25:05,  1.64it/s]2429it [25:05,  1.64it/s]2430it [25:06,  1.63it/s]2431it [25:06,  1.63it/s]2432it [25:07,  1.63it/s]2433it [25:08,  1.63it/s]2434it [25:08,  1.63it/s]2435it [25:09,  1.63it/s]2436it [25:09,  1.64it/s]2437it [25:10,  1.63it/s]2438it [25:11,  1.63it/s]2439it [25:11,  1.64it/s]2440it [25:12,  1.64it/s]2441it [25:12,  1.65it/s]2442it [25:13,  1.65it/s]2443it [25:14,  1.64it/s]2444it [25:14,  1.65it/s]2445it [25:15,  1.64it/s]2446it [25:16,  1.64it/s]2447it [25:16,  1.63it/s]2448it [25:17,  1.63it/s]2449it [25:17,  1.62it/s]2450it [25:18,  1.62it/s]2451it [25:19,  1.63it/s]2452it [25:19,  1.63it/s]2453it [25:20,  1.64it/s]2454it [25:20,  1.64it/s]2455it [25:21,  1.63it/s]2456it [25:22,  1.63it/s]2457it [25:22,  1.64it/s]2458it [25:23,  1.63it/s]2459it [25:24,  1.63it/s]2460it [25:24,  1.63it/s]2461it [25:25,  1.63it/s]2462it [25:25,  1.64it/s]2463it [25:26,  1.63it/s]2464it [25:27,  1.63it/s]2465it [25:27,  1.63it/s]2466it [25:28,  1.63it/s]2467it [25:28,  1.63it/s]2468it [25:29,  1.63it/s]2469it [25:30,  1.63it/s]2470it [25:30,  1.63it/s]2471it [25:31,  1.63it/s]2472it [25:31,  1.62it/s]2473it [25:32,  1.62it/s]2474it [25:33,  1.62it/s]2475it [25:33,  1.62it/s]2476it [25:34,  1.63it/s]2477it [25:35,  1.63it/s]2478it [25:35,  1.63it/s]2479it [25:36,  1.63it/s]2480it [25:36,  1.63it/s]2481it [25:37,  1.63it/s]2482it [25:38,  1.63it/s]2483it [25:38,  1.63it/s]2484it [25:39,  1.63it/s]2485it [25:39,  1.63it/s]2486it [25:40,  1.63it/s]2487it [25:41,  1.64it/s]2488it [25:41,  1.64it/s]2489it [25:42,  1.64it/s]2490it [25:43,  1.63it/s]2491it [25:43,  1.63it/s]2492it [25:44,  1.63it/s]2493it [25:44,  1.63it/s]2494it [25:45,  1.63it/s]2495it [25:46,  1.63it/s]2496it [25:46,  1.63it/s]2497it [25:47,  1.63it/s]2498it [25:47,  1.62it/s]2499it [25:48,  1.62it/s]step: 002500 	 epe: 15.907
Save checkpoint at step: 2500
2500it [25:49,  1.31it/s]2501it [25:50,  1.40it/s]2502it [25:50,  1.46it/s]2503it [25:51,  1.51it/s]2504it [25:52,  1.54it/s]2505it [25:52,  1.57it/s]2506it [25:53,  1.58it/s]2507it [25:53,  1.59it/s]2508it [25:54,  1.61it/s]2509it [25:55,  1.61it/s]2510it [25:55,  1.61it/s]2511it [25:56,  1.62it/s]2512it [25:57,  1.62it/s]2513it [25:57,  1.62it/s]2514it [25:58,  1.63it/s]2515it [25:58,  1.62it/s]2516it [25:59,  1.63it/s]2517it [26:00,  1.63it/s]2518it [26:00,  1.62it/s]2519it [26:01,  1.63it/s]2520it [26:01,  1.62it/s]2521it [26:02,  1.62it/s]2522it [26:03,  1.62it/s]2523it [26:03,  1.63it/s]2524it [26:04,  1.62it/s]2525it [26:05,  1.63it/s]2526it [26:05,  1.63it/s]2527it [26:06,  1.63it/s]2528it [26:06,  1.63it/s]2529it [26:07,  1.63it/s]2530it [26:08,  1.63it/s]2531it [26:08,  1.63it/s]2532it [26:09,  1.63it/s]2533it [26:09,  1.63it/s]2534it [26:10,  1.63it/s]2535it [26:11,  1.63it/s]2536it [26:11,  1.62it/s]2537it [26:12,  1.62it/s]2538it [26:13,  1.62it/s]2539it [26:13,  1.62it/s]2540it [26:14,  1.62it/s]2541it [26:14,  1.63it/s]2542it [26:15,  1.63it/s]2543it [26:16,  1.62it/s]2544it [26:16,  1.62it/s]2545it [26:17,  1.62it/s]2546it [26:17,  1.62it/s]2547it [26:18,  1.62it/s]2548it [26:19,  1.62it/s]2549it [26:19,  1.62it/s]2550it [26:20,  1.62it/s]2551it [26:21,  1.62it/s]2552it [26:21,  1.62it/s]2553it [26:22,  1.62it/s]2554it [26:22,  1.62it/s]2555it [26:23,  1.61it/s]2556it [26:24,  1.62it/s]2557it [26:24,  1.62it/s]2558it [26:25,  1.62it/s]2559it [26:25,  1.62it/s]2560it [26:26,  1.62it/s]2561it [26:27,  1.62it/s]2562it [26:27,  1.62it/s]2563it [26:28,  1.63it/s]2564it [26:29,  1.62it/s]2565it [26:29,  1.62it/s]2566it [26:30,  1.62it/s]2567it [26:30,  1.62it/s]2568it [26:31,  1.62it/s]2569it [26:32,  1.62it/s]2570it [26:32,  1.62it/s]2571it [26:33,  1.62it/s]2572it [26:34,  1.61it/s]2573it [26:34,  1.61it/s]2574it [26:35,  1.62it/s]2575it [26:35,  1.62it/s]2576it [26:36,  1.62it/s]2577it [26:37,  1.62it/s]2578it [26:37,  1.62it/s]2579it [26:38,  1.62it/s]2580it [26:38,  1.62it/s]2581it [26:39,  1.62it/s]2582it [26:40,  1.62it/s]2583it [26:40,  1.62it/s]2584it [26:41,  1.62it/s]2585it [26:42,  1.59it/s]2586it [26:42,  1.60it/s]2587it [26:43,  1.60it/s]2588it [26:43,  1.61it/s]2589it [26:44,  1.61it/s]2590it [26:45,  1.62it/s]2591it [26:45,  1.62it/s]2592it [26:46,  1.62it/s]2593it [26:47,  1.62it/s]2594it [26:47,  1.62it/s]2595it [26:48,  1.62it/s]2596it [26:48,  1.62it/s]2597it [26:49,  1.61it/s]2598it [26:50,  1.62it/s]2599it [26:50,  1.62it/s]step: 002600 	 epe: 7.931
Save checkpoint at step: 2600
2600it [26:51,  1.33it/s]2601it [26:52,  1.41it/s]2602it [26:53,  1.47it/s]2603it [26:53,  1.51it/s]2604it [26:54,  1.54it/s]2605it [26:54,  1.56it/s]2606it [26:55,  1.59it/s]2607it [26:56,  1.60it/s]2608it [26:56,  1.60it/s]2609it [26:57,  1.62it/s]2610it [26:57,  1.62it/s]2611it [26:58,  1.63it/s]2612it [26:59,  1.62it/s]2613it [26:59,  1.58it/s]2614it [27:00,  1.55it/s]2615it [27:01,  1.58it/s]2616it [27:01,  1.60it/s]2617it [27:02,  1.60it/s]2618it [27:02,  1.60it/s]2619it [27:03,  1.61it/s]2620it [27:04,  1.61it/s]2621it [27:04,  1.62it/s]2622it [27:05,  1.62it/s]2623it [27:06,  1.62it/s]2624it [27:06,  1.63it/s]2625it [27:07,  1.62it/s]2626it [27:07,  1.62it/s]2627it [27:08,  1.62it/s]2628it [27:09,  1.63it/s]2629it [27:09,  1.62it/s]2630it [27:10,  1.62it/s]2631it [27:10,  1.62it/s]2632it [27:11,  1.63it/s]2633it [27:12,  1.63it/s]2634it [27:12,  1.64it/s]2635it [27:13,  1.64it/s]2636it [27:14,  1.64it/s]2637it [27:14,  1.65it/s]2638it [27:15,  1.65it/s]2639it [27:15,  1.65it/s]2640it [27:16,  1.65it/s]2641it [27:17,  1.66it/s]2642it [27:17,  1.65it/s]2643it [27:18,  1.65it/s]2644it [27:18,  1.65it/s]2645it [27:19,  1.64it/s]2646it [27:20,  1.64it/s]2647it [27:20,  1.64it/s]2648it [27:21,  1.64it/s]2649it [27:21,  1.64it/s]2650it [27:22,  1.63it/s]2651it [27:23,  1.62it/s]2652it [27:23,  1.62it/s]2653it [27:24,  1.62it/s]2654it [27:25,  1.63it/s]2655it [27:25,  1.62it/s]2656it [27:26,  1.63it/s]2657it [27:26,  1.62it/s]2658it [27:27,  1.63it/s]2659it [27:28,  1.63it/s]2660it [27:28,  1.63it/s]2661it [27:29,  1.62it/s]2662it [27:29,  1.62it/s]2663it [27:30,  1.63it/s]2664it [27:31,  1.63it/s]2665it [27:31,  1.64it/s]2666it [27:32,  1.63it/s]2667it [27:32,  1.63it/s]2668it [27:33,  1.64it/s]2669it [27:34,  1.64it/s]2670it [27:34,  1.65it/s]2671it [27:35,  1.64it/s]2672it [27:36,  1.65it/s]2673it [27:36,  1.65it/s]2674it [27:37,  1.65it/s]2675it [27:37,  1.64it/s]2676it [27:38,  1.64it/s]2677it [27:39,  1.64it/s]2678it [27:39,  1.64it/s]2679it [27:40,  1.64it/s]2680it [27:40,  1.65it/s]2681it [27:41,  1.65it/s]2682it [27:42,  1.65it/s]2683it [27:42,  1.65it/s]2684it [27:43,  1.65it/s]2685it [27:43,  1.65it/s]2686it [27:44,  1.64it/s]2687it [27:45,  1.64it/s]2688it [27:45,  1.63it/s]2689it [27:46,  1.63it/s]2690it [27:46,  1.63it/s]2691it [27:47,  1.63it/s]2692it [27:48,  1.63it/s]2693it [27:48,  1.63it/s]2694it [27:49,  1.63it/s]2695it [27:50,  1.63it/s]2696it [27:50,  1.63it/s]2697it [27:51,  1.63it/s]2698it [27:51,  1.63it/s]2699it [27:52,  1.63it/s]step: 002700 	 epe: 2.913
Save checkpoint at step: 2700
2700it [27:53,  1.35it/s]2701it [27:54,  1.42it/s]2702it [27:54,  1.48it/s]2703it [27:55,  1.52it/s]2704it [27:56,  1.55it/s]2705it [27:56,  1.57it/s]2706it [27:57,  1.59it/s]2707it [27:57,  1.59it/s]2708it [27:58,  1.60it/s]2709it [27:59,  1.61it/s]2710it [27:59,  1.61it/s]2711it [28:00,  1.61it/s]2712it [28:00,  1.62it/s]2713it [28:01,  1.62it/s]2714it [28:02,  1.62it/s]2715it [28:02,  1.62it/s]2716it [28:03,  1.62it/s]2717it [28:04,  1.62it/s]2718it [28:04,  1.62it/s]2719it [28:05,  1.60it/s]2720it [28:05,  1.59it/s]2721it [28:06,  1.59it/s]2722it [28:07,  1.59it/s]2723it [28:07,  1.59it/s]2724it [28:08,  1.60it/s]2725it [28:09,  1.61it/s]2726it [28:09,  1.61it/s]2727it [28:10,  1.62it/s]2728it [28:10,  1.62it/s]2729it [28:11,  1.62it/s]2730it [28:12,  1.62it/s]2731it [28:12,  1.62it/s]2732it [28:13,  1.62it/s]2733it [28:13,  1.63it/s]2734it [28:14,  1.63it/s]2735it [28:15,  1.62it/s]2736it [28:15,  1.62it/s]2737it [28:16,  1.62it/s]2738it [28:17,  1.62it/s]2739it [28:17,  1.62it/s]2740it [28:18,  1.62it/s]2741it [28:18,  1.62it/s]2742it [28:19,  1.62it/s]2743it [28:20,  1.62it/s]2744it [28:20,  1.62it/s]2745it [28:21,  1.62it/s]2746it [28:21,  1.62it/s]2747it [28:22,  1.62it/s]2748it [28:23,  1.62it/s]2749it [28:23,  1.61it/s]2750it [28:24,  1.62it/s]2751it [28:25,  1.62it/s]2752it [28:25,  1.62it/s]2753it [28:26,  1.62it/s]2754it [28:26,  1.62it/s]2755it [28:27,  1.62it/s]2756it [28:28,  1.62it/s]2757it [28:28,  1.61it/s]2758it [28:29,  1.61it/s]2759it [28:30,  1.62it/s]2760it [28:30,  1.62it/s]2761it [28:31,  1.62it/s]2762it [28:31,  1.62it/s]2763it [28:32,  1.62it/s]2764it [28:33,  1.62it/s]2765it [28:33,  1.63it/s]2766it [28:34,  1.63it/s]2767it [28:34,  1.63it/s]2768it [28:35,  1.63it/s]2769it [28:36,  1.63it/s]2770it [28:36,  1.63it/s]2771it [28:37,  1.62it/s]2772it [28:38,  1.62it/s]2773it [28:38,  1.62it/s]2774it [28:39,  1.63it/s]2775it [28:39,  1.62it/s]2776it [28:40,  1.62it/s]2777it [28:41,  1.62it/s]2778it [28:41,  1.62it/s]2779it [28:42,  1.63it/s]2780it [28:42,  1.62it/s]2781it [28:43,  1.62it/s]2782it [28:44,  1.62it/s]2783it [28:44,  1.63it/s]2784it [28:45,  1.63it/s]2785it [28:46,  1.63it/s]2786it [28:46,  1.63it/s]2787it [28:47,  1.62it/s]2788it [28:47,  1.63it/s]2789it [28:48,  1.63it/s]2790it [28:49,  1.63it/s]2791it [28:49,  1.64it/s]2792it [28:50,  1.64it/s]2793it [28:50,  1.64it/s]2794it [28:51,  1.64it/s]2795it [28:52,  1.64it/s]2796it [28:52,  1.65it/s]2797it [28:53,  1.64it/s]2798it [28:53,  1.65it/s]2799it [28:54,  1.65it/s]step: 002800 	 epe: 12.658
Save checkpoint at step: 2800
2800it [28:55,  1.38it/s]2801it [28:56,  1.45it/s]2802it [28:56,  1.50it/s]2803it [28:57,  1.53it/s]2804it [28:58,  1.56it/s]2805it [28:58,  1.57it/s]2806it [28:59,  1.59it/s]2807it [28:59,  1.60it/s]2808it [29:00,  1.60it/s]2809it [29:01,  1.60it/s]2810it [29:01,  1.61it/s]2811it [29:02,  1.61it/s]2812it [29:02,  1.61it/s]2813it [29:03,  1.62it/s]2814it [29:04,  1.61it/s]2815it [29:04,  1.61it/s]2816it [29:05,  1.62it/s]2817it [29:06,  1.61it/s]2818it [29:06,  1.62it/s]2819it [29:07,  1.62it/s]2820it [29:07,  1.62it/s]2821it [29:08,  1.62it/s]2822it [29:09,  1.62it/s]2823it [29:09,  1.62it/s]2824it [29:10,  1.62it/s]2825it [29:10,  1.62it/s]2826it [29:11,  1.63it/s]2827it [29:12,  1.62it/s]2828it [29:12,  1.62it/s]2829it [29:13,  1.63it/s]2830it [29:14,  1.62it/s]2831it [29:14,  1.62it/s]2832it [29:15,  1.62it/s]2833it [29:15,  1.63it/s]2834it [29:16,  1.62it/s]2835it [29:17,  1.62it/s]2836it [29:17,  1.62it/s]2837it [29:18,  1.62it/s]2838it [29:19,  1.62it/s]2839it [29:19,  1.62it/s]2840it [29:20,  1.62it/s]2841it [29:20,  1.62it/s]2842it [29:21,  1.62it/s]2843it [29:22,  1.61it/s]2844it [29:22,  1.61it/s]2845it [29:23,  1.62it/s]2846it [29:23,  1.63it/s]2847it [29:24,  1.62it/s]2848it [29:25,  1.63it/s]2849it [29:25,  1.63it/s]2850it [29:26,  1.62it/s]2851it [29:27,  1.62it/s]2852it [29:27,  1.62it/s]2853it [29:28,  1.62it/s]2854it [29:28,  1.62it/s]2855it [29:29,  1.62it/s]2856it [29:30,  1.63it/s]2857it [29:30,  1.63it/s]2858it [29:31,  1.63it/s]2859it [29:31,  1.63it/s]2860it [29:32,  1.64it/s]2861it [29:33,  1.63it/s]2862it [29:33,  1.63it/s]2863it [29:34,  1.64it/s]2864it [29:34,  1.63it/s]2865it [29:35,  1.63it/s]2866it [29:36,  1.63it/s]2867it [29:36,  1.63it/s]2868it [29:37,  1.63it/s]2869it [29:38,  1.63it/s]2870it [29:38,  1.63it/s]2871it [29:39,  1.63it/s]2872it [29:39,  1.63it/s]2873it [29:40,  1.63it/s]2874it [29:41,  1.63it/s]2875it [29:41,  1.64it/s]2876it [29:42,  1.64it/s]2877it [29:42,  1.64it/s]2878it [29:43,  1.62it/s]2879it [29:44,  1.62it/s]2880it [29:44,  1.62it/s]2881it [29:45,  1.62it/s]2882it [29:46,  1.62it/s]2883it [29:46,  1.63it/s]2884it [29:47,  1.63it/s]2885it [29:47,  1.62it/s]2886it [29:48,  1.63it/s]2887it [29:49,  1.63it/s]2888it [29:49,  1.63it/s]2889it [29:50,  1.63it/s]2890it [29:50,  1.62it/s]2891it [29:51,  1.62it/s]2892it [29:52,  1.62it/s]2893it [29:52,  1.62it/s]2894it [29:53,  1.62it/s]2895it [29:54,  1.62it/s]2896it [29:54,  1.62it/s]2897it [29:55,  1.61it/s]2898it [29:55,  1.62it/s]2899it [29:56,  1.61it/s]step: 002900 	 epe: 5.312
Save checkpoint at step: 2900
2900it [29:57,  1.32it/s]2901it [29:58,  1.40it/s]2902it [29:58,  1.46it/s]2903it [29:59,  1.51it/s]2904it [30:00,  1.54it/s]2905it [30:00,  1.56it/s]2906it [30:01,  1.58it/s]2907it [30:01,  1.59it/s]2908it [30:02,  1.60it/s]2909it [30:03,  1.61it/s]2910it [30:03,  1.62it/s]2911it [30:04,  1.62it/s]2912it [30:05,  1.62it/s]2913it [30:05,  1.62it/s]2914it [30:06,  1.62it/s]2915it [30:06,  1.62it/s]2916it [30:07,  1.62it/s]2917it [30:08,  1.62it/s]2918it [30:08,  1.62it/s]2919it [30:09,  1.62it/s]2920it [30:09,  1.63it/s]2921it [30:10,  1.63it/s]2922it [30:11,  1.62it/s]2923it [30:11,  1.63it/s]2924it [30:12,  1.63it/s]2925it [30:13,  1.63it/s]2926it [30:13,  1.63it/s]2927it [30:14,  1.63it/s]2928it [30:14,  1.63it/s]2929it [30:15,  1.63it/s]2930it [30:16,  1.63it/s]2931it [30:16,  1.63it/s]2932it [30:17,  1.63it/s]2933it [30:17,  1.64it/s]2934it [30:18,  1.64it/s]2935it [30:19,  1.64it/s]2936it [30:19,  1.63it/s]2937it [30:20,  1.63it/s]2938it [30:20,  1.63it/s]2939it [30:21,  1.63it/s]2940it [30:22,  1.63it/s]2941it [30:22,  1.63it/s]2942it [30:23,  1.62it/s]2943it [30:24,  1.63it/s]2944it [30:24,  1.63it/s]2945it [30:25,  1.62it/s]2946it [30:25,  1.62it/s]2947it [30:26,  1.63it/s]2948it [30:27,  1.62it/s]2949it [30:27,  1.62it/s]2950it [30:28,  1.62it/s]2951it [30:28,  1.62it/s]2952it [30:29,  1.62it/s]2953it [30:30,  1.62it/s]2954it [30:30,  1.62it/s]2955it [30:31,  1.61it/s]2956it [30:32,  1.62it/s]2957it [30:32,  1.62it/s]2958it [30:33,  1.62it/s]2959it [30:33,  1.62it/s]2960it [30:34,  1.62it/s]2961it [30:35,  1.62it/s]2962it [30:35,  1.63it/s]2963it [30:36,  1.62it/s]2964it [30:37,  1.62it/s]2965it [30:37,  1.63it/s]2966it [30:38,  1.63it/s]2967it [30:38,  1.63it/s]2968it [30:39,  1.63it/s]2969it [30:40,  1.63it/s]2970it [30:40,  1.63it/s]2971it [30:41,  1.62it/s]2972it [30:41,  1.62it/s]2973it [30:42,  1.62it/s]2974it [30:43,  1.62it/s]2975it [30:43,  1.62it/s]2976it [30:44,  1.62it/s]2977it [30:45,  1.62it/s]2978it [30:45,  1.63it/s]2979it [30:46,  1.63it/s]2980it [30:46,  1.63it/s]2981it [30:47,  1.62it/s]2982it [30:48,  1.63it/s]2983it [30:48,  1.63it/s]2984it [30:49,  1.62it/s]2985it [30:49,  1.62it/s]2986it [30:50,  1.62it/s]2987it [30:51,  1.62it/s]2988it [30:51,  1.62it/s]2989it [30:52,  1.63it/s]2990it [30:53,  1.62it/s]2991it [30:53,  1.62it/s]2992it [30:54,  1.62it/s]2993it [30:54,  1.62it/s]2994it [30:55,  1.62it/s]2995it [30:56,  1.62it/s]2996it [30:56,  1.62it/s]2997it [30:57,  1.62it/s]2998it [30:57,  1.62it/s]2999it [30:58,  1.62it/s]step: 003000 	 epe: 3.524
Save checkpoint at step: 3000
3000it [30:59,  1.35it/s]3001it [31:00,  1.43it/s]3002it [31:00,  1.49it/s]3003it [31:01,  1.53it/s]3004it [31:02,  1.55it/s]3005it [31:02,  1.57it/s]3006it [31:03,  1.58it/s]3007it [31:03,  1.59it/s]3008it [31:04,  1.59it/s]3009it [31:05,  1.60it/s]3010it [31:05,  1.60it/s]3011it [31:06,  1.60it/s]3012it [31:07,  1.60it/s]3013it [31:07,  1.60it/s]3014it [31:08,  1.60it/s]3015it [31:08,  1.61it/s]3016it [31:09,  1.61it/s]3017it [31:10,  1.61it/s]3018it [31:10,  1.62it/s]3019it [31:11,  1.62it/s]3020it [31:11,  1.62it/s]3021it [31:12,  1.62it/s]3022it [31:13,  1.62it/s]3023it [31:13,  1.62it/s]3024it [31:14,  1.62it/s]3025it [31:15,  1.62it/s]3026it [31:15,  1.62it/s]3027it [31:16,  1.62it/s]3028it [31:16,  1.62it/s]3029it [31:17,  1.62it/s]3030it [31:18,  1.62it/s]3031it [31:18,  1.62it/s]3032it [31:19,  1.62it/s]3033it [31:20,  1.62it/s]3034it [31:20,  1.62it/s]3035it [31:21,  1.62it/s]3036it [31:21,  1.62it/s]3037it [31:22,  1.62it/s]3038it [31:23,  1.62it/s]3039it [31:23,  1.62it/s]3040it [31:24,  1.62it/s]3041it [31:24,  1.62it/s]3042it [31:25,  1.62it/s]3043it [31:26,  1.62it/s]3044it [31:26,  1.62it/s]3045it [31:27,  1.62it/s]3046it [31:28,  1.61it/s]3047it [31:28,  1.61it/s]3048it [31:29,  1.62it/s]3049it [31:29,  1.62it/s]3050it [31:30,  1.62it/s]3051it [31:31,  1.62it/s]3052it [31:31,  1.62it/s]3053it [31:32,  1.62it/s]3054it [31:32,  1.62it/s]3055it [31:33,  1.62it/s]3056it [31:34,  1.62it/s]3057it [31:34,  1.62it/s]3058it [31:35,  1.62it/s]3059it [31:36,  1.62it/s]3060it [31:36,  1.62it/s]3061it [31:37,  1.62it/s]3062it [31:37,  1.62it/s]3063it [31:38,  1.62it/s]3064it [31:39,  1.63it/s]3065it [31:39,  1.62it/s]3066it [31:40,  1.63it/s]3067it [31:41,  1.62it/s]3068it [31:41,  1.62it/s]3069it [31:42,  1.62it/s]3070it [31:42,  1.62it/s]3071it [31:43,  1.62it/s]3072it [31:44,  1.63it/s]3073it [31:44,  1.62it/s]3074it [31:45,  1.62it/s]3075it [31:45,  1.62it/s]3076it [31:46,  1.62it/s]3077it [31:47,  1.62it/s]3078it [31:47,  1.62it/s]3079it [31:48,  1.62it/s]3080it [31:49,  1.62it/s]3081it [31:49,  1.63it/s]3082it [31:50,  1.62it/s]3083it [31:50,  1.62it/s]3084it [31:51,  1.63it/s]3085it [31:52,  1.62it/s]3086it [31:52,  1.63it/s]3087it [31:53,  1.62it/s]3088it [31:53,  1.62it/s]3089it [31:54,  1.62it/s]3090it [31:55,  1.62it/s]3091it [31:55,  1.62it/s]3092it [31:56,  1.62it/s]3093it [31:57,  1.62it/s]3094it [31:57,  1.62it/s]3095it [31:58,  1.62it/s]3096it [31:58,  1.62it/s]3097it [31:59,  1.62it/s]3098it [32:00,  1.62it/s]3099it [32:00,  1.62it/s]step: 003100 	 epe: 5.034
Save checkpoint at step: 3100
3100it [32:01,  1.33it/s]3101it [32:02,  1.41it/s]3102it [32:03,  1.47it/s]3103it [32:03,  1.51it/s]3104it [32:04,  1.54it/s]3105it [32:04,  1.57it/s]3106it [32:05,  1.58it/s]3107it [32:06,  1.60it/s]3108it [32:06,  1.59it/s]3109it [32:07,  1.60it/s]3110it [32:07,  1.61it/s]3111it [32:08,  1.61it/s]3112it [32:09,  1.62it/s]3113it [32:09,  1.62it/s]3114it [32:10,  1.62it/s]3115it [32:11,  1.62it/s]3116it [32:11,  1.62it/s]3117it [32:12,  1.62it/s]3118it [32:12,  1.62it/s]3119it [32:13,  1.62it/s]3120it [32:14,  1.63it/s]3121it [32:14,  1.62it/s]3122it [32:15,  1.62it/s]3123it [32:15,  1.62it/s]3124it [32:16,  1.62it/s]3125it [32:17,  1.62it/s]3126it [32:17,  1.62it/s]3127it [32:18,  1.63it/s]3128it [32:19,  1.63it/s]3129it [32:19,  1.63it/s]3130it [32:20,  1.63it/s]3131it [32:20,  1.62it/s]3132it [32:21,  1.62it/s]3133it [32:22,  1.63it/s]3134it [32:22,  1.63it/s]3135it [32:23,  1.63it/s]3136it [32:23,  1.63it/s]3137it [32:24,  1.64it/s]3138it [32:25,  1.65it/s]3139it [32:25,  1.65it/s]3140it [32:26,  1.65it/s]3141it [32:26,  1.64it/s]3142it [32:27,  1.64it/s]3143it [32:28,  1.64it/s]3144it [32:28,  1.63it/s]3145it [32:29,  1.63it/s]3146it [32:30,  1.63it/s]3147it [32:30,  1.62it/s]3148it [32:31,  1.62it/s]3149it [32:31,  1.62it/s]3150it [32:32,  1.62it/s]3151it [32:33,  1.62it/s]3152it [32:33,  1.62it/s]3153it [32:34,  1.62it/s]3154it [32:35,  1.62it/s]3155it [32:35,  1.62it/s]3156it [32:36,  1.62it/s]3157it [32:36,  1.61it/s]3158it [32:37,  1.62it/s]3159it [32:38,  1.62it/s]3160it [32:38,  1.62it/s]3161it [32:39,  1.62it/s]3162it [32:39,  1.62it/s]3163it [32:40,  1.62it/s]3164it [32:41,  1.62it/s]3165it [32:41,  1.62it/s]3166it [32:42,  1.62it/s]3167it [32:43,  1.62it/s]3168it [32:43,  1.62it/s]3169it [32:44,  1.62it/s]3170it [32:44,  1.61it/s]3171it [32:45,  1.62it/s]3172it [32:46,  1.63it/s]3173it [32:46,  1.63it/s]3174it [32:47,  1.63it/s]3175it [32:47,  1.63it/s]3176it [32:48,  1.62it/s]3177it [32:49,  1.63it/s]3178it [32:49,  1.62it/s]3179it [32:50,  1.62it/s]3180it [32:51,  1.62it/s]3181it [32:51,  1.62it/s]3182it [32:52,  1.62it/s]3183it [32:52,  1.62it/s]3184it [32:53,  1.62it/s]3185it [32:54,  1.62it/s]3186it [32:54,  1.62it/s]3187it [32:55,  1.62it/s]3188it [32:55,  1.61it/s]3189it [32:56,  1.62it/s]3190it [32:57,  1.62it/s]3191it [32:57,  1.62it/s]3192it [32:58,  1.62it/s]3193it [32:59,  1.62it/s]3194it [32:59,  1.62it/s]3195it [33:00,  1.63it/s]3196it [33:00,  1.63it/s]3197it [33:01,  1.62it/s]3198it [33:02,  1.62it/s]3199it [33:02,  1.62it/s]step: 003200 	 epe: 2.717
Save checkpoint at step: 3200
3200it [33:03,  1.33it/s]3201it [33:04,  1.41it/s]3202it [33:05,  1.46it/s]3203it [33:05,  1.51it/s]3204it [33:06,  1.55it/s]3205it [33:06,  1.57it/s]3206it [33:07,  1.59it/s]3207it [33:08,  1.60it/s]3208it [33:08,  1.61it/s]3209it [33:09,  1.61it/s]3210it [33:09,  1.61it/s]3211it [33:10,  1.62it/s]3212it [33:11,  1.61it/s]3213it [33:11,  1.61it/s]3214it [33:12,  1.61it/s]3215it [33:13,  1.61it/s]3216it [33:13,  1.61it/s]3217it [33:14,  1.61it/s]3218it [33:14,  1.62it/s]3219it [33:15,  1.62it/s]3220it [33:16,  1.62it/s]3221it [33:16,  1.63it/s]3222it [33:17,  1.62it/s]3223it [33:18,  1.62it/s]3224it [33:18,  1.63it/s]3225it [33:19,  1.63it/s]3226it [33:19,  1.63it/s]3227it [33:20,  1.63it/s]3228it [33:21,  1.63it/s]3229it [33:21,  1.62it/s]3230it [33:22,  1.63it/s]3231it [33:22,  1.62it/s]3232it [33:23,  1.62it/s]3233it [33:24,  1.62it/s]3234it [33:24,  1.62it/s]3235it [33:25,  1.62it/s]3236it [33:26,  1.62it/s]3237it [33:26,  1.62it/s]3238it [33:27,  1.62it/s]3239it [33:27,  1.62it/s]3240it [33:28,  1.63it/s]3241it [33:29,  1.63it/s]3242it [33:29,  1.62it/s]3243it [33:30,  1.62it/s]3244it [33:30,  1.62it/s]3245it [33:31,  1.62it/s]3246it [33:32,  1.62it/s]3247it [33:32,  1.63it/s]3248it [33:33,  1.63it/s]3249it [33:34,  1.62it/s]3250it [33:34,  1.62it/s]3251it [33:35,  1.62it/s]3252it [33:35,  1.62it/s]3253it [33:36,  1.63it/s]3254it [33:37,  1.63it/s]3255it [33:37,  1.63it/s]3256it [33:38,  1.63it/s]3257it [33:38,  1.63it/s]3258it [33:39,  1.63it/s]3259it [33:40,  1.63it/s]3260it [33:40,  1.63it/s]3261it [33:41,  1.63it/s]3262it [33:41,  1.63it/s]3263it [33:42,  1.63it/s]3264it [33:43,  1.63it/s]3265it [33:43,  1.63it/s]3266it [33:44,  1.63it/s]3267it [33:45,  1.63it/s]3268it [33:45,  1.63it/s]3269it [33:46,  1.63it/s]3270it [33:46,  1.62it/s]3271it [33:47,  1.63it/s]3272it [33:48,  1.63it/s]3273it [33:48,  1.64it/s]3274it [33:49,  1.64it/s]3275it [33:49,  1.65it/s]3276it [33:50,  1.64it/s]3277it [33:51,  1.64it/s]3278it [33:51,  1.64it/s]3279it [33:52,  1.63it/s]3280it [33:53,  1.63it/s]3281it [33:53,  1.63it/s]3282it [33:54,  1.63it/s]3283it [33:54,  1.62it/s]3284it [33:55,  1.63it/s]3285it [33:56,  1.63it/s]3286it [33:56,  1.63it/s]3287it [33:57,  1.62it/s]3288it [33:57,  1.63it/s]3289it [33:58,  1.63it/s]3290it [33:59,  1.63it/s]3291it [33:59,  1.62it/s]3292it [34:00,  1.62it/s]3293it [34:01,  1.62it/s]3294it [34:01,  1.62it/s]3295it [34:02,  1.62it/s]3296it [34:02,  1.62it/s]3297it [34:03,  1.62it/s]3298it [34:04,  1.62it/s]3299it [34:04,  1.61it/s]step: 003300 	 epe: 13.058
Save checkpoint at step: 3300
3300it [34:05,  1.34it/s]3301it [34:06,  1.41it/s]3302it [34:07,  1.47it/s]3303it [34:07,  1.52it/s]3304it [34:08,  1.54it/s]3305it [34:08,  1.57it/s]3306it [34:09,  1.58it/s]3307it [34:10,  1.59it/s]3308it [34:10,  1.60it/s]3309it [34:11,  1.60it/s]3310it [34:11,  1.62it/s]3311it [34:12,  1.62it/s]3312it [34:13,  1.61it/s]3313it [34:13,  1.62it/s]3314it [34:14,  1.62it/s]3315it [34:15,  1.62it/s]3316it [34:15,  1.63it/s]3317it [34:16,  1.64it/s]3318it [34:16,  1.64it/s]3319it [34:17,  1.63it/s]3320it [34:18,  1.64it/s]3321it [34:18,  1.64it/s]3322it [34:19,  1.64it/s]3323it [34:19,  1.64it/s]3324it [34:20,  1.64it/s]3325it [34:21,  1.63it/s]3326it [34:21,  1.63it/s]3327it [34:22,  1.62it/s]3328it [34:22,  1.62it/s]3329it [34:23,  1.63it/s]3330it [34:24,  1.62it/s]3331it [34:24,  1.62it/s]3332it [34:25,  1.62it/s]3333it [34:26,  1.62it/s]3334it [34:26,  1.63it/s]3335it [34:27,  1.63it/s]3336it [34:27,  1.62it/s]3337it [34:28,  1.62it/s]3338it [34:29,  1.62it/s]3339it [34:29,  1.61it/s]3340it [34:30,  1.61it/s]3341it [34:31,  1.62it/s]3342it [34:31,  1.62it/s]3343it [34:32,  1.62it/s]3344it [34:32,  1.63it/s]3345it [34:33,  1.63it/s]3346it [34:34,  1.62it/s]3347it [34:34,  1.63it/s]3348it [34:35,  1.62it/s]3349it [34:35,  1.62it/s]3350it [34:36,  1.60it/s]3351it [34:37,  1.60it/s]3352it [34:37,  1.61it/s]3353it [34:38,  1.61it/s]3354it [34:39,  1.61it/s]3355it [34:39,  1.61it/s]3356it [34:40,  1.62it/s]3357it [34:40,  1.61it/s]3358it [34:41,  1.61it/s]3359it [34:42,  1.61it/s]3360it [34:42,  1.61it/s]3361it [34:43,  1.61it/s]3362it [34:44,  1.61it/s]3363it [34:44,  1.62it/s]3364it [34:45,  1.62it/s]3365it [34:45,  1.63it/s]3366it [34:46,  1.62it/s]3367it [34:47,  1.63it/s]3368it [34:47,  1.63it/s]3369it [34:48,  1.62it/s]3370it [34:48,  1.63it/s]3371it [34:49,  1.63it/s]3372it [34:50,  1.61it/s]3373it [34:50,  1.61it/s]3374it [34:51,  1.62it/s]3375it [34:52,  1.62it/s]3376it [34:52,  1.62it/s]3377it [34:53,  1.62it/s]3378it [34:53,  1.62it/s]3379it [34:54,  1.61it/s]3380it [34:55,  1.61it/s]3381it [34:55,  1.62it/s]3382it [34:56,  1.61it/s]3383it [34:56,  1.62it/s]3384it [34:57,  1.62it/s]3385it [34:58,  1.62it/s]3386it [34:58,  1.62it/s]3387it [34:59,  1.62it/s]3388it [35:00,  1.61it/s]3389it [35:00,  1.61it/s]3390it [35:01,  1.62it/s]3391it [35:01,  1.61it/s]3392it [35:02,  1.60it/s]3393it [35:03,  1.61it/s]3394it [35:03,  1.61it/s]3395it [35:04,  1.61it/s]3396it [35:05,  1.61it/s]3397it [35:05,  1.61it/s]3398it [35:06,  1.61it/s]3399it [35:06,  1.61it/s]step: 003400 	 epe: 2.911
Save checkpoint at step: 3400
3400it [35:07,  1.35it/s]3401it [35:08,  1.42it/s]3402it [35:09,  1.47it/s]3403it [35:09,  1.51it/s]3404it [35:10,  1.54it/s]3405it [35:11,  1.56it/s]3406it [35:11,  1.58it/s]3407it [35:12,  1.59it/s]3408it [35:12,  1.60it/s]3409it [35:13,  1.61it/s]3410it [35:14,  1.61it/s]3411it [35:14,  1.60it/s]3412it [35:15,  1.61it/s]3413it [35:15,  1.61it/s]3414it [35:16,  1.61it/s]3415it [35:17,  1.61it/s]3416it [35:17,  1.61it/s]3417it [35:18,  1.61it/s]3418it [35:19,  1.61it/s]3419it [35:19,  1.61it/s]3420it [35:20,  1.62it/s]3421it [35:20,  1.62it/s]3422it [35:21,  1.62it/s]3423it [35:22,  1.62it/s]3424it [35:22,  1.61it/s]3425it [35:23,  1.61it/s]3426it [35:24,  1.61it/s]3427it [35:24,  1.61it/s]3428it [35:25,  1.61it/s]3429it [35:25,  1.62it/s]3430it [35:26,  1.61it/s]3431it [35:27,  1.62it/s]3432it [35:27,  1.62it/s]3433it [35:28,  1.62it/s]3434it [35:28,  1.61it/s]3435it [35:29,  1.61it/s]3436it [35:30,  1.61it/s]3437it [35:30,  1.61it/s]3438it [35:31,  1.61it/s]3439it [35:32,  1.61it/s]3440it [35:32,  1.61it/s]3441it [35:33,  1.61it/s]3442it [35:33,  1.62it/s]3443it [35:34,  1.62it/s]3444it [35:35,  1.62it/s]3445it [35:35,  1.62it/s]3446it [35:36,  1.62it/s]3447it [35:37,  1.63it/s]3448it [35:37,  1.63it/s]3449it [35:38,  1.63it/s]3450it [35:38,  1.63it/s]3451it [35:39,  1.62it/s]3452it [35:40,  1.63it/s]3453it [35:40,  1.63it/s]3454it [35:41,  1.63it/s]3455it [35:41,  1.63it/s]3456it [35:42,  1.63it/s]3457it [35:43,  1.62it/s]3458it [35:43,  1.62it/s]3459it [35:44,  1.62it/s]3460it [35:45,  1.61it/s]3461it [35:45,  1.62it/s]3462it [35:46,  1.62it/s]3463it [35:46,  1.62it/s]3464it [35:47,  1.62it/s]3465it [35:48,  1.62it/s]3466it [35:48,  1.62it/s]3467it [35:49,  1.62it/s]3468it [35:49,  1.61it/s]3469it [35:50,  1.62it/s]3470it [35:51,  1.62it/s]3471it [35:51,  1.62it/s]3472it [35:52,  1.62it/s]3473it [35:53,  1.62it/s]3474it [35:53,  1.61it/s]3475it [35:54,  1.62it/s]3476it [35:54,  1.61it/s]3477it [35:55,  1.61it/s]3478it [35:56,  1.62it/s]3479it [35:56,  1.62it/s]3480it [35:57,  1.61it/s]3481it [35:58,  1.62it/s]3482it [35:58,  1.62it/s]3483it [35:59,  1.61it/s]3484it [35:59,  1.62it/s]3485it [36:00,  1.62it/s]3486it [36:01,  1.62it/s]3487it [36:01,  1.62it/s]3488it [36:02,  1.62it/s]3489it [36:02,  1.62it/s]3490it [36:03,  1.63it/s]3491it [36:04,  1.62it/s]3492it [36:04,  1.62it/s]3493it [36:05,  1.63it/s]3494it [36:06,  1.62it/s]3495it [36:06,  1.62it/s]3496it [36:07,  1.62it/s]3497it [36:07,  1.62it/s]3498it [36:08,  1.63it/s]3499it [36:09,  1.63it/s]step: 003500 	 epe: 4.777
Save checkpoint at step: 3500
3500it [36:10,  1.34it/s]3501it [36:10,  1.42it/s]3502it [36:11,  1.47it/s]3503it [36:12,  1.51it/s]3504it [36:12,  1.54it/s]3505it [36:13,  1.56it/s]3506it [36:13,  1.58it/s]3507it [36:14,  1.59it/s]3508it [36:15,  1.60it/s]3509it [36:15,  1.61it/s]3510it [36:16,  1.61it/s]3511it [36:16,  1.62it/s]3512it [36:17,  1.62it/s]3513it [36:18,  1.62it/s]3514it [36:18,  1.62it/s]3515it [36:19,  1.62it/s]3516it [36:20,  1.62it/s]3517it [36:20,  1.63it/s]3518it [36:21,  1.63it/s]3519it [36:21,  1.63it/s]3520it [36:22,  1.62it/s]3521it [36:23,  1.61it/s]3522it [36:23,  1.62it/s]3523it [36:24,  1.61it/s]3524it [36:24,  1.62it/s]3525it [36:25,  1.62it/s]3526it [36:26,  1.63it/s]3527it [36:26,  1.63it/s]3528it [36:27,  1.62it/s]3529it [36:28,  1.63it/s]3530it [36:28,  1.63it/s]3531it [36:29,  1.63it/s]3532it [36:29,  1.62it/s]3533it [36:30,  1.63it/s]3534it [36:31,  1.62it/s]3535it [36:31,  1.62it/s]3536it [36:32,  1.62it/s]3537it [36:32,  1.62it/s]3538it [36:33,  1.62it/s]3539it [36:34,  1.62it/s]3540it [36:34,  1.62it/s]3541it [36:35,  1.62it/s]3542it [36:36,  1.62it/s]3543it [36:36,  1.61it/s]3544it [36:37,  1.61it/s]3545it [36:37,  1.61it/s]3546it [36:38,  1.61it/s]3547it [36:39,  1.61it/s]3548it [36:39,  1.61it/s]3549it [36:40,  1.61it/s]3550it [36:41,  1.61it/s]3551it [36:41,  1.61it/s]3552it [36:42,  1.61it/s]3553it [36:42,  1.61it/s]3554it [36:43,  1.62it/s]3555it [36:44,  1.61it/s]3556it [36:44,  1.62it/s]3557it [36:45,  1.62it/s]3558it [36:45,  1.62it/s]3559it [36:46,  1.62it/s]3560it [36:47,  1.62it/s]3561it [36:47,  1.62it/s]3562it [36:48,  1.62it/s]3563it [36:49,  1.61it/s]3564it [36:49,  1.61it/s]3565it [36:50,  1.62it/s]3566it [36:50,  1.61it/s]3567it [36:51,  1.61it/s]3568it [36:52,  1.61it/s]3569it [36:52,  1.61it/s]3570it [36:53,  1.60it/s]3571it [36:54,  1.61it/s]3572it [36:54,  1.62it/s]3573it [36:55,  1.61it/s]3574it [36:55,  1.62it/s]3575it [36:56,  1.61it/s]3576it [36:57,  1.61it/s]3577it [36:57,  1.62it/s]3578it [36:58,  1.62it/s]3579it [36:58,  1.62it/s]3580it [36:59,  1.62it/s]3581it [37:00,  1.63it/s]3582it [37:00,  1.63it/s]3583it [37:01,  1.63it/s]3584it [37:02,  1.63it/s]3585it [37:02,  1.63it/s]3586it [37:03,  1.63it/s]3587it [37:03,  1.63it/s]3588it [37:04,  1.63it/s]3589it [37:05,  1.63it/s]3590it [37:05,  1.64it/s]3591it [37:06,  1.64it/s]3592it [37:06,  1.64it/s]3593it [37:07,  1.64it/s]3594it [37:08,  1.64it/s]3595it [37:08,  1.63it/s]3596it [37:09,  1.63it/s]3597it [37:09,  1.64it/s]3598it [37:10,  1.63it/s]3599it [37:11,  1.64it/s]step: 003600 	 epe: 3.618
Save checkpoint at step: 3600
3600it [37:12,  1.38it/s]3600it [37:12,  1.61it/s]
total_steps = 3600
0.1962285041809082 Go allocated
0it [00:00, ?it/s]1it [00:00,  1.28it/s]2it [00:01,  1.46it/s]3it [00:02,  1.54it/s]4it [00:02,  1.58it/s]5it [00:03,  1.59it/s]6it [00:03,  1.61it/s]7it [00:04,  1.61it/s]8it [00:05,  1.62it/s]9it [00:05,  1.62it/s]10it [00:06,  1.63it/s]11it [00:06,  1.63it/s]12it [00:07,  1.63it/s]13it [00:08,  1.63it/s]14it [00:08,  1.63it/s]15it [00:09,  1.63it/s]16it [00:09,  1.63it/s]17it [00:10,  1.63it/s]18it [00:11,  1.63it/s]19it [00:11,  1.63it/s]20it [00:12,  1.63it/s]21it [00:13,  1.64it/s]22it [00:13,  1.63it/s]23it [00:14,  1.63it/s]24it [00:14,  1.63it/s]25it [00:15,  1.63it/s]26it [00:16,  1.63it/s]27it [00:16,  1.62it/s]28it [00:17,  1.63it/s]29it [00:17,  1.63it/s]30it [00:18,  1.63it/s]31it [00:19,  1.63it/s]32it [00:19,  1.63it/s]33it [00:20,  1.63it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Namespace(checkpoint_dir='checkpoints_stereo/StereoHybrid', stage='hybrid', val_dataset=['kitti15'], max_disp=400, img_height=384, img_width=768, padding_factor=32, batch_size=1, num_workers=8, lr=0.0004, weight_decay=0.0001, seed=326, resume='checkpoints_stereo/StereoHybrid/step_005900.pth', strict_resume=False, no_resume_optimizer=True, resume_exclude_upsampler=False, task='stereo', num_scales=2, feature_channels=128, upsample_factor=4, num_head=1, ffn_dim_expansion=4, num_transformer_layers=6, reg_refine=True, attn_type='self_swin2d_cross_swin1d', attn_splits_list=[2, 8], corr_radius_list=[-1, 4], prop_radius_list=[-1, 1], num_reg_refine=3, eval=False, inference_size=None, count_time=False, save_vis_disp=False, save_dir=None, middlebury_resolution='F', submission=False, eth_submission_mode='train', middlebury_submission_mode='training', output_path='output', summary_freq=100, save_ckpt_freq=1000, val_freq=10000, save_latest_ckpt_freq=100, num_steps=100000, distributed=False, local_rank=0, launcher='pytorch', gpu_ids=0, inference_dir=None, inference_dir_left=None, inference_dir_right=None, pred_bidir_disp=False, pred_right_disp=False, save_pfm_disp=False, debug=False)
args.launcher = 'pytorch'
=> Number of trainable parameters: 7354416
=> Load checkpoint: checkpoints_stereo/StereoHybrid/step_005900.pth
start_epoch: 0, start_step: 0
=> 3600 training samples found in the training set
2023-03-02 17:08:17.500364: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-02 17:08:17.615618: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2023-03-02 17:08:18.029259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 17:08:18.029312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.9/dist-packages/cv2/../../lib64:
2023-03-02 17:08:18.029318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
=> Start training...
total_steps = 0
0.08244705200195312 Go allocated
0it [00:00, ?it/s]/home/godeta/.local/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
1it [00:03,  3.70s/it]2it [00:04,  1.80s/it]3it [00:04,  1.21s/it]4it [00:05,  1.08it/s]5it [00:05,  1.30it/s]6it [00:06,  1.48it/s]7it [00:06,  1.62it/s]8it [00:07,  1.73it/s]9it [00:07,  1.80it/s]10it [00:08,  1.86it/s]11it [00:08,  1.90it/s]12it [00:09,  1.93it/s]13it [00:09,  1.95it/s]14it [00:10,  1.96it/s]15it [00:10,  1.97it/s]16it [00:11,  1.98it/s]17it [00:11,  1.99it/s]18it [00:12,  2.00it/s]19it [00:12,  1.99it/s]20it [00:13,  2.00it/s]21it [00:13,  1.92it/s]22it [00:14,  1.84it/s]23it [00:14,  1.78it/s]24it [00:15,  1.74it/s]25it [00:16,  1.71it/s]26it [00:16,  1.70it/s]27it [00:17,  1.68it/s]28it [00:17,  1.67it/s]29it [00:18,  1.67it/s]30it [00:19,  1.66it/s]31it [00:19,  1.66it/s]32it [00:20,  1.66it/s]33it [00:20,  1.65it/s]34it [00:21,  1.65it/s]35it [00:22,  1.65it/s]36it [00:22,  1.65it/s]37it [00:23,  1.65it/s]38it [00:24,  1.65it/s]39it [00:24,  1.65it/s]40it [00:25,  1.65it/s]41it [00:25,  1.65it/s]42it [00:26,  1.65it/s]43it [00:27,  1.64it/s]44it [00:27,  1.64it/s]45it [00:28,  1.65it/s]46it [00:28,  1.65it/s]47it [00:29,  1.65it/s]48it [00:30,  1.64it/s]49it [00:30,  1.65it/s]50it [00:31,  1.65it/s]51it [00:31,  1.65it/s]52it [00:32,  1.65it/s]53it [00:33,  1.65it/s]54it [00:33,  1.65it/s]55it [00:34,  1.65it/s]56it [00:34,  1.64it/s]57it [00:35,  1.64it/s]58it [00:36,  1.64it/s]59it [00:36,  1.64it/s]60it [00:37,  1.64it/s]61it [00:37,  1.64it/s]62it [00:38,  1.64it/s]63it [00:39,  1.64it/s]64it [00:39,  1.64it/s]65it [00:40,  1.64it/s]66it [00:41,  1.65it/s]67it [00:41,  1.64it/s]68it [00:42,  1.64it/s]69it [00:42,  1.64it/s]70it [00:43,  1.64it/s]71it [00:44,  1.64it/s]72it [00:44,  1.64it/s]73it [00:45,  1.64it/s]74it [00:45,  1.64it/s]75it [00:46,  1.64it/s]76it [00:47,  1.63it/s]77it [00:47,  1.63it/s]78it [00:48,  1.63it/s]79it [00:48,  1.64it/s]80it [00:49,  1.63it/s]81it [00:50,  1.63it/s]82it [00:50,  1.63it/s]83it [00:51,  1.63it/s]84it [00:52,  1.63it/s]85it [00:52,  1.63it/s]86it [00:53,  1.63it/s]87it [00:53,  1.64it/s]88it [00:54,  1.63it/s]89it [00:55,  1.63it/s]90it [00:55,  1.63it/s]91it [00:56,  1.63it/s]92it [00:56,  1.63it/s]93it [00:57,  1.63it/s]94it [00:58,  1.63it/s]95it [00:58,  1.63it/s]96it [00:59,  1.63it/s]97it [01:00,  1.63it/s]98it [01:00,  1.63it/s]99it [01:01,  1.63it/s]step: 000100 	 epe: 5.255
100it [01:02,  1.35it/s]101it [01:02,  1.42it/s]102it [01:03,  1.48it/s]103it [01:04,  1.52it/s]104it [01:04,  1.55it/s]105it [01:05,  1.57it/s]106it [01:05,  1.59it/s]107it [01:06,  1.61it/s]108it [01:07,  1.62it/s]109it [01:07,  1.62it/s]110it [01:08,  1.63it/s]111it [01:09,  1.63it/s]112it [01:09,  1.64it/s]113it [01:10,  1.64it/s]114it [01:10,  1.63it/s]115it [01:11,  1.64it/s]116it [01:12,  1.64it/s]117it [01:12,  1.64it/s]118it [01:13,  1.64it/s]119it [01:13,  1.64it/s]120it [01:14,  1.64it/s]121it [01:15,  1.64it/s]122it [01:15,  1.64it/s]123it [01:16,  1.64it/s]124it [01:16,  1.64it/s]125it [01:17,  1.64it/s]126it [01:18,  1.64it/s]127it [01:18,  1.64it/s]128it [01:19,  1.64it/s]129it [01:19,  1.63it/s]130it [01:20,  1.63it/s]131it [01:21,  1.63it/s]132it [01:21,  1.62it/s]133it [01:22,  1.63it/s]134it [01:23,  1.63it/s]135it [01:23,  1.62it/s]136it [01:24,  1.63it/s]137it [01:24,  1.63it/s]138it [01:25,  1.63it/s]139it [01:26,  1.62it/s]140it [01:26,  1.62it/s]141it [01:27,  1.63it/s]142it [01:27,  1.63it/s]143it [01:28,  1.63it/s]144it [01:29,  1.62it/s]145it [01:29,  1.62it/s]146it [01:30,  1.62it/s]147it [01:31,  1.62it/s]148it [01:31,  1.62it/s]149it [01:32,  1.62it/s]150it [01:32,  1.62it/s]151it [01:33,  1.62it/s]152it [01:34,  1.62it/s]153it [01:34,  1.62it/s]154it [01:35,  1.62it/s]155it [01:36,  1.63it/s]156it [01:36,  1.63it/s]157it [01:37,  1.63it/s]158it [01:37,  1.63it/s]159it [01:38,  1.63it/s]160it [01:39,  1.63it/s]161it [01:39,  1.63it/s]162it [01:40,  1.63it/s]163it [01:40,  1.63it/s]164it [01:41,  1.63it/s]165it [01:42,  1.63it/s]166it [01:42,  1.63it/s]167it [01:43,  1.63it/s]168it [01:43,  1.63it/s]169it [01:44,  1.62it/s]170it [01:45,  1.62it/s]171it [01:45,  1.63it/s]172it [01:46,  1.63it/s]173it [01:47,  1.63it/s]174it [01:47,  1.63it/s]175it [01:48,  1.63it/s]176it [01:48,  1.63it/s]177it [01:49,  1.63it/s]178it [01:50,  1.63it/s]179it [01:50,  1.63it/s]180it [01:51,  1.63it/s]181it [01:51,  1.63it/s]182it [01:52,  1.63it/s]183it [01:53,  1.63it/s]184it [01:53,  1.63it/s]185it [01:54,  1.63it/s]186it [01:55,  1.63it/s]187it [01:55,  1.63it/s]188it [01:56,  1.63it/s]189it [01:56,  1.62it/s]190it [01:57,  1.62it/s]191it [01:58,  1.63it/s]192it [01:58,  1.63it/s]193it [01:59,  1.63it/s]194it [01:59,  1.63it/s]195it [02:00,  1.63it/s]196it [02:01,  1.63it/s]197it [02:01,  1.62it/s]198it [02:02,  1.62it/s]199it [02:03,  1.62it/s]step: 000200 	 epe: 7.877
200it [02:04,  1.35it/s]201it [02:04,  1.42it/s]202it [02:05,  1.48it/s]203it [02:05,  1.52it/s]204it [02:06,  1.55it/s]205it [02:07,  1.57it/s]206it [02:07,  1.59it/s]207it [02:08,  1.60it/s]208it [02:08,  1.60it/s]209it [02:09,  1.61it/s]210it [02:10,  1.61it/s]211it [02:10,  1.61it/s]212it [02:11,  1.61it/s]213it [02:12,  1.62it/s]214it [02:12,  1.62it/s]215it [02:13,  1.62it/s]216it [02:13,  1.62it/s]217it [02:14,  1.63it/s]218it [02:15,  1.63it/s]219it [02:15,  1.63it/s]220it [02:16,  1.62it/s]221it [02:16,  1.62it/s]222it [02:17,  1.63it/s]223it [02:18,  1.63it/s]224it [02:18,  1.63it/s]225it [02:19,  1.63it/s]226it [02:20,  1.63it/s]227it [02:20,  1.63it/s]228it [02:21,  1.63it/s]229it [02:21,  1.63it/s]230it [02:22,  1.63it/s]231it [02:23,  1.63it/s]232it [02:23,  1.63it/s]233it [02:24,  1.63it/s]234it [02:24,  1.63it/s]235it [02:25,  1.63it/s]236it [02:26,  1.63it/s]237it [02:26,  1.62it/s]238it [02:27,  1.62it/s]239it [02:28,  1.62it/s]240it [02:28,  1.62it/s]241it [02:29,  1.62it/s]242it [02:29,  1.63it/s]243it [02:30,  1.63it/s]244it [02:31,  1.62it/s]245it [02:31,  1.62it/s]246it [02:32,  1.62it/s]247it [02:32,  1.62it/s]248it [02:33,  1.62it/s]249it [02:34,  1.62it/s]250it [02:34,  1.63it/s]251it [02:35,  1.63it/s]252it [02:36,  1.63it/s]253it [02:36,  1.63it/s]254it [02:37,  1.62it/s]255it [02:37,  1.62it/s]256it [02:38,  1.62it/s]257it [02:39,  1.63it/s]258it [02:39,  1.63it/s]259it [02:40,  1.63it/s]260it [02:40,  1.62it/s]261it [02:41,  1.62it/s]262it [02:42,  1.62it/s]263it [02:42,  1.62it/s]264it [02:43,  1.62it/s]265it [02:44,  1.62it/s]266it [02:44,  1.62it/s]267it [02:45,  1.63it/s]268it [02:45,  1.63it/s]269it [02:46,  1.63it/s]270it [02:47,  1.62it/s]271it [02:47,  1.62it/s]272it [02:48,  1.62it/s]273it [02:48,  1.62it/s]274it [02:49,  1.62it/s]275it [02:50,  1.62it/s]276it [02:50,  1.62it/s]277it [02:51,  1.63it/s]278it [02:52,  1.63it/s]279it [02:52,  1.62it/s]280it [02:53,  1.62it/s]281it [02:53,  1.62it/s]282it [02:54,  1.62it/s]283it [02:55,  1.62it/s]284it [02:55,  1.62it/s]285it [02:56,  1.63it/s]286it [02:57,  1.63it/s]287it [02:57,  1.63it/s]288it [02:58,  1.63it/s]289it [02:58,  1.63it/s]290it [02:59,  1.63it/s]291it [03:00,  1.62it/s]292it [03:00,  1.62it/s]293it [03:01,  1.62it/s]294it [03:01,  1.62it/s]295it [03:02,  1.62it/s]296it [03:03,  1.62it/s]297it [03:03,  1.63it/s]298it [03:04,  1.62it/s]299it [03:05,  1.62it/s]step: 000300 	 epe: 4.095
300it [03:06,  1.36it/s]301it [03:06,  1.43it/s]302it [03:07,  1.48it/s]303it [03:07,  1.52it/s]304it [03:08,  1.55it/s]305it [03:09,  1.57it/s]306it [03:09,  1.57it/s]307it [03:10,  1.59it/s]308it [03:10,  1.60it/s]309it [03:11,  1.61it/s]310it [03:12,  1.62it/s]311it [03:12,  1.62it/s]312it [03:13,  1.62it/s]313it [03:14,  1.62it/s]314it [03:14,  1.62it/s]315it [03:15,  1.62it/s]316it [03:15,  1.63it/s]317it [03:16,  1.63it/s]318it [03:17,  1.63it/s]319it [03:17,  1.62it/s]320it [03:18,  1.62it/s]321it [03:18,  1.62it/s]322it [03:19,  1.62it/s]323it [03:20,  1.61it/s]324it [03:20,  1.61it/s]325it [03:21,  1.62it/s]326it [03:22,  1.63it/s]327it [03:22,  1.62it/s]328it [03:23,  1.62it/s]329it [03:23,  1.62it/s]330it [03:24,  1.62it/s]331it [03:25,  1.62it/s]332it [03:25,  1.62it/s]333it [03:26,  1.62it/s]334it [03:27,  1.62it/s]335it [03:27,  1.62it/s]336it [03:28,  1.62it/s]337it [03:28,  1.62it/s]338it [03:29,  1.62it/s]339it [03:30,  1.62it/s]340it [03:30,  1.63it/s]341it [03:31,  1.63it/s]342it [03:31,  1.63it/s]343it [03:32,  1.63it/s]344it [03:33,  1.63it/s]345it [03:33,  1.63it/s]346it [03:34,  1.62it/s]347it [03:35,  1.62it/s]348it [03:35,  1.62it/s]349it [03:36,  1.61it/s]350it [03:36,  1.61it/s]351it [03:37,  1.61it/s]352it [03:38,  1.61it/s]353it [03:38,  1.61it/s]354it [03:39,  1.61it/s]355it [03:39,  1.62it/s]356it [03:40,  1.62it/s]357it [03:41,  1.62it/s]358it [03:41,  1.63it/s]359it [03:42,  1.63it/s]360it [03:43,  1.63it/s]361it [03:43,  1.63it/s]362it [03:44,  1.63it/s]363it [03:44,  1.63it/s]364it [03:45,  1.63it/s]365it [03:46,  1.63it/s]366it [03:46,  1.64it/s]367it [03:47,  1.64it/s]368it [03:47,  1.63it/s]369it [03:48,  1.64it/s]370it [03:49,  1.63it/s]371it [03:49,  1.63it/s]372it [03:50,  1.62it/s]373it [03:51,  1.63it/s]374it [03:51,  1.62it/s]375it [03:52,  1.61it/s]376it [03:52,  1.62it/s]377it [03:53,  1.62it/s]378it [03:54,  1.62it/s]379it [03:54,  1.61it/s]380it [03:55,  1.62it/s]381it [03:55,  1.62it/s]382it [03:56,  1.62it/s]383it [03:57,  1.62it/s]384it [03:57,  1.62it/s]385it [03:58,  1.62it/s]386it [03:59,  1.63it/s]387it [03:59,  1.62it/s]388it [04:00,  1.62it/s]389it [04:00,  1.61it/s]390it [04:01,  1.61it/s]391it [04:02,  1.62it/s]392it [04:02,  1.61it/s]393it [04:03,  1.62it/s]394it [04:04,  1.61it/s]395it [04:04,  1.61it/s]396it [04:05,  1.62it/s]397it [04:05,  1.62it/s]398it [04:06,  1.62it/s]399it [04:07,  1.62it/s]step: 000400 	 epe: 3.727
400it [04:08,  1.35it/s]401it [04:08,  1.42it/s]402it [04:09,  1.47it/s]403it [04:09,  1.51it/s]404it [04:10,  1.54it/s]405it [04:11,  1.57it/s]406it [04:11,  1.58it/s]407it [04:12,  1.60it/s]408it [04:13,  1.61it/s]409it [04:13,  1.62it/s]410it [04:14,  1.62it/s]411it [04:14,  1.62it/s]412it [04:15,  1.62it/s]413it [04:16,  1.62it/s]414it [04:16,  1.62it/s]415it [04:17,  1.62it/s]416it [04:17,  1.62it/s]417it [04:18,  1.62it/s]418it [04:19,  1.62it/s]419it [04:19,  1.62it/s]420it [04:20,  1.62it/s]421it [04:21,  1.62it/s]422it [04:21,  1.62it/s]423it [04:22,  1.62it/s]424it [04:22,  1.63it/s]425it [04:23,  1.63it/s]426it [04:24,  1.63it/s]427it [04:24,  1.63it/s]428it [04:25,  1.63it/s]429it [04:25,  1.63it/s]430it [04:26,  1.63it/s]431it [04:27,  1.64it/s]432it [04:27,  1.64it/s]433it [04:28,  1.63it/s]434it [04:29,  1.63it/s]435it [04:29,  1.63it/s]436it [04:30,  1.63it/s]437it [04:30,  1.63it/s]438it [04:31,  1.63it/s]439it [04:32,  1.63it/s]440it [04:32,  1.63it/s]441it [04:33,  1.63it/s]442it [04:33,  1.63it/s]443it [04:34,  1.63it/s]444it [04:35,  1.63it/s]445it [04:35,  1.63it/s]446it [04:36,  1.64it/s]447it [04:36,  1.64it/s]448it [04:37,  1.63it/s]449it [04:38,  1.63it/s]450it [04:38,  1.64it/s]451it [04:39,  1.64it/s]452it [04:40,  1.63it/s]453it [04:40,  1.63it/s]454it [04:41,  1.63it/s]455it [04:41,  1.63it/s]456it [04:42,  1.63it/s]457it [04:43,  1.63it/s]458it [04:43,  1.63it/s]459it [04:44,  1.63it/s]460it [04:44,  1.62it/s]461it [04:45,  1.63it/s]462it [04:46,  1.63it/s]463it [04:46,  1.63it/s]464it [04:47,  1.63it/s]465it [04:48,  1.62it/s]466it [04:48,  1.62it/s]467it [04:49,  1.63it/s]468it [04:49,  1.62it/s]469it [04:50,  1.62it/s]470it [04:51,  1.63it/s]471it [04:51,  1.63it/s]472it [04:52,  1.62it/s]473it [04:52,  1.63it/s]474it [04:53,  1.63it/s]475it [04:54,  1.62it/s]476it [04:54,  1.63it/s]477it [04:55,  1.63it/s]478it [04:56,  1.63it/s]479it [04:56,  1.64it/s]480it [04:57,  1.64it/s]481it [04:57,  1.64it/s]482it [04:58,  1.63it/s]483it [04:59,  1.63it/s]484it [04:59,  1.63it/s]485it [05:00,  1.62it/s]486it [05:00,  1.62it/s]487it [05:01,  1.63it/s]488it [05:02,  1.63it/s]489it [05:02,  1.63it/s]490it [05:03,  1.63it/s]491it [05:03,  1.63it/s]492it [05:04,  1.64it/s]493it [05:05,  1.64it/s]494it [05:05,  1.63it/s]495it [05:06,  1.63it/s]496it [05:07,  1.63it/s]497it [05:07,  1.63it/s]498it [05:08,  1.63it/s]499it [05:08,  1.63it/s]step: 000500 	 epe: 1.916
500it [05:09,  1.37it/s]501it [05:10,  1.44it/s]502it [05:11,  1.49it/s]503it [05:11,  1.53it/s]504it [05:12,  1.56it/s]505it [05:12,  1.58it/s]506it [05:13,  1.60it/s]507it [05:14,  1.61it/s]508it [05:14,  1.62it/s]509it [05:15,  1.63it/s]510it [05:16,  1.63it/s]511it [05:16,  1.64it/s]512it [05:17,  1.63it/s]513it [05:17,  1.63it/s]514it [05:18,  1.63it/s]515it [05:19,  1.63it/s]516it [05:19,  1.64it/s]517it [05:20,  1.64it/s]518it [05:20,  1.64it/s]519it [05:21,  1.64it/s]520it [05:22,  1.63it/s]521it [05:22,  1.63it/s]522it [05:23,  1.64it/s]523it [05:23,  1.63it/s]524it [05:24,  1.64it/s]525it [05:25,  1.64it/s]526it [05:25,  1.64it/s]527it [05:26,  1.64it/s]528it [05:27,  1.63it/s]529it [05:27,  1.63it/s]530it [05:28,  1.63it/s]531it [05:28,  1.63it/s]532it [05:29,  1.63it/s]533it [05:30,  1.63it/s]534it [05:30,  1.64it/s]535it [05:31,  1.64it/s]536it [05:31,  1.64it/s]537it [05:32,  1.64it/s]538it [05:33,  1.63it/s]539it [05:33,  1.63it/s]540it [05:34,  1.63it/s]541it [05:34,  1.63it/s]542it [05:35,  1.63it/s]543it [05:36,  1.63it/s]544it [05:36,  1.63it/s]545it [05:37,  1.63it/s]546it [05:38,  1.63it/s]547it [05:38,  1.63it/s]548it [05:39,  1.63it/s]549it [05:39,  1.63it/s]550it [05:40,  1.64it/s]551it [05:41,  1.63it/s]552it [05:41,  1.63it/s]553it [05:42,  1.63it/s]554it [05:42,  1.63it/s]555it [05:43,  1.63it/s]556it [05:44,  1.63it/s]557it [05:44,  1.63it/s]558it [05:45,  1.64it/s]559it [05:46,  1.63it/s]560it [05:46,  1.63it/s]561it [05:47,  1.63it/s]562it [05:47,  1.63it/s]563it [05:48,  1.62it/s]564it [05:49,  1.63it/s]565it [05:49,  1.62it/s]566it [05:50,  1.63it/s]567it [05:50,  1.63it/s]568it [05:51,  1.64it/s]569it [05:52,  1.63it/s]570it [05:52,  1.64it/s]571it [05:53,  1.64it/s]572it [05:53,  1.64it/s]573it [05:54,  1.64it/s]574it [05:55,  1.64it/s]575it [05:55,  1.64it/s]576it [05:56,  1.64it/s]577it [05:57,  1.65it/s]578it [05:57,  1.64it/s]579it [05:58,  1.63it/s]580it [05:58,  1.63it/s]581it [05:59,  1.63it/s]582it [06:00,  1.63it/s]583it [06:00,  1.63it/s]584it [06:01,  1.63it/s]585it [06:01,  1.63it/s]586it [06:02,  1.63it/s]587it [06:03,  1.63it/s]588it [06:03,  1.63it/s]589it [06:04,  1.64it/s]590it [06:04,  1.64it/s]591it [06:05,  1.64it/s]592it [06:06,  1.64it/s]593it [06:06,  1.64it/s]594it [06:07,  1.63it/s]595it [06:08,  1.63it/s]596it [06:08,  1.64it/s]597it [06:09,  1.64it/s]598it [06:09,  1.63it/s]599it [06:10,  1.64it/s]step: 000600 	 epe: 5.919
600it [06:11,  1.39it/s]601it [06:12,  1.46it/s]602it [06:12,  1.51it/s]603it [06:13,  1.54it/s]604it [06:13,  1.56it/s]605it [06:14,  1.58it/s]606it [06:15,  1.59it/s]607it [06:15,  1.61it/s]608it [06:16,  1.61it/s]609it [06:16,  1.62it/s]610it [06:17,  1.62it/s]611it [06:18,  1.62it/s]612it [06:18,  1.63it/s]613it [06:19,  1.63it/s]614it [06:20,  1.63it/s]615it [06:20,  1.63it/s]616it [06:21,  1.63it/s]617it [06:21,  1.63it/s]618it [06:22,  1.63it/s]619it [06:23,  1.63it/s]620it [06:23,  1.63it/s]621it [06:24,  1.63it/s]622it [06:24,  1.63it/s]623it [06:25,  1.63it/s]624it [06:26,  1.63it/s]625it [06:26,  1.63it/s]626it [06:27,  1.63it/s]627it [06:28,  1.63it/s]628it [06:28,  1.63it/s]629it [06:29,  1.63it/s]630it [06:29,  1.63it/s]631it [06:30,  1.63it/s]632it [06:31,  1.62it/s]633it [06:31,  1.62it/s]634it [06:32,  1.63it/s]635it [06:32,  1.62it/s]636it [06:33,  1.63it/s]637it [06:34,  1.62it/s]638it [06:34,  1.63it/s]639it [06:35,  1.63it/s]640it [06:36,  1.63it/s]641it [06:36,  1.63it/s]642it [06:37,  1.63it/s]643it [06:37,  1.63it/s]644it [06:38,  1.63it/s]645it [06:39,  1.62it/s]646it [06:39,  1.62it/s]647it [06:40,  1.63it/s]648it [06:40,  1.63it/s]649it [06:41,  1.63it/s]650it [06:42,  1.63it/s]651it [06:42,  1.63it/s]652it [06:43,  1.63it/s]653it [06:44,  1.62it/s]654it [06:44,  1.62it/s]655it [06:45,  1.62it/s]656it [06:45,  1.62it/s]657it [06:46,  1.63it/s]658it [06:47,  1.62it/s]659it [06:47,  1.62it/s]660it [06:48,  1.63it/s]661it [06:48,  1.63it/s]662it [06:49,  1.63it/s]663it [06:50,  1.63it/s]664it [06:50,  1.63it/s]665it [06:51,  1.63it/s]666it [06:52,  1.62it/s]667it [06:52,  1.63it/s]668it [06:53,  1.63it/s]669it [06:53,  1.63it/s]670it [06:54,  1.63it/s]671it [06:55,  1.63it/s]672it [06:55,  1.63it/s]673it [06:56,  1.63it/s]674it [06:56,  1.63it/s]675it [06:57,  1.63it/s]676it [06:58,  1.63it/s]677it [06:58,  1.63it/s]678it [06:59,  1.63it/s]679it [06:59,  1.63it/s]680it [07:00,  1.63it/s]681it [07:01,  1.63it/s]682it [07:01,  1.63it/s]683it [07:02,  1.63it/s]684it [07:03,  1.63it/s]685it [07:03,  1.64it/s]686it [07:04,  1.63it/s]687it [07:04,  1.63it/s]688it [07:05,  1.63it/s]689it [07:06,  1.63it/s]690it [07:06,  1.63it/s]691it [07:07,  1.63it/s]692it [07:07,  1.62it/s]693it [07:08,  1.62it/s]694it [07:09,  1.62it/s]695it [07:09,  1.62it/s]696it [07:10,  1.63it/s]697it [07:11,  1.63it/s]698it [07:11,  1.63it/s]699it [07:12,  1.63it/s]step: 000700 	 epe: 3.483
700it [07:13,  1.38it/s]701it [07:13,  1.45it/s]702it [07:14,  1.51it/s]703it [07:15,  1.54it/s]704it [07:15,  1.56it/s]705it [07:16,  1.58it/s]706it [07:16,  1.60it/s]707it [07:17,  1.61it/s]708it [07:18,  1.62it/s]709it [07:18,  1.62it/s]710it [07:19,  1.62it/s]711it [07:19,  1.62it/s]712it [07:20,  1.63it/s]713it [07:21,  1.63it/s]714it [07:21,  1.64it/s]715it [07:22,  1.63it/s]716it [07:23,  1.64it/s]717it [07:23,  1.63it/s]718it [07:24,  1.63it/s]719it [07:24,  1.62it/s]720it [07:25,  1.63it/s]721it [07:26,  1.63it/s]722it [07:26,  1.63it/s]723it [07:27,  1.63it/s]724it [07:27,  1.62it/s]725it [07:28,  1.62it/s]726it [07:29,  1.62it/s]727it [07:29,  1.62it/s]728it [07:30,  1.62it/s]729it [07:31,  1.63it/s]730it [07:31,  1.63it/s]731it [07:32,  1.62it/s]732it [07:32,  1.62it/s]733it [07:33,  1.63it/s]734it [07:34,  1.63it/s]735it [07:34,  1.62it/s]736it [07:35,  1.63it/s]737it [07:35,  1.63it/s]738it [07:36,  1.63it/s]739it [07:37,  1.63it/s]740it [07:37,  1.63it/s]741it [07:38,  1.63it/s]742it [07:39,  1.63it/s]743it [07:39,  1.63it/s]744it [07:40,  1.64it/s]745it [07:40,  1.63it/s]746it [07:41,  1.63it/s]747it [07:42,  1.63it/s]748it [07:42,  1.63it/s]749it [07:43,  1.63it/s]750it [07:43,  1.63it/s]751it [07:44,  1.63it/s]752it [07:45,  1.63it/s]753it [07:45,  1.63it/s]754it [07:46,  1.63it/s]755it [07:47,  1.63it/s]756it [07:47,  1.63it/s]757it [07:48,  1.63it/s]758it [07:48,  1.63it/s]759it [07:49,  1.63it/s]760it [07:50,  1.63it/s]761it [07:50,  1.63it/s]762it [07:51,  1.63it/s]763it [07:51,  1.63it/s]764it [07:52,  1.63it/s]765it [07:53,  1.63it/s]766it [07:53,  1.63it/s]767it [07:54,  1.62it/s]768it [07:54,  1.63it/s]769it [07:55,  1.63it/s]770it [07:56,  1.63it/s]771it [07:56,  1.63it/s]772it [07:57,  1.63it/s]773it [07:58,  1.63it/s]774it [07:58,  1.63it/s]775it [07:59,  1.63it/s]776it [07:59,  1.64it/s]777it [08:00,  1.64it/s]778it [08:01,  1.64it/s]779it [08:01,  1.63it/s]780it [08:02,  1.63it/s]781it [08:02,  1.63it/s]782it [08:03,  1.63it/s]783it [08:04,  1.63it/s]784it [08:04,  1.63it/s]785it [08:05,  1.63it/s]786it [08:06,  1.63it/s]787it [08:06,  1.63it/s]788it [08:07,  1.63it/s]789it [08:07,  1.63it/s]790it [08:08,  1.63it/s]791it [08:09,  1.63it/s]792it [08:09,  1.64it/s]793it [08:10,  1.63it/s]794it [08:10,  1.63it/s]795it [08:11,  1.63it/s]796it [08:12,  1.63it/s]797it [08:12,  1.62it/s]798it [08:13,  1.63it/s]799it [08:13,  1.63it/s]step: 000800 	 epe: 9.450
800it [08:15,  1.37it/s]801it [08:15,  1.44it/s]802it [08:16,  1.49it/s]803it [08:16,  1.53it/s]804it [08:17,  1.56it/s]805it [08:18,  1.58it/s]806it [08:18,  1.59it/s]807it [08:19,  1.60it/s]808it [08:19,  1.60it/s]809it [08:20,  1.61it/s]810it [08:21,  1.62it/s]811it [08:21,  1.62it/s]812it [08:22,  1.62it/s]813it [08:23,  1.62it/s]814it [08:23,  1.62it/s]815it [08:24,  1.62it/s]816it [08:24,  1.62it/s]817it [08:25,  1.63it/s]818it [08:26,  1.62it/s]819it [08:26,  1.62it/s]820it [08:27,  1.63it/s]821it [08:27,  1.62it/s]822it [08:28,  1.62it/s]823it [08:29,  1.63it/s]824it [08:29,  1.63it/s]825it [08:30,  1.62it/s]826it [08:31,  1.63it/s]827it [08:31,  1.63it/s]828it [08:32,  1.64it/s]829it [08:32,  1.64it/s]830it [08:33,  1.63it/s]831it [08:34,  1.64it/s]832it [08:34,  1.63it/s]833it [08:35,  1.63it/s]834it [08:35,  1.63it/s]835it [08:36,  1.63it/s]836it [08:37,  1.64it/s]837it [08:37,  1.64it/s]838it [08:38,  1.64it/s]839it [08:38,  1.63it/s]840it [08:39,  1.63it/s]841it [08:40,  1.63it/s]842it [08:40,  1.63it/s]843it [08:41,  1.63it/s]844it [08:42,  1.63it/s]845it [08:42,  1.63it/s]846it [08:43,  1.63it/s]847it [08:43,  1.63it/s]848it [08:44,  1.63it/s]849it [08:45,  1.64it/s]850it [08:45,  1.63it/s]851it [08:46,  1.64it/s]852it [08:46,  1.63it/s]853it [08:47,  1.63it/s]854it [08:48,  1.63it/s]855it [08:48,  1.63it/s]856it [08:49,  1.63it/s]857it [08:49,  1.63it/s]858it [08:50,  1.63it/s]859it [08:51,  1.63it/s]860it [08:51,  1.63it/s]861it [08:52,  1.63it/s]862it [08:53,  1.63it/s]863it [08:53,  1.63it/s]864it [08:54,  1.62it/s]865it [08:54,  1.63it/s]866it [08:55,  1.62it/s]867it [08:56,  1.62it/s]868it [08:56,  1.63it/s]869it [08:57,  1.63it/s]870it [08:57,  1.63it/s]871it [08:58,  1.63it/s]872it [08:59,  1.63it/s]873it [08:59,  1.63it/s]874it [09:00,  1.63it/s]875it [09:01,  1.63it/s]876it [09:01,  1.62it/s]877it [09:02,  1.62it/s]878it [09:02,  1.62it/s]879it [09:03,  1.63it/s]880it [09:04,  1.62it/s]881it [09:04,  1.62it/s]882it [09:05,  1.63it/s]883it [09:05,  1.63it/s]884it [09:06,  1.63it/s]885it [09:07,  1.63it/s]886it [09:07,  1.63it/s]887it [09:08,  1.62it/s]888it [09:09,  1.63it/s]889it [09:09,  1.63it/s]890it [09:10,  1.63it/s]891it [09:10,  1.63it/s]892it [09:11,  1.63it/s]893it [09:12,  1.63it/s]894it [09:12,  1.63it/s]895it [09:13,  1.62it/s]896it [09:13,  1.63it/s]897it [09:14,  1.63it/s]898it [09:15,  1.63it/s]899it [09:15,  1.63it/s]step: 000900 	 epe: 6.221
900it [09:16,  1.37it/s]901it [09:17,  1.44it/s]902it [09:18,  1.49it/s]903it [09:18,  1.53it/s]904it [09:19,  1.56it/s]905it [09:19,  1.58it/s]906it [09:20,  1.60it/s]907it [09:21,  1.61it/s]908it [09:21,  1.61it/s]909it [09:22,  1.62it/s]910it [09:22,  1.63it/s]911it [09:23,  1.63it/s]912it [09:24,  1.63it/s]913it [09:24,  1.63it/s]914it [09:25,  1.63it/s]915it [09:25,  1.63it/s]916it [09:26,  1.63it/s]917it [09:27,  1.64it/s]918it [09:27,  1.63it/s]919it [09:28,  1.63it/s]920it [09:29,  1.63it/s]921it [09:29,  1.63it/s]922it [09:30,  1.63it/s]923it [09:30,  1.63it/s]924it [09:31,  1.63it/s]925it [09:32,  1.62it/s]926it [09:32,  1.63it/s]927it [09:33,  1.63it/s]928it [09:33,  1.62it/s]929it [09:34,  1.63it/s]930it [09:35,  1.62it/s]931it [09:35,  1.62it/s]932it [09:36,  1.62it/s]933it [09:37,  1.62it/s]934it [09:37,  1.62it/s]935it [09:38,  1.62it/s]936it [09:38,  1.62it/s]937it [09:39,  1.62it/s]938it [09:40,  1.63it/s]939it [09:40,  1.63it/s]940it [09:41,  1.62it/s]941it [09:41,  1.62it/s]942it [09:42,  1.63it/s]943it [09:43,  1.62it/s]944it [09:43,  1.63it/s]945it [09:44,  1.63it/s]946it [09:45,  1.63it/s]947it [09:45,  1.63it/s]948it [09:46,  1.63it/s]949it [09:46,  1.63it/s]950it [09:47,  1.64it/s]951it [09:48,  1.64it/s]952it [09:48,  1.63it/s]953it [09:49,  1.63it/s]954it [09:49,  1.63it/s]955it [09:50,  1.63it/s]956it [09:51,  1.63it/s]957it [09:51,  1.63it/s]958it [09:52,  1.63it/s]959it [09:53,  1.63it/s]960it [09:53,  1.63it/s]961it [09:54,  1.63it/s]962it [09:54,  1.62it/s]963it [09:55,  1.62it/s]964it [09:56,  1.63it/s]965it [09:56,  1.63it/s]966it [09:57,  1.63it/s]967it [09:57,  1.63it/s]968it [09:58,  1.63it/s]969it [09:59,  1.63it/s]970it [09:59,  1.63it/s]971it [10:00,  1.63it/s]972it [10:00,  1.63it/s]973it [10:01,  1.63it/s]974it [10:02,  1.62it/s]975it [10:02,  1.62it/s]976it [10:03,  1.62it/s]977it [10:04,  1.62it/s]978it [10:04,  1.62it/s]979it [10:05,  1.62it/s]980it [10:05,  1.63it/s]981it [10:06,  1.63it/s]982it [10:07,  1.62it/s]983it [10:07,  1.63it/s]984it [10:08,  1.63it/s]985it [10:08,  1.63it/s]986it [10:09,  1.62it/s]987it [10:10,  1.62it/s]988it [10:10,  1.62it/s]989it [10:11,  1.63it/s]990it [10:12,  1.62it/s]991it [10:12,  1.63it/s]992it [10:13,  1.63it/s]993it [10:13,  1.64it/s]994it [10:14,  1.64it/s]995it [10:15,  1.63it/s]996it [10:15,  1.64it/s]997it [10:16,  1.63it/s]998it [10:16,  1.63it/s]999it [10:17,  1.63it/s]step: 001000 	 epe: 2.948
Save checkpoint at step: 1000
1000it [10:18,  1.35it/s]1001it [10:19,  1.42it/s]1002it [10:19,  1.48it/s]1003it [10:20,  1.52it/s]1004it [10:21,  1.55it/s]1005it [10:21,  1.58it/s]1006it [10:22,  1.59it/s]1007it [10:22,  1.60it/s]1008it [10:23,  1.61it/s]1009it [10:24,  1.61it/s]1010it [10:24,  1.61it/s]1011it [10:25,  1.61it/s]1012it [10:25,  1.62it/s]1013it [10:26,  1.61it/s]1014it [10:27,  1.62it/s]1015it [10:27,  1.62it/s]1016it [10:28,  1.62it/s]1017it [10:29,  1.63it/s]1018it [10:29,  1.62it/s]1019it [10:30,  1.62it/s]1020it [10:30,  1.63it/s]1021it [10:31,  1.63it/s]1022it [10:32,  1.63it/s]1023it [10:32,  1.63it/s]1024it [10:33,  1.63it/s]1025it [10:33,  1.63it/s]1026it [10:34,  1.64it/s]1027it [10:35,  1.64it/s]1028it [10:35,  1.63it/s]1029it [10:36,  1.63it/s]1030it [10:37,  1.63it/s]1031it [10:37,  1.63it/s]1032it [10:38,  1.63it/s]1033it [10:38,  1.63it/s]1034it [10:39,  1.63it/s]1035it [10:40,  1.63it/s]1036it [10:40,  1.64it/s]1037it [10:41,  1.64it/s]1038it [10:41,  1.63it/s]1039it [10:42,  1.63it/s]1040it [10:43,  1.63it/s]1041it [10:43,  1.63it/s]1042it [10:44,  1.63it/s]1043it [10:45,  1.63it/s]1044it [10:45,  1.63it/s]1045it [10:46,  1.63it/s]1046it [10:46,  1.63it/s]1047it [10:47,  1.63it/s]1048it [10:48,  1.63it/s]1049it [10:48,  1.62it/s]1050it [10:49,  1.63it/s]1051it [10:49,  1.63it/s]1052it [10:50,  1.63it/s]1053it [10:51,  1.63it/s]1054it [10:51,  1.63it/s]1055it [10:52,  1.63it/s]1056it [10:52,  1.64it/s]1057it [10:53,  1.64it/s]1058it [10:54,  1.64it/s]1059it [10:54,  1.63it/s]1060it [10:55,  1.63it/s]1061it [10:56,  1.63it/s]1062it [10:56,  1.63it/s]1063it [10:57,  1.63it/s]1064it [10:57,  1.63it/s]1065it [10:58,  1.63it/s]1066it [10:59,  1.63it/s]1067it [10:59,  1.63it/s]1068it [11:00,  1.63it/s]1069it [11:00,  1.63it/s]1070it [11:01,  1.63it/s]1071it [11:02,  1.63it/s]1072it [11:02,  1.63it/s]1073it [11:03,  1.63it/s]1074it [11:04,  1.63it/s]1075it [11:04,  1.63it/s]1076it [11:05,  1.62it/s]1077it [11:05,  1.62it/s]1078it [11:06,  1.63it/s]1079it [11:07,  1.62it/s]1080it [11:07,  1.62it/s]1081it [11:08,  1.63it/s]1082it [11:08,  1.63it/s]1083it [11:09,  1.64it/s]1084it [11:10,  1.64it/s]1085it [11:10,  1.63it/s]1086it [11:11,  1.62it/s]1087it [11:12,  1.63it/s]1088it [11:12,  1.63it/s]1089it [11:13,  1.63it/s]1090it [11:13,  1.63it/s]1091it [11:14,  1.63it/s]1092it [11:15,  1.63it/s]1093it [11:15,  1.62it/s]1094it [11:16,  1.63it/s]1095it [11:16,  1.63it/s]1096it [11:17,  1.63it/s]1097it [11:18,  1.63it/s]1098it [11:18,  1.63it/s]1099it [11:19,  1.63it/s]step: 001100 	 epe: 3.079
1100it [11:20,  1.38it/s]1101it [11:20,  1.44it/s]1102it [11:21,  1.49it/s]1103it [11:22,  1.53it/s]1104it [11:22,  1.55it/s]1105it [11:23,  1.57it/s]1106it [11:24,  1.58it/s]1107it [11:24,  1.60it/s]1108it [11:25,  1.61it/s]1109it [11:25,  1.62it/s]1110it [11:26,  1.62it/s]1111it [11:27,  1.62it/s]1112it [11:27,  1.63it/s]1113it [11:28,  1.63it/s]1114it [11:28,  1.63it/s]1115it [11:29,  1.63it/s]1116it [11:30,  1.63it/s]1117it [11:30,  1.63it/s]1118it [11:31,  1.63it/s]1119it [11:32,  1.63it/s]1120it [11:32,  1.63it/s]1121it [11:33,  1.63it/s]1122it [11:33,  1.63it/s]1123it [11:34,  1.63it/s]1124it [11:35,  1.63it/s]1125it [11:35,  1.63it/s]1126it [11:36,  1.64it/s]1127it [11:36,  1.63it/s]1128it [11:37,  1.63it/s]1129it [11:38,  1.63it/s]1130it [11:38,  1.63it/s]1131it [11:39,  1.63it/s]1132it [11:40,  1.63it/s]1133it [11:40,  1.62it/s]1134it [11:41,  1.62it/s]1135it [11:41,  1.63it/s]1136it [11:42,  1.63it/s]1137it [11:43,  1.63it/s]1138it [11:43,  1.62it/s]1139it [11:44,  1.62it/s]1140it [11:44,  1.63it/s]1141it [11:45,  1.63it/s]1142it [11:46,  1.63it/s]1143it [11:46,  1.63it/s]1144it [11:47,  1.63it/s]1145it [11:47,  1.63it/s]1146it [11:48,  1.63it/s]1147it [11:49,  1.63it/s]1148it [11:49,  1.63it/s]1149it [11:50,  1.63it/s]1150it [11:51,  1.63it/s]1151it [11:51,  1.63it/s]1152it [11:52,  1.62it/s]1153it [11:52,  1.62it/s]1154it [11:53,  1.63it/s]1155it [11:54,  1.62it/s]1156it [11:54,  1.63it/s]1157it [11:55,  1.63it/s]1158it [11:55,  1.63it/s]1159it [11:56,  1.63it/s]1160it [11:57,  1.63it/s]1161it [11:57,  1.63it/s]1162it [11:58,  1.64it/s]1163it [11:59,  1.63it/s]1164it [11:59,  1.63it/s]1165it [12:00,  1.63it/s]1166it [12:00,  1.63it/s]1167it [12:01,  1.62it/s]1168it [12:02,  1.63it/s]1169it [12:02,  1.63it/s]1170it [12:03,  1.62it/s]1171it [12:03,  1.62it/s]1172it [12:04,  1.62it/s]1173it [12:05,  1.62it/s]1174it [12:05,  1.61it/s]1175it [12:06,  1.62it/s]1176it [12:07,  1.62it/s]1177it [12:07,  1.62it/s]1178it [12:08,  1.63it/s]1179it [12:08,  1.63it/s]1180it [12:09,  1.63it/s]1181it [12:10,  1.64it/s]1182it [12:10,  1.63it/s]1183it [12:11,  1.63it/s]1184it [12:11,  1.63it/s]1185it [12:12,  1.63it/s]1186it [12:13,  1.64it/s]1187it [12:13,  1.63it/s]1188it [12:14,  1.63it/s]1189it [12:15,  1.63it/s]1190it [12:15,  1.63it/s]1191it [12:16,  1.63it/s]1192it [12:16,  1.63it/s]1193it [12:17,  1.63it/s]1194it [12:18,  1.63it/s]1195it [12:18,  1.64it/s]1196it [12:19,  1.63it/s]1197it [12:19,  1.63it/s]1198it [12:20,  1.64it/s]1199it [12:21,  1.64it/s]step: 001200 	 epe: 8.125
1200it [12:22,  1.35it/s]1201it [12:22,  1.43it/s]1202it [12:23,  1.48it/s]1203it [12:24,  1.52it/s]1204it [12:24,  1.55it/s]1205it [12:25,  1.58it/s]1206it [12:25,  1.59it/s]1207it [12:26,  1.61it/s]1208it [12:27,  1.61it/s]1209it [12:27,  1.61it/s]1210it [12:28,  1.62it/s]1211it [12:28,  1.63it/s]1212it [12:29,  1.63it/s]1213it [12:30,  1.63it/s]1214it [12:30,  1.63it/s]1215it [12:31,  1.63it/s]1216it [12:32,  1.62it/s]1217it [12:32,  1.62it/s]1218it [12:33,  1.62it/s]1219it [12:33,  1.62it/s]1220it [12:34,  1.62it/s]1221it [12:35,  1.63it/s]1222it [12:35,  1.62it/s]1223it [12:36,  1.62it/s]1224it [12:36,  1.63it/s]1225it [12:37,  1.62it/s]1226it [12:38,  1.62it/s]1227it [12:38,  1.63it/s]1228it [12:39,  1.63it/s]1229it [12:40,  1.63it/s]1230it [12:40,  1.62it/s]1231it [12:41,  1.62it/s]1232it [12:41,  1.62it/s]1233it [12:42,  1.62it/s]1234it [12:43,  1.62it/s]1235it [12:43,  1.62it/s]1236it [12:44,  1.63it/s]1237it [12:44,  1.63it/s]1238it [12:45,  1.63it/s]1239it [12:46,  1.63it/s]1240it [12:46,  1.62it/s]1241it [12:47,  1.62it/s]1242it [12:48,  1.63it/s]1243it [12:48,  1.63it/s]1244it [12:49,  1.62it/s]1245it [12:49,  1.63it/s]1246it [12:50,  1.63it/s]1247it [12:51,  1.63it/s]1248it [12:51,  1.63it/s]1249it [12:52,  1.63it/s]1250it [12:52,  1.63it/s]1251it [12:53,  1.63it/s]1252it [12:54,  1.63it/s]1253it [12:54,  1.63it/s]1254it [12:55,  1.63it/s]1255it [12:55,  1.64it/s]1256it [12:56,  1.64it/s]1257it [12:57,  1.63it/s]1258it [12:57,  1.63it/s]1259it [12:58,  1.63it/s]1260it [12:59,  1.63it/s]1261it [12:59,  1.63it/s]1262it [13:00,  1.63it/s]1263it [13:00,  1.62it/s]1264it [13:01,  1.63it/s]1265it [13:02,  1.63it/s]1266it [13:02,  1.63it/s]1267it [13:03,  1.63it/s]1268it [13:03,  1.63it/s]1269it [13:04,  1.63it/s]1270it [13:05,  1.63it/s]1271it [13:05,  1.63it/s]1272it [13:06,  1.63it/s]1273it [13:07,  1.63it/s]1274it [13:07,  1.63it/s]1275it [13:08,  1.63it/s]1276it [13:08,  1.63it/s]1277it [13:09,  1.62it/s]1278it [13:10,  1.62it/s]1279it [13:10,  1.63it/s]1280it [13:11,  1.63it/s]1281it [13:11,  1.63it/s]1282it [13:12,  1.63it/s]1283it [13:13,  1.63it/s]1284it [13:13,  1.63it/s]1285it [13:14,  1.63it/s]1286it [13:15,  1.62it/s]1287it [13:15,  1.63it/s]1288it [13:16,  1.63it/s]1289it [13:16,  1.63it/s]1290it [13:17,  1.63it/s]1291it [13:18,  1.63it/s]1292it [13:18,  1.63it/s]1293it [13:19,  1.64it/s]1294it [13:19,  1.64it/s]1295it [13:20,  1.63it/s]1296it [13:21,  1.63it/s]1297it [13:21,  1.63it/s]1298it [13:22,  1.63it/s]1299it [13:23,  1.63it/s]step: 001300 	 epe: 2.049
1300it [13:24,  1.36it/s]1301it [13:24,  1.43it/s]1302it [13:25,  1.49it/s]1303it [13:25,  1.53it/s]1304it [13:26,  1.56it/s]1305it [13:27,  1.58it/s]1306it [13:27,  1.59it/s]1307it [13:28,  1.60it/s]1308it [13:28,  1.61it/s]1309it [13:29,  1.61it/s]1310it [13:30,  1.62it/s]1311it [13:30,  1.62it/s]1312it [13:31,  1.62it/s]1313it [13:31,  1.63it/s]1314it [13:32,  1.63it/s]1315it [13:33,  1.63it/s]1316it [13:33,  1.62it/s]1317it [13:34,  1.62it/s]1318it [13:35,  1.62it/s]1319it [13:35,  1.62it/s]1320it [13:36,  1.62it/s]1321it [13:36,  1.63it/s]1322it [13:37,  1.63it/s]1323it [13:38,  1.63it/s]1324it [13:38,  1.63it/s]1325it [13:39,  1.63it/s]1326it [13:39,  1.63it/s]1327it [13:40,  1.63it/s]1328it [13:41,  1.62it/s]1329it [13:41,  1.63it/s]1330it [13:42,  1.63it/s]1331it [13:43,  1.62it/s]1332it [13:43,  1.62it/s]1333it [13:44,  1.63it/s]1334it [13:44,  1.62it/s]1335it [13:45,  1.62it/s]1336it [13:46,  1.62it/s]1337it [13:46,  1.62it/s]1338it [13:47,  1.62it/s]1339it [13:48,  1.62it/s]1340it [13:48,  1.62it/s]1341it [13:49,  1.62it/s]1342it [13:49,  1.63it/s]1343it [13:50,  1.63it/s]1344it [13:51,  1.63it/s]1345it [13:51,  1.63it/s]1346it [13:52,  1.62it/s]1347it [13:52,  1.63it/s]1348it [13:53,  1.63it/s]1349it [13:54,  1.62it/s]1350it [13:54,  1.63it/s]1351it [13:55,  1.62it/s]1352it [13:56,  1.62it/s]1353it [13:56,  1.62it/s]1354it [13:57,  1.63it/s]1355it [13:57,  1.63it/s]1356it [13:58,  1.63it/s]1357it [13:59,  1.63it/s]1358it [13:59,  1.63it/s]1359it [14:00,  1.63it/s]1360it [14:00,  1.63it/s]1361it [14:01,  1.62it/s]1362it [14:02,  1.62it/s]1363it [14:02,  1.63it/s]1364it [14:03,  1.63it/s]1365it [14:03,  1.63it/s]1366it [14:04,  1.63it/s]1367it [14:05,  1.63it/s]1368it [14:05,  1.61it/s]1369it [14:06,  1.62it/s]1370it [14:07,  1.62it/s]1371it [14:07,  1.63it/s]1372it [14:08,  1.63it/s]1373it [14:08,  1.63it/s]1374it [14:09,  1.63it/s]1375it [14:10,  1.63it/s]1376it [14:10,  1.63it/s]1377it [14:11,  1.63it/s]1378it [14:11,  1.62it/s]1379it [14:12,  1.62it/s]1380it [14:13,  1.63it/s]1381it [14:13,  1.63it/s]1382it [14:14,  1.63it/s]1383it [14:15,  1.63it/s]1384it [14:15,  1.63it/s]1385it [14:16,  1.63it/s]1386it [14:16,  1.64it/s]1387it [14:17,  1.63it/s]1388it [14:18,  1.63it/s]1389it [14:18,  1.63it/s]1390it [14:19,  1.63it/s]1391it [14:19,  1.63it/s]1392it [14:20,  1.63it/s]1393it [14:21,  1.63it/s]1394it [14:21,  1.62it/s]1395it [14:22,  1.62it/s]1396it [14:23,  1.62it/s]1397it [14:23,  1.62it/s]1398it [14:24,  1.63it/s]1399it [14:24,  1.63it/s]step: 001400 	 epe: 7.124
1400it [14:25,  1.37it/s]1401it [14:26,  1.44it/s]1402it [14:27,  1.50it/s]1403it [14:27,  1.53it/s]1404it [14:28,  1.56it/s]1405it [14:28,  1.58it/s]1406it [14:29,  1.60it/s]1407it [14:30,  1.61it/s]1408it [14:30,  1.61it/s]1409it [14:31,  1.62it/s]1410it [14:32,  1.62it/s]1411it [14:32,  1.62it/s]1412it [14:33,  1.62it/s]1413it [14:33,  1.62it/s]1414it [14:34,  1.62it/s]1415it [14:35,  1.62it/s]1416it [14:35,  1.62it/s]1417it [14:36,  1.62it/s]1418it [14:36,  1.62it/s]1419it [14:37,  1.62it/s]1420it [14:38,  1.63it/s]1421it [14:38,  1.64it/s]1422it [14:39,  1.63it/s]1423it [14:40,  1.63it/s]1424it [14:40,  1.63it/s]1425it [14:41,  1.63it/s]1426it [14:41,  1.63it/s]1427it [14:42,  1.63it/s]1428it [14:43,  1.63it/s]1429it [14:43,  1.62it/s]1430it [14:44,  1.62it/s]1431it [14:44,  1.62it/s]1432it [14:45,  1.62it/s]1433it [14:46,  1.63it/s]1434it [14:46,  1.62it/s]1435it [14:47,  1.62it/s]1436it [14:48,  1.62it/s]1437it [14:48,  1.63it/s]1438it [14:49,  1.63it/s]1439it [14:49,  1.63it/s]1440it [14:50,  1.63it/s]1441it [14:51,  1.63it/s]1442it [14:51,  1.63it/s]1443it [14:52,  1.63it/s]1444it [14:52,  1.63it/s]1445it [14:53,  1.63it/s]1446it [14:54,  1.63it/s]1447it [14:54,  1.63it/s]1448it [14:55,  1.63it/s]1449it [14:55,  1.63it/s]1450it [14:56,  1.63it/s]1451it [14:57,  1.63it/s]1452it [14:57,  1.63it/s]1453it [14:58,  1.63it/s]1454it [14:59,  1.63it/s]1455it [14:59,  1.62it/s]1456it [15:00,  1.62it/s]1457it [15:00,  1.62it/s]1458it [15:01,  1.62it/s]1459it [15:02,  1.62it/s]1460it [15:02,  1.61it/s]1461it [15:03,  1.61it/s]1462it [15:04,  1.62it/s]1463it [15:04,  1.62it/s]1464it [15:05,  1.62it/s]1465it [15:05,  1.62it/s]1466it [15:06,  1.62it/s]1467it [15:07,  1.62it/s]1468it [15:07,  1.63it/s]1469it [15:08,  1.62it/s]1470it [15:08,  1.62it/s]1471it [15:09,  1.63it/s]1472it [15:10,  1.62it/s]1473it [15:10,  1.63it/s]1474it [15:11,  1.63it/s]1475it [15:12,  1.63it/s]1476it [15:12,  1.63it/s]1477it [15:13,  1.63it/s]1478it [15:13,  1.63it/s]1479it [15:14,  1.63it/s]1480it [15:15,  1.63it/s]1481it [15:15,  1.63it/s]1482it [15:16,  1.63it/s]1483it [15:16,  1.63it/s]1484it [15:17,  1.63it/s]1485it [15:18,  1.62it/s]1486it [15:18,  1.62it/s]1487it [15:19,  1.62it/s]1488it [15:19,  1.62it/s]1489it [15:20,  1.63it/s]1490it [15:21,  1.63it/s]1491it [15:21,  1.62it/s]1492it [15:22,  1.63it/s]1493it [15:23,  1.63it/s]1494it [15:23,  1.62it/s]1495it [15:24,  1.62it/s]1496it [15:24,  1.62it/s]1497it [15:25,  1.62it/s]1498it [15:26,  1.63it/s]1499it [15:26,  1.62it/s]step: 001500 	 epe: 2.828
1500it [15:27,  1.34it/s]1501it [15:28,  1.41it/s]1502it [15:29,  1.47it/s]1503it [15:29,  1.52it/s]1504it [15:30,  1.56it/s]1505it [15:30,  1.58it/s]1506it [15:31,  1.60it/s]1507it [15:32,  1.61it/s]1508it [15:32,  1.61it/s]1509it [15:33,  1.62it/s]1510it [15:33,  1.63it/s]1511it [15:34,  1.63it/s]1512it [15:35,  1.63it/s]1513it [15:35,  1.62it/s]1514it [15:36,  1.63it/s]1515it [15:37,  1.63it/s]1516it [15:37,  1.63it/s]1517it [15:38,  1.63it/s]1518it [15:38,  1.63it/s]1519it [15:39,  1.63it/s]1520it [15:40,  1.63it/s]1521it [15:40,  1.63it/s]1522it [15:41,  1.63it/s]1523it [15:41,  1.63it/s]1524it [15:42,  1.63it/s]1525it [15:43,  1.63it/s]1526it [15:43,  1.63it/s]1527it [15:44,  1.62it/s]1528it [15:44,  1.63it/s]1529it [15:45,  1.63it/s]1530it [15:46,  1.63it/s]1531it [15:46,  1.63it/s]1532it [15:47,  1.63it/s]1533it [15:48,  1.64it/s]1534it [15:48,  1.64it/s]1535it [15:49,  1.64it/s]1536it [15:49,  1.63it/s]1537it [15:50,  1.63it/s]1538it [15:51,  1.63it/s]1539it [15:51,  1.63it/s]1540it [15:52,  1.63it/s]1541it [15:52,  1.63it/s]1542it [15:53,  1.61it/s]1543it [15:54,  1.61it/s]1544it [15:54,  1.62it/s]1545it [15:55,  1.62it/s]1546it [15:56,  1.62it/s]1547it [15:56,  1.63it/s]1548it [15:57,  1.61it/s]1549it [15:57,  1.62it/s]1550it [15:58,  1.62it/s]1551it [15:59,  1.63it/s]1552it [15:59,  1.62it/s]1553it [16:00,  1.63it/s]1554it [16:00,  1.63it/s]1555it [16:01,  1.63it/s]1556it [16:02,  1.63it/s]1557it [16:02,  1.63it/s]1558it [16:03,  1.64it/s]1559it [16:04,  1.64it/s]1560it [16:04,  1.63it/s]1561it [16:05,  1.63it/s]1562it [16:05,  1.63it/s]1563it [16:06,  1.63it/s]1564it [16:07,  1.63it/s]1565it [16:07,  1.61it/s]1566it [16:08,  1.61it/s]1567it [16:08,  1.62it/s]1568it [16:09,  1.62it/s]1569it [16:10,  1.62it/s]1570it [16:10,  1.60it/s]1571it [16:11,  1.61it/s]1572it [16:12,  1.61it/s]1573it [16:12,  1.57it/s]1574it [16:13,  1.57it/s]1575it [16:13,  1.59it/s]1576it [16:14,  1.60it/s]1577it [16:15,  1.61it/s]1578it [16:15,  1.61it/s]1579it [16:16,  1.61it/s]1580it [16:17,  1.61it/s]1581it [16:17,  1.62it/s]1582it [16:18,  1.62it/s]1583it [16:18,  1.61it/s]1584it [16:19,  1.62it/s]1585it [16:20,  1.63it/s]1586it [16:20,  1.63it/s]1587it [16:21,  1.62it/s]1588it [16:21,  1.63it/s]1589it [16:22,  1.62it/s]1590it [16:23,  1.62it/s]1591it [16:23,  1.63it/s]1592it [16:24,  1.63it/s]1593it [16:25,  1.63it/s]1594it [16:25,  1.63it/s]1595it [16:26,  1.63it/s]1596it [16:26,  1.63it/s]1597it [16:27,  1.63it/s]1598it [16:28,  1.63it/s]1599it [16:28,  1.63it/s]step: 001600 	 epe: 4.341
1600it [16:29,  1.35it/s]1601it [16:30,  1.43it/s]1602it [16:31,  1.48it/s]